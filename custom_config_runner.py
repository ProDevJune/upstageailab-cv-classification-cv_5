#!/usr/bin/env python3
"""
Custom Config Sequential Runner
ì‚¬ìš©ìê°€ ì§ì ‘ ë§Œë“  ì—¬ëŸ¬ ê°œì˜ YAML íŒŒì¼ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import os
import yaml
import argparse
import subprocess
import json
from pathlib import Path
import time
from datetime import datetime

class CustomConfigRunner:
    def __init__(self, config_dir="my_configs"):
        self.config_dir = Path(config_dir)
        self.config_dir.mkdir(exist_ok=True)
        
        # ì‹¤í–‰ ë¡œê·¸ ë””ë ‰í† ë¦¬
        self.logs_dir = self.config_dir / "logs"
        self.logs_dir.mkdir(exist_ok=True)
        
        # ê²°ê³¼ ë””ë ‰í† ë¦¬
        self.results_dir = self.config_dir / "results"
        self.results_dir.mkdir(exist_ok=True)
        
    def scan_configs(self, pattern="*.yaml"):
        """ì‚¬ìš©ì ì •ì˜ config íŒŒì¼ë“¤ ìŠ¤ìº”"""
        config_files = list(self.config_dir.glob(pattern))
        config_files = [f for f in config_files if f.name not in ['execution_order.txt', 'results.json']]
        
        print(f"ğŸ” Found {len(config_files)} config files:")
        for i, config_file in enumerate(config_files, 1):
            print(f"  {i}. {config_file.name}")
        
        return config_files
    
    def detect_experiment_type(self, config_file):
        """Config ë‚´ìš©ì„ ë¶„ì„í•´ì„œ ì‹¤í—˜ íƒ€ì… ìë™ ê°ì§€"""
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # v2_1 íŠ¹ì§• ê°ì§€
            v2_1_indicators = [
                'convnext' in config.get('model_name', '').lower(),
                config.get('scheduler_name') == 'CosineAnnealingWarmupRestarts',
                config.get('epochs', 0) > 5000,
                config.get('lr', 0) < 0.0001
            ]
            
            # v2_2 íŠ¹ì§• ê°ì§€  
            v2_2_indicators = [
                config.get('criterion') == 'FocalLoss',
                config.get('two_stage', False),
                'online_aug' in config and any(config['online_aug'].values()),
                'dynamic_augmentation' in config and config['dynamic_augmentation'].get('enabled', False)
            ]
            
            if sum(v2_1_indicators) >= 2:
                return 'v2_1'
            elif sum(v2_2_indicators) >= 1:
                return 'v2_2'
            else:
                # ê¸°ë³¸ì ìœ¼ë¡œ v2_2 (ë” ë²”ìš©ì )
                return 'v2_2'
                
        except Exception as e:
            print(f"âš ï¸  Error detecting type for {config_file}: {e}")
            return 'v2_2'
    
    def get_execution_order(self):
        """ì‹¤í–‰ ìˆœì„œ íŒŒì¼ ë¡œë“œ (ìˆìœ¼ë©´)"""
        order_file = self.config_dir / "execution_order.txt"
        if order_file.exists():
            with open(order_file, 'r') as f:
                order = [line.strip() for line in f if line.strip() and not line.startswith('#')]
            return order
        return None
    
    def create_execution_order_template(self, config_files):
        """ì‹¤í–‰ ìˆœì„œ í…œí”Œë¦¿ ìƒì„±"""
        order_file = self.config_dir / "execution_order.txt"
        
        with open(order_file, 'w') as f:
            f.write("# ì‹¤í–‰ ìˆœì„œ íŒŒì¼\n")
            f.write("# ì›í•˜ëŠ” ìˆœì„œëŒ€ë¡œ config íŒŒì¼ëª…ì„ ë‚˜ì—´í•˜ì„¸ìš”\n")
            f.write("# '#'ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì¤„ì€ ì£¼ì„ì…ë‹ˆë‹¤\n")
            f.write("# íŒŒì¼ëª…ë§Œ ì ìœ¼ë©´ ë©ë‹ˆë‹¤ (í™•ì¥ì í¬í•¨)\n\n")
            
            for config_file in config_files:
                f.write(f"{config_file.name}\n")
        
        print(f"ğŸ“ Created execution order template: {order_file}")
        print("   Edit this file to customize execution order")
        
    def run_single_experiment(self, config_file, exp_type):
        """ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰"""
        print(f"\nğŸ”¬ Starting experiment: {config_file.name}")
        print(f"   Type: {exp_type}")
        print(f"   Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ì ì ˆí•œ main ìŠ¤í¬ë¦½íŠ¸ ì„ íƒ
        if exp_type == 'v2_1':
            main_script = "codes/gemini_main_v2_1_style.py"
        else:
            main_script = "codes/gemini_main_v2_enhanced.py"
        
        # ë¡œê·¸ íŒŒì¼ ì„¤ì •
        log_file = self.logs_dir / f"{config_file.stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        # ì‹¤í–‰ ëª…ë ¹ êµ¬ì„±
        cmd = ['python', main_script, '--config', str(config_file)]
        
        # 2-stage í•™ìŠµ ê°ì§€ (config2 íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸)
        config2_file = self.config_dir / f"{config_file.stem}_stage2.yaml"
        if config2_file.exists():
            cmd.extend(['--config2', str(config2_file)])
            print(f"   ğŸ¯ 2-stage learning detected: {config2_file.name}")
        
        try:
            # ì‹¤í—˜ ì‹¤í–‰
            start_time = time.time()
            
            with open(log_file, 'w') as f:
                process = subprocess.Popen(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    bufsize=1,
                    universal_newlines=True
                )\n                
                # ì‹¤ì‹œê°„ ì¶œë ¥ ë° ë¡œê·¸ ê¸°ë¡
                for line in process.stdout:
                    print(line, end='')
                    f.write(line)
                    f.flush()
                
                process.wait()
            
            end_time = time.time()
            duration = end_time - start_time
            
            if process.returncode == 0:
                print(f"âœ… Experiment completed successfully")
                print(f"   Duration: {duration/3600:.2f} hours")
                status = "success"
            else:
                print(f"âŒ Experiment failed with return code: {process.returncode}")
                status = "failed"
                
        except Exception as e:
            print(f"âŒ Error running experiment: {e}")
            status = "error"
            duration = 0
        
        # ê²°ê³¼ ê¸°ë¡
        result = {
            'config_file': config_file.name,
            'experiment_type': exp_type,
            'status': status,
            'duration_hours': duration / 3600,
            'start_time': datetime.fromtimestamp(start_time).isoformat(),
            'end_time': datetime.fromtimestamp(end_time).isoformat(),
            'log_file': str(log_file)
        }
        
        return result
    
    def run_all_experiments(self, config_files, respect_order=True):
        """ëª¨ë“  ì‹¤í—˜ ìˆœì°¨ ì‹¤í–‰"""
        print(f"ğŸš€ Starting sequential execution of {len(config_files)} experiments")
        print("=" * 60)
        
        # ì‹¤í–‰ ìˆœì„œ ê²°ì •
        if respect_order:
            order = self.get_execution_order()
            if order:
                print("ğŸ“‹ Using custom execution order")
                # ìˆœì„œì— ë”°ë¼ config íŒŒì¼ ì •ë ¬
                ordered_configs = []
                for filename in order:
                    config_file = self.config_dir / filename
                    if config_file.exists():
                        ordered_configs.append(config_file)
                    else:
                        print(f"âš ï¸  Warning: {filename} not found")
                config_files = ordered_configs
        
        results = []
        failed_experiments = []
        
        for i, config_file in enumerate(config_files, 1):
            print(f"\nğŸ“Š Progress: {i}/{len(config_files)}")
            
            # ì‹¤í—˜ íƒ€ì… ê°ì§€
            exp_type = self.detect_experiment_type(config_file)
            
            # ì‹¤í—˜ ì‹¤í–‰
            result = self.run_single_experiment(config_file, exp_type)
            results.append(result)
            
            if result['status'] != 'success':
                failed_experiments.append(config_file.name)
            
            # ê²°ê³¼ ì €ì¥ (ì‹¤ì‹œê°„)
            self.save_results(results)
            
            print("-" * 60)
        
        # ìµœì¢… ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ‰ All experiments completed!")
        print(f"   Total: {len(results)}")
        print(f"   Successful: {len([r for r in results if r['status'] == 'success'])}")
        print(f"   Failed: {len(failed_experiments)}")
        
        if failed_experiments:
            print(f"\nâŒ Failed experiments:")
            for exp in failed_experiments:
                print(f"   - {exp}")
        
        return results
    
    def save_results(self, results):
        """ê²°ê³¼ ì €ì¥"""
        results_file = self.results_dir / "experiment_results.json"
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2)
    
    def create_sample_configs(self):
        """ìƒ˜í”Œ config íŒŒì¼ë“¤ ìƒì„±"""
        print("ğŸ“ Creating sample config files...")
        
        # ìƒ˜í”Œ 1: V2_1 ìŠ¤íƒ€ì¼
        sample_v2_1 = {
            'model_name': 'convnextv2_base.fcmae_ft_in22k_in1k_384',
            'criterion': 'CrossEntropyLoss',
            'optimizer_name': 'AdamW',
            'lr': 0.0001,
            'scheduler_name': 'CosineAnnealingWarmupRestarts',
            'scheduler_params': {
                'T_max': 5000,
                'max_lr': 0.0001,
                'min_lr': 0.00001,
                'warmup_steps': 5
            },
            'epochs': 8000,
            'batch_size': 32,
            'image_size': 384,
            'random_seed': 256,
            'n_folds': 0,
            'val_split_ratio': 0.15,
            'online_augmentation': True,
            'augmentation': {
                'eda': True,
                'dilation': True,
                'erosion': True
            },
            'dynamic_augmentation': {'enabled': False},
            'val_TTA': True,
            'test_TTA': True,
            'mixed_precision': True,
            'patience': 10,
            'norm_mean': [0.5, 0.5, 0.5],
            'norm_std': [0.5, 0.5, 0.5],
            'timm': {'activation': None},
            'wandb': {'project': 'my-experiments', 'log': True},
            'data_dir': './data',
            'train_data': 'train0705a.csv'
        }
        
        # ìƒ˜í”Œ 2: V2_2 ìŠ¤íƒ€ì¼ (Mixup)
        sample_v2_2_mixup = {
            'model_name': 'resnet50.tv2_in1k',
            'criterion': 'FocalLoss',
            'optimizer_name': 'AdamW',
            'lr': 0.001,
            'scheduler_name': 'CosineAnnealingLR',
            'scheduler_params': {'T_max': 50, 'max_lr': 0.001, 'min_lr': 0.00001},
            'epochs': 100,
            'batch_size': 32,
            'image_size': 384,
            'random_seed': 256,
            'n_folds': 0,
            'val_split_ratio': 0.15,
            'online_augmentation': True,
            'augmentation': {'eda': True},
            'online_aug': {'mixup': True, 'cutmix': False},
            'dynamic_augmentation': {'enabled': False},
            'val_TTA': False,
            'test_TTA': False,
            'mixed_precision': True,
            'patience': 10,
            'norm_mean': [0.5, 0.5, 0.5],
            'norm_std': [0.5, 0.5, 0.5],
            'timm': {'activation': None},
            'wandb': {'project': 'my-experiments', 'log': True},
            'data_dir': './data',
            'train_data': 'train0705a.csv'
        }
        
        # ìƒ˜í”Œ 3: V2_2 ìŠ¤íƒ€ì¼ (2-stage)
        sample_v2_2_2stage = {
            'model_name': 'efficientnet_b4.ra2_in1k',
            'criterion': 'CrossEntropyLoss',
            'optimizer_name': 'AdamW',
            'lr': 0.001,
            'scheduler_name': 'CosineAnnealingLR',
            'scheduler_params': {'T_max': 30, 'max_lr': 0.001, 'min_lr': 0.0001},
            'epochs': 30,
            'batch_size': 64,
            'image_size': 384,
            'random_seed': 256,
            'n_folds': 0,
            'val_split_ratio': 0.15,
            'two_stage': True,
            'online_augmentation': True,
            'augmentation': {'eda': False, 'easiest': True},
            'dynamic_augmentation': {'enabled': False},
            'val_TTA': False,
            'test_TTA': True,
            'mixed_precision': True,
            'patience': 5,
            'norm_mean': [0.5, 0.5, 0.5],
            'norm_std': [0.5, 0.5, 0.5],
            'timm': {'activation': None},
            'wandb': {'project': 'my-experiments', 'log': True},
            'data_dir': './data',
            'train_data': 'train0705a.csv'
        }
        
        # Stage 2 config for 2-stage learning
        sample_stage2 = {
            'model_name': 'efficientnet_b4.ra2_in1k',
            'criterion': 'FocalLoss',
            'optimizer_name': 'AdamW',
            'lr': 0.0001,
            'scheduler_name': 'CosineAnnealingLR',
            'scheduler_params': {'T_max': 20, 'max_lr': 0.0001, 'min_lr': 0.00001},
            'epochs': 20,
            'batch_size': 32,
            'image_size': 384,
            'random_seed': 256,
            'n_folds': 0,
            'val_split_ratio': 0.15,
            'two_stage': False,
            'online_augmentation': True,
            'augmentation': {'eda': False, 'middle': True},
            'online_aug': {'mixup': True, 'cutmix': False},
            'dynamic_augmentation': {'enabled': False},
            'val_TTA': True,
            'test_TTA': True,
            'mixed_precision': True,
            'patience': 5,
            'norm_mean': [0.5, 0.5, 0.5],
            'norm_std': [0.5, 0.5, 0.5],
            'timm': {'activation': None},
            'wandb': {'project': 'my-experiments', 'log': True},
            'data_dir': './data',
            'train_data': 'train0705a.csv'
        }
        
        # íŒŒì¼ ì €ì¥
        configs = [
            ('sample_v2_1_convnext.yaml', sample_v2_1),
            ('sample_v2_2_resnet_mixup.yaml', sample_v2_2_mixup),
            ('sample_v2_2_efficient_2stage.yaml', sample_v2_2_2stage),
            ('sample_v2_2_efficient_2stage_stage2.yaml', sample_stage2)
        ]
        
        for filename, config in configs:
            config_file = self.config_dir / filename
            with open(config_file, 'w') as f:
                yaml.dump(config, f, default_flow_style=False)
            print(f"   âœ… Created: {filename}")
        
        print(f"\nğŸ“‚ Sample configs created in: {self.config_dir}")
        print("   Edit these files to customize your experiments!")

def main():
    parser = argparse.ArgumentParser(description="Custom Config Sequential Runner")
    parser.add_argument('--config-dir', default='my_configs', help='Directory containing config files')
    parser.add_argument('--pattern', default='*.yaml', help='Pattern to match config files')
    parser.add_argument('--create-samples', action='store_true', help='Create sample config files')
    parser.add_argument('--create-order', action='store_true', help='Create execution order template')
    parser.add_argument('--dry-run', action='store_true', help='Show what would be executed')
    parser.add_argument('--single', help='Run single config file')
    
    args = parser.parse_args()
    
    runner = CustomConfigRunner(args.config_dir)
    
    if args.create_samples:
        runner.create_sample_configs()
        return
    
    if args.single:
        config_file = Path(args.config_dir) / args.single
        if config_file.exists():
            exp_type = runner.detect_experiment_type(config_file)
            runner.run_single_experiment(config_file, exp_type)
        else:
            print(f"âŒ Config file not found: {config_file}")
        return
    
    # Config íŒŒì¼ ìŠ¤ìº”
    config_files = runner.scan_configs(args.pattern)
    
    if not config_files:
        print("âŒ No config files found")
        print("ğŸ’¡ Use --create-samples to create sample config files")
        return
    
    if args.create_order:
        runner.create_execution_order_template(config_files)
        return
    
    if args.dry_run:
        print("\nğŸ” Dry run - would execute:")
        for i, config_file in enumerate(config_files, 1):
            exp_type = runner.detect_experiment_type(config_file)
            print(f"   {i}. {config_file.name} ({exp_type})")
        return
    
    # ì‹¤ì œ ì‹¤í–‰
    results = runner.run_all_experiments(config_files)
    print(f"\nğŸ“Š Results saved to: {runner.results_dir / 'experiment_results.json'}")

if __name__ == "__main__":
    main()
