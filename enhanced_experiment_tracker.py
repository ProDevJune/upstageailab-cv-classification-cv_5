"""
AIStages ì„œë²„ì™€ í†µí•©ëœ í™•ì¥ HPO ì‹¤í—˜ ì¶”ì  ì‹œìŠ¤í…œ
ê¸°ì¡´ experiment_tracker.pyë¥¼ í™•ì¥í•˜ì—¬ ëŒ€íšŒ ì„œë²„ ì ìˆ˜ê¹Œì§€ ì¶”ì 
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

class EnhancedExperimentTracker:
    """AIStages ì„œë²„ ì ìˆ˜ ì¶”ì ì´ í¬í•¨ëœ í™•ì¥ ì‹¤í—˜ ì¶”ì ê¸°"""
    
    def __init__(self, results_path: str = "experiment_results.csv"):
        self.results_path = Path(results_path)
        self.analysis_dir = Path("analysis_results")
        self.analysis_dir.mkdir(exist_ok=True)
        
        # í™•ì¥ëœ ê²°ê³¼ íŒŒì¼ (ê¸°ì¡´ + AIStages ì ìˆ˜)
        self.enhanced_results_path = Path("enhanced_experiment_results.csv")
        self._initialize_enhanced_results()
        
        print(f"ğŸ“Š í™•ì¥ ì‹¤í—˜ ì¶”ì ê¸° ì´ˆê¸°í™”: {self.results_path}")
    
    def _initialize_enhanced_results(self):
        """í™•ì¥ëœ ì‹¤í—˜ ê²°ê³¼ íŒŒì¼ ì´ˆê¸°í™”"""
        if not self.enhanced_results_path.exists():
            # ê¸°ì¡´ ì»¬ëŸ¼ + AIStages ê´€ë ¨ ì»¬ëŸ¼
            columns = [
                # ê¸°ì¡´ HPO ê²°ê³¼ ì»¬ëŸ¼ë“¤
                'experiment_id', 'timestamp', 'platform', 'device', 'status',
                'model_name', 'image_size', 'lr', 'batch_size', 'augmentation_level',
                'TTA', 'epochs_run', 'final_f1', 'val_accuracy', 'training_time_min',
                'config_path', 'model_path', 'submission_path', 'error_message',
                
                # AIStages ê´€ë ¨ ì»¬ëŸ¼ë“¤
                'aistages_submitted', 'submission_date', 'submission_time',
                'aistages_public_score', 'aistages_private_score', 
                'public_rank', 'private_rank',
                'score_difference_public', 'score_difference_private',
                'submission_notes', 'leaderboard_screenshot_path',
                
                # ë¶„ì„ ì»¬ëŸ¼ë“¤
                'local_server_correlation', 'overfitting_risk', 'recommended_for_ensemble'
            ]
            df = pd.DataFrame(columns=columns)
            df.to_csv(self.enhanced_results_path, index=False)
            print(f"ğŸ“Š í™•ì¥ ì‹¤í—˜ ê²°ê³¼ íŒŒì¼ ìƒì„±: {self.enhanced_results_path}")

    def sync_from_basic_results(self):
        """ê¸°ì¡´ experiment_results.csvì—ì„œ ë°ì´í„° ë™ê¸°í™”"""
        if not self.results_path.exists():
            print("âš ï¸ ê¸°ë³¸ ì‹¤í—˜ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        basic_df = pd.read_csv(self.results_path)
        enhanced_df = pd.read_csv(self.enhanced_results_path)
        
        # ìƒˆë¡œìš´ ì‹¤í—˜ë“¤ë§Œ ì¶”ê°€
        new_experiments = []
        for _, row in basic_df.iterrows():
            if row['experiment_id'] not in enhanced_df['experiment_id'].values:
                # ê¸°ë³¸ ë°ì´í„° + ë¹ˆ AIStages ì»¬ëŸ¼ë“¤
                enhanced_row = row.to_dict()
                enhanced_row.update({
                    'aistages_submitted': False,
                    'submission_date': None,
                    'submission_time': None,
                    'aistages_public_score': None,
                    'aistages_private_score': None,
                    'public_rank': None,
                    'private_rank': None,
                    'score_difference_public': None,
                    'score_difference_private': None,
                    'submission_notes': None,
                    'leaderboard_screenshot_path': None,
                    'local_server_correlation': None,
                    'overfitting_risk': 'unknown',
                    'recommended_for_ensemble': False
                })
                new_experiments.append(enhanced_row)
        
        if new_experiments:
            new_df = pd.DataFrame(new_experiments)
            enhanced_df = pd.concat([enhanced_df, new_df], ignore_index=True)
            enhanced_df.to_csv(self.enhanced_results_path, index=False)
            print(f"âœ… {len(new_experiments)}ê°œ ìƒˆ ì‹¤í—˜ ë™ê¸°í™” ì™„ë£Œ")

    def submit_to_aistages(self, experiment_id: str, submission_notes: str = "") -> str:
        """AIStages ì œì¶œì„ ìœ„í•œ ì¤€ë¹„ ë° ì•ˆë‚´"""
        enhanced_df = pd.read_csv(self.enhanced_results_path)
        experiment = enhanced_df[enhanced_df['experiment_id'] == experiment_id]
        
        if experiment.empty:
            return f"âŒ ì‹¤í—˜ ID '{experiment_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        exp = experiment.iloc[0]
        submission_file = exp['submission_path']
        
        if pd.isna(submission_file) or not Path(submission_file).exists():
            return f"âŒ ì œì¶œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {submission_file}"
        
        # ì œì¶œ ì¤€ë¹„ ìƒíƒœë¡œ ë§ˆí‚¹
        enhanced_df.loc[enhanced_df['experiment_id'] == experiment_id, 'submission_notes'] = submission_notes
        enhanced_df.to_csv(self.enhanced_results_path, index=False)
        
        instructions = f"""
ğŸš€ AIStages ì œì¶œ ì¤€ë¹„ ì™„ë£Œ!

ğŸ“‹ ì‹¤í—˜ ì •ë³´:
  - ì‹¤í—˜ ID: {experiment_id}
  - ëª¨ë¸: {exp['model_name']}
  - ë¡œì»¬ F1: {exp['final_f1']:.4f}
  - ì œì¶œ íŒŒì¼: {submission_file}

ğŸ“¤ ì œì¶œ í›„ í•´ì•¼ í•  ì¼:
  1. AIStagesì—ì„œ ì ìˆ˜ í™•ì¸
  2. ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ê²°ê³¼ ê¸°ë¡:
     tracker.record_aistages_result(
         experiment_id="{experiment_id}",
         public_score=<ì„œë²„ì ìˆ˜>,
         public_rank=<ìˆœìœ„>,
         private_score=<ìµœì¢…ì ìˆ˜>,  # ì„ íƒ
         private_rank=<ìµœì¢…ìˆœìœ„>   # ì„ íƒ
     )

ğŸ’¡ ê¸°ë¡í•˜ì§€ ì•Šìœ¼ë©´ ë¡œì»¬-ì„œë²„ ì ìˆ˜ ë¶„ì„ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤!
        """
        
        return instructions

    def record_aistages_result(self, experiment_id: str, public_score: float,
                              public_rank: int = None, private_score: float = None,
                              private_rank: int = None, notes: str = None) -> None:
        """AIStages ì„œë²„ ì ìˆ˜ ê¸°ë¡"""
        enhanced_df = pd.read_csv(self.enhanced_results_path)
        exp_idx = enhanced_df[enhanced_df['experiment_id'] == experiment_id].index
        
        if len(exp_idx) == 0:
            print(f"âŒ ì‹¤í—˜ ID '{experiment_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        idx = exp_idx[0]
        local_f1 = enhanced_df.loc[idx, 'final_f1']
        
        # AIStages ê²°ê³¼ ì—…ë°ì´íŠ¸
        enhanced_df.loc[idx, 'aistages_submitted'] = True
        enhanced_df.loc[idx, 'submission_date'] = datetime.now().strftime("%Y-%m-%d")
        enhanced_df.loc[idx, 'submission_time'] = datetime.now().strftime("%H:%M:%S")
        enhanced_df.loc[idx, 'aistages_public_score'] = public_score
        enhanced_df.loc[idx, 'public_rank'] = public_rank
        
        if private_score is not None:
            enhanced_df.loc[idx, 'aistages_private_score'] = private_score
            enhanced_df.loc[idx, 'private_rank'] = private_rank
            enhanced_df.loc[idx, 'score_difference_private'] = private_score - local_f1
        
        # ì ìˆ˜ ì°¨ì´ ê³„ì‚°
        score_diff = public_score - local_f1
        enhanced_df.loc[idx, 'score_difference_public'] = score_diff
        
        # ê³¼ì í•© ìœ„í—˜ë„ í‰ê°€
        if score_diff < -0.05:
            enhanced_df.loc[idx, 'overfitting_risk'] = 'high'
        elif score_diff < -0.02:
            enhanced_df.loc[idx, 'overfitting_risk'] = 'medium'
        else:
            enhanced_df.loc[idx, 'overfitting_risk'] = 'low'
        
        if notes:
            existing_notes = enhanced_df.loc[idx, 'submission_notes']
            if pd.isna(existing_notes):
                enhanced_df.loc[idx, 'submission_notes'] = notes
            else:
                enhanced_df.loc[idx, 'submission_notes'] = f"{existing_notes} | {notes}"
        
        enhanced_df.to_csv(self.enhanced_results_path, index=False)
        
        # ìƒê´€ê´€ê³„ ì—…ë°ì´íŠ¸
        self._update_correlation_analysis()
        
        print(f"âœ… ì‹¤í—˜ {experiment_id} AIStages ê²°ê³¼ ê¸°ë¡ ì™„ë£Œ")
        print(f"   ë¡œì»¬ F1: {local_f1:.4f} â†’ ì„œë²„ ì ìˆ˜: {public_score:.4f} (ì°¨ì´: {score_diff:+.4f})")
        if public_rank:
            print(f"   ìˆœìœ„: {public_rank}ìœ„")

    def _update_correlation_analysis(self):
        """ì „ì²´ ì‹¤í—˜ì˜ ë¡œì»¬-ì„œë²„ ìƒê´€ê´€ê³„ ë¶„ì„"""
        enhanced_df = pd.read_csv(self.enhanced_results_path)
        submitted = enhanced_df[enhanced_df['aistages_submitted'] == True].copy()
        
        if len(submitted) < 2:
            return
        
        # ì „ì²´ ìƒê´€ê´€ê³„ ê³„ì‚°
        correlation = submitted['final_f1'].corr(submitted['aistages_public_score'])
        
        # ê° ì‹¤í—˜ì˜ ìƒê´€ê´€ê³„ ê¸°ì—¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)
        for idx in submitted.index:
            enhanced_df.loc[idx, 'local_server_correlation'] = correlation
        
        # ì•™ìƒë¸” ì¶”ì²œ ì—…ë°ì´íŠ¸
        self._update_ensemble_recommendations(enhanced_df, submitted)
        
        enhanced_df.to_csv(self.enhanced_results_path, index=False)

    def _update_ensemble_recommendations(self, enhanced_df: pd.DataFrame, submitted: pd.DataFrame):
        """ì•™ìƒë¸”ìš© ëª¨ë¸ ì¶”ì²œ ì—…ë°ì´íŠ¸"""
        if len(submitted) < 3:
            return
        
        # ìƒìœ„ 30% ë˜ëŠ” ìµœì†Œ 3ê°œ
        top_n = max(3, len(submitted) // 3)
        top_experiments = submitted.nlargest(top_n, 'aistages_public_score')
        
        # ì¶”ì²œ ê¸°ì¤€: ë†’ì€ ì„œë²„ ì ìˆ˜ + ë‚®ì€ ê³¼ì í•© ìœ„í—˜
        for idx in top_experiments.index:
            overfitting_risk = enhanced_df.loc[idx, 'overfitting_risk']
            if overfitting_risk in ['low', 'medium']:
                enhanced_df.loc[idx, 'recommended_for_ensemble'] = True

    def print_enhanced_summary(self):
        """í™•ì¥ëœ ì‹¤í—˜ ìš”ì•½ ì¶œë ¥"""
        self.sync_from_basic_results()  # ìµœì‹  ë°ì´í„° ë™ê¸°í™”
        
        enhanced_df = pd.read_csv(self.enhanced_results_path)
        submitted = enhanced_df[enhanced_df['aistages_submitted'] == True]
        
        print("\nğŸ¯ HPO + AIStages í†µí•© ì‹¤í—˜ ìš”ì•½")
        print("=" * 70)
        
        # ê¸°ë³¸ í†µê³„
        print(f"ğŸ“Š ì „ì²´ HPO ì‹¤í—˜: {len(enhanced_df)}ê°œ")
        print(f"ğŸ“¤ AIStages ì œì¶œ: {len(submitted)}ê°œ")
        print(f"ğŸ† ì™„ë£Œëœ ì‹¤í—˜: {len(enhanced_df[enhanced_df['status'] == 'completed'])}ê°œ")
        
        if len(submitted) > 0:
            print(f"\nğŸŒŸ AIStages ì„œë²„ ì„±ê³¼:")
            print(f"   ìµœê³  ì„œë²„ ì ìˆ˜: {submitted['aistages_public_score'].max():.4f}")
            print(f"   í‰ê·  ì„œë²„ ì ìˆ˜: {submitted['aistages_public_score'].mean():.4f}")
            best_rank = submitted['public_rank'].min() if 'public_rank' in submitted.columns and not submitted['public_rank'].isna().all() else 'N/A'
            print(f"   ìµœê³  ìˆœìœ„: {best_rank}")
            
            # ìƒê´€ê´€ê³„ ë¶„ì„
            if len(submitted) >= 2:
                correlation = submitted['final_f1'].corr(submitted['aistages_public_score'])
                mean_diff = submitted['score_difference_public'].mean()
                print(f"\nğŸ“ˆ ë¡œì»¬ vs ì„œë²„ ë¶„ì„:")
                print(f"   ìƒê´€ê´€ê³„: {correlation:.3f}")
                print(f"   í‰ê·  ì ìˆ˜ ì°¨ì´: {mean_diff:+.4f}")
                
                if correlation < 0.7:
                    print("   âš ï¸ ìƒê´€ê´€ê³„ê°€ ë‚®ìŠµë‹ˆë‹¤. Validation ì „ëµì„ ì¬ê²€í† í•˜ì„¸ìš”.")
                if mean_diff < -0.03:
                    print("   âš ï¸ ê³¼ì í•© ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.")
            
            # ê³¼ì í•© ìœ„í—˜ ë¶„ì„
            high_risk = len(submitted[submitted['overfitting_risk'] == 'high'])
            medium_risk = len(submitted[submitted['overfitting_risk'] == 'medium'])
            low_risk = len(submitted[submitted['overfitting_risk'] == 'low'])
            
            print(f"\nâš ï¸ ê³¼ì í•© ìœ„í—˜ ë¶„ì„:")
            print(f"   ë†’ìŒ: {high_risk}ê°œ, ë³´í†µ: {medium_risk}ê°œ, ë‚®ìŒ: {low_risk}ê°œ")
            
            # ì•™ìƒë¸” ì¶”ì²œ
            ensemble_candidates = enhanced_df[enhanced_df['recommended_for_ensemble'] == True]
            if len(ensemble_candidates) > 0:
                print(f"\nğŸ¯ ì•™ìƒë¸” ì¶”ì²œ: {len(ensemble_candidates)}ê°œ ëª¨ë¸")
                print("   ì‹¤í—˜ IDë“¤:", list(ensemble_candidates['experiment_id']))

    def get_submission_candidates(self, strategy: str = "diverse") -> pd.DataFrame:
        """ì œì¶œ í›„ë³´ ì‹¤í—˜ë“¤ ì¶”ì²œ"""
        enhanced_df = pd.read_csv(self.enhanced_results_path)
        completed = enhanced_df[enhanced_df['status'] == 'completed'].copy()
        not_submitted = completed[completed['aistages_submitted'] != True]
        
        if len(not_submitted) == 0:
            print("ğŸ“­ ì œì¶œí•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        if strategy == "best_local":
            # ë¡œì»¬ ì„±ëŠ¥ ê¸°ì¤€ ìƒìœ„
            candidates = not_submitted.nlargest(5, 'final_f1')
        elif strategy == "diverse":
            # ë‹¤ì–‘í•œ ì„¤ì • ì¡°í•©
            candidates = self._select_diverse_experiments(not_submitted)
        elif strategy == "conservative":
            # ê³¼ì í•© ìœ„í—˜ì´ ë‚®ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ì‹¤í—˜ë“¤
            candidates = self._select_conservative_experiments(not_submitted)
        else:
            candidates = not_submitted.nlargest(5, 'final_f1')
        
        return candidates[['experiment_id', 'final_f1', 'model_name', 'lr', 
                         'augmentation_level', 'TTA', 'submission_path']]

    def _select_diverse_experiments(self, df: pd.DataFrame) -> pd.DataFrame:
        """ë‹¤ì–‘í•œ ì„¤ì • ì¡°í•© ì„ íƒ"""
        # ëª¨ë¸ë³„ë¡œ ìµœê³  ì„±ëŠ¥ 1ê°œì”©
        diverse = []
        for model in df['model_name'].unique():
            model_experiments = df[df['model_name'] == model]
            best = model_experiments.nlargest(1, 'final_f1')
            diverse.append(best)
        
        result = pd.concat(diverse, ignore_index=True) if diverse else pd.DataFrame()
        return result.nlargest(5, 'final_f1')

    def _select_conservative_experiments(self, df: pd.DataFrame) -> pd.DataFrame:
        """ë³´ìˆ˜ì  ì‹¤í—˜ ì„ íƒ (ê³¼ì í•© ìœ„í—˜ ìµœì†Œí™”)"""
        # ê°„ë‹¨í•œ augmentation, ì ì ˆí•œ ì—í¬í¬ ìˆ˜
        conservative = df[
            (df['augmentation_level'].isin(['minimal', 'moderate'])) &
            (df['epochs_run'] < 70)  # ë„ˆë¬´ ë§ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ê²ƒë“¤
        ]
        return conservative.nlargest(5, 'final_f1')

    def create_submission_report(self, experiment_ids: List[str], 
                               output_path: str = "submission_report.html") -> None:
        """ì œì¶œìš© ì‹¤í—˜ ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        enhanced_df = pd.read_csv(self.enhanced_results_path)
        experiments = enhanced_df[enhanced_df['experiment_id'].isin(experiment_ids)]
        
        if len(experiments) == 0:
            print("âŒ í•´ë‹¹í•˜ëŠ” ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        html_content = f"""
        <html>
        <head>
            <title>AIStages ì œì¶œìš© ì‹¤í—˜ ë¦¬í¬íŠ¸</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                table {{ border-collapse: collapse; width: 100%; margin: 10px 0; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
                .best {{ background-color: #d4edda; }}
                .warning {{ background-color: #fff3cd; }}
            </style>
        </head>
        <body>
            <h1>ğŸš€ AIStages ì œì¶œìš© ì‹¤í—˜ ë¦¬í¬íŠ¸</h1>
            <p>ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            
            <h2>ğŸ“‹ ì„ íƒëœ ì‹¤í—˜ë“¤</h2>
            {experiments[['experiment_id', 'final_f1', 'val_accuracy', 'model_name', 
                         'lr', 'augmentation_level', 'TTA', 'epochs_run']].to_html(index=False)}
            
            <h2>ğŸ¯ ì œì¶œ ìˆœì„œ ì¶”ì²œ</h2>
            <ol>
        """
        
        # ì œì¶œ ìˆœì„œ ì¶”ì²œ (ë¡œì»¬ ì„±ëŠ¥ ê¸°ì¤€)
        sorted_experiments = experiments.sort_values('final_f1', ascending=False)
        for idx, (_, exp) in enumerate(sorted_experiments.iterrows(), 1):
            html_content += f"""
                <li>
                    <strong>{exp['experiment_id']}</strong> 
                    (F1: {exp['final_f1']:.4f}, {exp['model_name']})
                    <br>ì„¤ì •: lr={exp['lr']}, aug={exp['augmentation_level']}, TTA={exp['TTA']}
                    <br>ì œì¶œ íŒŒì¼: {exp['submission_path']}
                </li>
            """
        
        html_content += """
            </ol>
            
            <h2>ğŸ“ ì œì¶œ í›„ ì²´í¬ë¦¬ìŠ¤íŠ¸</h2>
            <ul>
                <li>âœ… AIStagesì—ì„œ Public Score í™•ì¸</li>
                <li>âœ… Leaderboard ìˆœìœ„ í™•ì¸</li>
                <li>âœ… Pythonìœ¼ë¡œ ê²°ê³¼ ê¸°ë¡:<br>
                    <code>tracker.record_aistages_result(experiment_id="...", public_score=0.xxxx, public_rank=xx)</code>
                </li>
                <li>âœ… ê°€ëŠ¥í•˜ë©´ ë¦¬ë”ë³´ë“œ ìŠ¤í¬ë¦°ìƒ· ì €ì¥</li>
            </ul>
            
        </body>
        </html>
        """
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"ğŸ“„ ì œì¶œìš© ë¦¬í¬íŠ¸ ìƒì„±: {output_path}")

    def analyze_best_strategies(self) -> Dict:
        """ìµœê³  ì„±ê³¼ë¥¼ ë‚¸ ì „ëµë“¤ ë¶„ì„"""
        enhanced_df = pd.read_csv(self.enhanced_results_path)
        submitted = enhanced_df[enhanced_df['aistages_submitted'] == True]
        
        if len(submitted) < 3:
            return {"message": "ë¶„ì„ì„ ìœ„í•œ ì œì¶œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."}
        
        # ìƒìœ„ 30% ì‹¤í—˜ë“¤ ë¶„ì„
        top_30_percent = submitted.nlargest(max(1, len(submitted) // 3), 'aistages_public_score')
        
        analysis = {
            "best_models": top_30_percent['model_name'].value_counts().to_dict(),
            "best_learning_rates": top_30_percent['lr'].value_counts().to_dict(),
            "best_image_sizes": top_30_percent['image_size'].value_counts().to_dict(),
            "best_augmentation": top_30_percent['augmentation_level'].value_counts().to_dict(),
            "best_tta_settings": top_30_percent['TTA'].value_counts().to_dict(),
            "correlation_insights": {
                "local_server_correlation": submitted['final_f1'].corr(submitted['aistages_public_score']),
                "overfitting_rate": len(submitted[submitted['overfitting_risk'] == 'high']) / len(submitted),
                "avg_score_difference": submitted['score_difference_public'].mean()
            }
        }
        
        return analysis

    def create_correlation_plot(self, save_path: str = "analysis_results/local_vs_server_correlation.png") -> None:
        """ë¡œì»¬ vs ì„œë²„ ì ìˆ˜ ìƒê´€ê´€ê³„ ì‹œê°í™”"""
        try:
            enhanced_df = pd.read_csv(self.enhanced_results_path)
            submitted = enhanced_df[enhanced_df['aistages_submitted'] == True]
            complete_data = submitted.dropna(subset=['final_f1', 'aistages_public_score'])
            
            if len(complete_data) < 2:
                print("ğŸ“Š ì‹œê°í™”ë¥¼ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                return
            
            plt.figure(figsize=(10, 8))
            
            # ì‚°ì ë„
            plt.scatter(complete_data['final_f1'], complete_data['aistages_public_score'], 
                       alpha=0.7, s=100)
            
            # ì‹¤í—˜ ID ë¼ë²¨
            for idx, row in complete_data.iterrows():
                plt.annotate(row['experiment_id'], 
                           (row['final_f1'], row['aistages_public_score']),
                           xytext=(5, 5), textcoords='offset points', fontsize=8)
            
            # ì¶”ì„¸ì„ 
            z = np.polyfit(complete_data['final_f1'], complete_data['aistages_public_score'], 1)
            p = np.poly1d(z)
            plt.plot(complete_data['final_f1'], p(complete_data['final_f1']), "r--", alpha=0.8)
            
            # ëŒ€ê°ì„  (ì™„ë²½í•œ ìƒê´€ê´€ê³„)
            min_val = min(complete_data['final_f1'].min(), complete_data['aistages_public_score'].min())
            max_val = max(complete_data['final_f1'].max(), complete_data['aistages_public_score'].max())
            plt.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, label='Perfect Correlation')
            
            # ìƒê´€ê³„ìˆ˜ í‘œì‹œ
            correlation = complete_data['final_f1'].corr(complete_data['aistages_public_score'])
            plt.title(f'Local vs AIStages Server Score Correlation\n(r = {correlation:.3f})', fontsize=14)
            plt.xlabel('Local Validation F1 Score', fontsize=12)
            plt.ylabel('AIStages Server Score', fontsize=12)
            plt.grid(True, alpha=0.3)
            plt.legend()
            
            plt.tight_layout()
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.show()
            
            print(f"ğŸ“Š ìƒê´€ê´€ê³„ ê·¸ë˜í”„ ì €ì¥: {save_path}")
            
        except Exception as e:
            print(f"âŒ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")


# ì‚¬ìš© ì˜ˆì‹œ ë° í†µí•© ê°€ì´ë“œ
if __name__ == "__main__":
    # í™•ì¥ ì¶”ì ê¸° ì´ˆê¸°í™”
    tracker = EnhancedExperimentTracker()
    
    print("ğŸš€ HPO + AIStages í†µí•© ì‹¤í—˜ ì¶”ì  ì‹œìŠ¤í…œ")
    print("=" * 50)
    
    # ê¸°ë³¸ ì‚¬ìš©ë²• ì¶œë ¥
    usage_guide = """
ğŸ”§ ê¸°ë³¸ ì‚¬ìš©ë²•:

1ï¸âƒ£ ê¸°ì¡´ HPO ì‹¤í—˜ ê²°ê³¼ ë™ê¸°í™”:
   tracker.sync_from_basic_results()

2ï¸âƒ£ ì œì¶œ í›„ë³´ í™•ì¸:
   candidates = tracker.get_submission_candidates(strategy="diverse")

3ï¸âƒ£ AIStages ì œì¶œ ì¤€ë¹„:
   instructions = tracker.submit_to_aistages("exp_quick_003_2507041446")

4ï¸âƒ£ ì„œë²„ ì ìˆ˜ ê¸°ë¡:
   tracker.record_aistages_result(
       experiment_id="exp_quick_003_2507041446",
       public_score=0.8756,
       public_rank=15
   )

5ï¸âƒ£ ì „ì²´ ìš”ì•½ í™•ì¸:
   tracker.print_enhanced_summary()

6ï¸âƒ£ ì œì¶œìš© ë¦¬í¬íŠ¸ ìƒì„±:
   tracker.create_submission_report(["exp_001", "exp_002"])
    """
    print(usage_guide)
