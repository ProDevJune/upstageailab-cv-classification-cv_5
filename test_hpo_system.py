#!/usr/bin/env python3
"""
HPO ì‹œìŠ¤í…œ ì§ì ‘ í…ŒìŠ¤íŠ¸
ë¬¸ì œ í•´ê²° ë²„ì „
"""

import sys
import os

print("ğŸ§ª HPO ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
print("=" * 50)

# ê¸°ë³¸ íŒ¨í‚¤ì§€ í™•ì¸
try:
    import yaml
    import torch
    import pandas as pd
    import numpy as np
    import psutil
    import platform
    print("âœ… ëª¨ë“  í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸ ì™„ë£Œ")
except ImportError as e:
    print(f"âŒ íŒ¨í‚¤ì§€ ì˜¤ë¥˜: {e}")
    exit(1)

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ pathì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

# í”Œë«í¼ ì •ë³´ ì§ì ‘ ìˆ˜ì§‘
print("\nğŸ–¥ï¸ ì‹œìŠ¤í…œ ì •ë³´")
print("=" * 50)

system_info = {
    'os': platform.system().lower(),
    'architecture': platform.machine().lower(),
    'python_version': platform.python_version(),
    'cpu_count': psutil.cpu_count(logical=True),
    'memory_gb': round(psutil.virtual_memory().total / (1024**3), 1)
}

print(f"OS: {system_info['os'].title()}")
print(f"ì•„í‚¤í…ì²˜: {system_info['architecture']}")
print(f"CPU ì½”ì–´: {system_info['cpu_count']}")
print(f"ë©”ëª¨ë¦¬: {system_info['memory_gb']} GB")
print(f"Python: {system_info['python_version']}")

# ë””ë°”ì´ìŠ¤ ê°ì§€
print("\nğŸš€ ì»´í“¨íŒ… ë””ë°”ì´ìŠ¤")
print("=" * 50)

device_info = {
    'cpu': True,
    'cuda': False,
    'mps': False,
    'primary_device': 'cpu'
}

if torch.cuda.is_available():
    device_info['cuda'] = True
    device_info['primary_device'] = 'cuda'
    print("CUDA ë””ë°”ì´ìŠ¤:")
    for i in range(torch.cuda.device_count()):
        name = torch.cuda.get_device_name(i)
        memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
        print(f"  - GPU {i}: {name} ({memory:.1f} GB)")

elif torch.backends.mps.is_available():
    device_info['mps'] = True
    device_info['primary_device'] = 'mps'
    print(f"MPS ë””ë°”ì´ìŠ¤: Apple Silicon ({system_info['memory_gb']} GB í†µí•© ë©”ëª¨ë¦¬)")
    
    # MPS í…ŒìŠ¤íŠ¸
    try:
        device = torch.device('mps')
        x = torch.randn(10, 10).to(device)
        print(f"âœ… MPS í…ì„œ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
    except Exception as e:
        print(f"âš ï¸ MPS í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

else:
    print("CPU ì „ìš© í™˜ê²½")

print(f"\nì£¼ ë””ë°”ì´ìŠ¤: {device_info['primary_device'].upper()}")

# ìµœì í™” ì„¤ì • ì¶”ì²œ
print("\nâš™ï¸ ê¶Œì¥ ì„¤ì •")
print("=" * 50)

if device_info['primary_device'] == 'mps':
    print("ğŸ Apple Silicon MPS ìµœì í™”:")
    print("  - ë°°ì¹˜ í¬ê¸°: 25 (80% ì¡°ì •)")
    print("  - ì›Œì»¤ ìˆ˜: 4")
    print("  - í˜¼í•© ì •ë°€ë„: False (MPS ì œí•œ)")
    print("  - ê¶Œì¥ HPO: Optuna ë² ì´ì§€ì•ˆ ìµœì í™”")
    
elif device_info['primary_device'] == 'cuda':
    print("ğŸš€ CUDA ìµœì í™”:")
    print("  - ë°°ì¹˜ í¬ê¸°: 48 (150% ì¡°ì •)")
    print("  - ì›Œì»¤ ìˆ˜: 8")
    print("  - í˜¼í•© ì •ë°€ë„: True")
    print("  - ê¶Œì¥ HPO: Ray Tune ë¶„ì‚° ìµœì í™”")
    
else:
    print("ğŸ’» CPU ìµœì í™”:")
    print("  - ë°°ì¹˜ í¬ê¸°: 16 (50% ì¡°ì •)")
    print(f"  - ì›Œì»¤ ìˆ˜: {system_info['cpu_count']}")
    print("  - í˜¼í•© ì •ë°€ë„: False")
    print("  - ê¶Œì¥ HPO: Basic Grid Search")

print("\nâœ… í”Œë«í¼ ê°ì§€ ë° ìµœì í™” ì™„ë£Œ!")
print("\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
print("  ./run_experiments.sh  # HPO ì‹œìŠ¤í…œ ì‹œì‘")

# ê°„ë‹¨í•œ ì„¤ì • íŒŒì¼ ìƒì„± í…ŒìŠ¤íŠ¸
try:
    test_config = {
        'platform': system_info['os'],
        'device': device_info['primary_device'],
        'batch_size': 25 if device_info['primary_device'] == 'mps' else 32,
        'mixed_precision': device_info['primary_device'] == 'cuda'
    }
    
    # YAML ì €ì¥ í…ŒìŠ¤íŠ¸
    with open('platform_test_config.yaml', 'w') as f:
        yaml.dump(test_config, f, default_flow_style=False)
    
    print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ ìƒì„±: platform_test_config.yaml")
    print("âœ… YAML íŒŒì¼ ìƒì„± í…ŒìŠ¤íŠ¸ ì„±ê³µ")
    
    # ì •ë¦¬
    os.remove('platform_test_config.yaml')
    
except Exception as e:
    print(f"âš ï¸ YAML í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
