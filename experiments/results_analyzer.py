#!/usr/bin/env python3
"""
ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ê¸°
ì™„ë£Œëœ ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ë¥¼ ì¢…í•© ë¶„ì„í•˜ê³  ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import os
import sys
import json
import argparse
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import matplotlib.pyplot as plt
import seaborn as sns


@dataclass
class ExperimentResult:
    """ì‹¤í—˜ ê²°ê³¼ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    experiment_id: str
    model: str
    technique: str
    local_f1: float
    local_acc: float
    training_time: float
    success: bool
    server_score: Optional[float] = None
    server_rank: Optional[int] = None
    performance_gap: Optional[float] = None


class ResultsAnalyzer:
    """ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, base_dir: str):
        self.base_dir = Path(base_dir)
        self.logs_dir = self.base_dir / "experiments" / "logs"
        self.results = self._load_all_results()
        
    def _load_all_results(self) -> List[ExperimentResult]:
        """ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¡œë“œ"""
        results = []
        
        if not self.logs_dir.exists():
            print("âš ï¸  ë¡œê·¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return results
        
        for log_file in self.logs_dir.glob("*.json"):
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                local_results = data.get('local_results', {})
                server_eval = data.get('server_evaluation', {})
                
                result = ExperimentResult(
                    experiment_id=data['experiment_id'],
                    model=data['model'],
                    technique=data['technique'],
                    local_f1=local_results.get('validation_f1', 0.0),
                    local_acc=local_results.get('validation_acc', 0.0),
                    training_time=local_results.get('training_time_minutes', 0.0),
                    success=data.get('success', False),
                    server_score=server_eval.get('server_score'),
                    server_rank=server_eval.get('server_rank'),
                    performance_gap=server_eval.get('performance_gap')
                )
                
                results.append(result)
                
            except Exception as e:
                print(f"âš ï¸  ë¡œê·¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {log_file}: {e}")
        
        return results
    
    def get_success_results(self) -> List[ExperimentResult]:
        """ì„±ê³µí•œ ì‹¤í—˜ë“¤ë§Œ ë°˜í™˜"""
        return [r for r in self.results if r.success]
    
    def generate_model_technique_matrix(self) -> pd.DataFrame:
        """ëª¨ë¸ë³„ ê¸°ë²• íš¨ê³¼ì„± ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±"""
        success_results = self.get_success_results()
        
        if not success_results:
            return pd.DataFrame()
        
        # ë°ì´í„° ì¤€ë¹„
        data = []
        for result in success_results:
            data.append({
                'model': result.model,
                'technique': result.technique,
                'f1_score': result.local_f1,
                'accuracy': result.local_acc,
                'training_time': result.training_time
            })
        
        df = pd.DataFrame(data)
        
        # í”¼ë²— í…Œì´ë¸” ìƒì„± (ëª¨ë¸ Ã— ê¸°ë²• with F1 ì ìˆ˜)
        matrix = df.pivot_table(
            index='model',
            columns='technique', 
            values='f1_score',
            aggfunc='mean'
        )
        
        return matrix
    
    def get_top_performers(self, top_k: int = 5) -> List[ExperimentResult]:
        """ìµœê³  ì„±ëŠ¥ ì¡°í•© TOP K ì¶”ì¶œ"""
        success_results = self.get_success_results()
        
        # F1 ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        success_results.sort(key=lambda x: x.local_f1, reverse=True)
        
        return success_results[:top_k]
    
    def analyze_performance_gaps(self) -> Dict:
        """ë¡œì»¬ vs ì„œë²„ ì„±ëŠ¥ ì°¨ì´ íŒ¨í„´ ë¶„ì„"""
        submitted_results = [r for r in self.results if r.server_score is not None]
        
        if not submitted_results:
            return {'message': 'ì„œë²„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.'}
        
        gaps = [r.performance_gap for r in submitted_results if r.performance_gap is not None]
        
        if not gaps:
            return {'message': 'ì„±ëŠ¥ ì°¨ì´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'}
        
        return {
            'total_count': len(submitted_results),
            'mean_gap': np.mean(gaps),
            'std_gap': np.std(gaps),
            'median_gap': np.median(gaps),
            'min_gap': np.min(gaps),
            'max_gap': np.max(gaps),
            'positive_ratio': len([g for g in gaps if g > 0]) / len(gaps),
            'model_gaps': self._analyze_gaps_by_model(submitted_results),
            'technique_gaps': self._analyze_gaps_by_technique(submitted_results)
        }
    
    def _analyze_gaps_by_model(self, results: List[ExperimentResult]) -> Dict:
        """ëª¨ë¸ë³„ ì„±ëŠ¥ ì°¨ì´ ë¶„ì„"""
        model_gaps = {}
        
        for result in results:
            if result.performance_gap is None:
                continue
                
            if result.model not in model_gaps:
                model_gaps[result.model] = []
            model_gaps[result.model].append(result.performance_gap)
        
        # í‰ê·  ê³„ì‚°
        for model in model_gaps:
            gaps = model_gaps[model]
            model_gaps[model] = {
                'mean_gap': np.mean(gaps),
                'count': len(gaps),
                'std_gap': np.std(gaps) if len(gaps) > 1 else 0
            }
        
        return model_gaps
    
    def _analyze_gaps_by_technique(self, results: List[ExperimentResult]) -> Dict:
        """ê¸°ë²•ë³„ ì„±ëŠ¥ ì°¨ì´ ë¶„ì„"""
        technique_gaps = {}
        
        for result in results:
            if result.performance_gap is None:
                continue
                
            if result.technique not in technique_gaps:
                technique_gaps[result.technique] = []
            technique_gaps[result.technique].append(result.performance_gap)
        
        # í‰ê·  ê³„ì‚°
        for technique in technique_gaps:
            gaps = technique_gaps[technique]
            technique_gaps[technique] = {
                'mean_gap': np.mean(gaps),
                'count': len(gaps),
                'std_gap': np.std(gaps) if len(gaps) > 1 else 0
            }
        
        return technique_gaps
    
    def calculate_roi_analysis(self) -> List[Dict]:
        """ROI (ì‹œê°„ ëŒ€ë¹„ ì„±ëŠ¥) ë¶„ì„"""
        success_results = self.get_success_results()
        
        roi_data = []
        for result in success_results:
            if result.training_time > 0:
                roi = result.local_f1 / (result.training_time / 60)  # ì‹œê°„ë‹¹ F1 ì ìˆ˜
                roi_data.append({
                    'experiment_id': result.experiment_id,
                    'model': result.model,
                    'technique': result.technique,
                    'f1_score': result.local_f1,
                    'training_hours': result.training_time / 60,
                    'roi': roi
                })
        
        # ROI ìˆœìœ¼ë¡œ ì •ë ¬
        roi_data.sort(key=lambda x: x['roi'], reverse=True)
        
        return roi_data
    
    def recommend_ensemble_candidates(self) -> Dict:
        """ì•™ìƒë¸” í›„ë³´ ì¶”ì²œ"""
        success_results = self.get_success_results()
        
        if len(success_results) < 2:
            return {'message': 'ì•™ìƒë¸”ì„ ìœ„í•œ ì¶©ë¶„í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.'}
        
        # ì„±ëŠ¥ ê¸°ë°˜ ì¶”ì²œ (ìƒìœ„ ì„±ëŠ¥)
        performance_based = sorted(success_results, key=lambda x: x.local_f1, reverse=True)[:5]
        
        # ë‹¤ì–‘ì„± ê¸°ë°˜ ì¶”ì²œ (ì„œë¡œ ë‹¤ë¥¸ ëª¨ë¸/ê¸°ë²• ì¡°í•©)
        diversity_based = []
        used_models = set()
        used_techniques = set()
        
        for result in performance_based:
            if result.model not in used_models or result.technique not in used_techniques:
                diversity_based.append(result)
                used_models.add(result.model)
                used_techniques.add(result.technique)
                
                if len(diversity_based) >= 3:
                    break
        
        return {
            'performance_based': [
                {
                    'experiment_id': r.experiment_id,
                    'model': r.model,
                    'technique': r.technique,
                    'f1_score': r.local_f1
                } for r in performance_based
            ],
            'diversity_based': [
                {
                    'experiment_id': r.experiment_id,
                    'model': r.model,
                    'technique': r.technique,
                    'f1_score': r.local_f1
                } for r in diversity_based
            ]
        }
    
    def generate_markdown_report(self) -> str:
        """ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = []
        
        # í—¤ë”
        report.append("# ğŸ”¬ ìë™ ì‹¤í—˜ ì‹œìŠ¤í…œ ê²°ê³¼ ë¶„ì„ ë¦¬í¬íŠ¸")
        report.append(f"")
        report.append(f"ìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"")
        
        # ì „ì²´ ìš”ì•½
        total_experiments = len(self.results)
        success_experiments = len(self.get_success_results())
        success_rate = (success_experiments / total_experiments * 100) if total_experiments > 0 else 0
        
        report.append("## ğŸ“Š ì „ì²´ ìš”ì•½")
        report.append(f"")
        report.append(f"- **ì´ ì‹¤í—˜ ìˆ˜**: {total_experiments}ê°œ")
        report.append(f"- **ì„±ê³µí•œ ì‹¤í—˜**: {success_experiments}ê°œ")
        report.append(f"- **ì„±ê³µë¥ **: {success_rate:.1f}%")
        report.append(f"")
        
        # ìµœê³  ì„±ëŠ¥ ê²°ê³¼
        top_performers = self.get_top_performers(5)
        if top_performers:
            report.append("## ğŸ† TOP 5 ìµœê³  ì„±ëŠ¥ ì¡°í•©")
            report.append(f"")
            for i, result in enumerate(top_performers, 1):
                report.append(f"{i}. **{result.experiment_id}**")
                report.append(f"   - ëª¨ë¸: {result.model}")
                report.append(f"   - ê¸°ë²•: {result.technique}")
                report.append(f"   - F1 ì ìˆ˜: {result.local_f1:.4f}")
                report.append(f"   - ì •í™•ë„: {result.local_acc:.4f}")
                report.append(f"   - í•™ìŠµ ì‹œê°„: {result.training_time:.1f}ë¶„")
                report.append(f"")
        
        # ëª¨ë¸ë³„ ê¸°ë²• íš¨ê³¼ì„± ë§¤íŠ¸ë¦­ìŠ¤
        matrix = self.generate_model_technique_matrix()
        if not matrix.empty:
            report.append("## ğŸ“ˆ ëª¨ë¸ë³„ ê¸°ë²• íš¨ê³¼ì„± ë§¤íŠ¸ë¦­ìŠ¤ (F1 ì ìˆ˜)")
            report.append(f"")
            report.append(matrix.to_markdown())
            report.append(f"")
        
        # ì„±ëŠ¥ ì°¨ì´ ë¶„ì„
        gap_analysis = self.analyze_performance_gaps()
        if 'message' not in gap_analysis:
            report.append("## ğŸ“Š ë¡œì»¬ vs ì„œë²„ ì„±ëŠ¥ ì°¨ì´ ë¶„ì„")
            report.append(f"")
            report.append(f"- **ì œì¶œëœ ì‹¤í—˜ ìˆ˜**: {gap_analysis['total_count']}ê°œ")
            report.append(f"- **í‰ê·  ì„±ëŠ¥ ì°¨ì´**: {gap_analysis['mean_gap']:+.4f}")
            report.append(f"- **ì„±ëŠ¥ í–¥ìƒ ë¹„ìœ¨**: {gap_analysis['positive_ratio']:.1%}")
            report.append(f"- **ìµœëŒ€ í–¥ìƒ**: {gap_analysis['max_gap']:+.4f}")
            report.append(f"- **ìµœëŒ€ í•˜ë½**: {gap_analysis['min_gap']:+.4f}")
            report.append(f"")
            
            # ëª¨ë¸ë³„ ì„±ëŠ¥ ì°¨ì´
            if gap_analysis['model_gaps']:
                report.append("### ëª¨ë¸ë³„ ì„±ëŠ¥ ì°¨ì´")
                report.append(f"")
                for model, data in gap_analysis['model_gaps'].items():
                    report.append(f"- **{model}**: {data['mean_gap']:+.4f} (n={data['count']})")
                report.append(f"")
            
            # ê¸°ë²•ë³„ ì„±ëŠ¥ ì°¨ì´
            if gap_analysis['technique_gaps']:
                report.append("### ê¸°ë²•ë³„ ì„±ëŠ¥ ì°¨ì´")
                report.append(f"")
                for technique, data in gap_analysis['technique_gaps'].items():
                    report.append(f"- **{technique}**: {data['mean_gap']:+.4f} (n={data['count']})")
                report.append(f"")
        
        # ROI ë¶„ì„
        roi_analysis = self.calculate_roi_analysis()
        if roi_analysis:
            report.append("## âš¡ ROI ë¶„ì„ (ì‹œê°„ ëŒ€ë¹„ ì„±ëŠ¥)")
            report.append(f"")
            report.append("ìƒìœ„ 5ê°œ íš¨ìœ¨ì ì¸ ì‹¤í—˜:")
            report.append(f"")
            for i, roi_data in enumerate(roi_analysis[:5], 1):
                report.append(f"{i}. **{roi_data['experiment_id']}**")
                report.append(f"   - ëª¨ë¸: {roi_data['model']}")
                report.append(f"   - ê¸°ë²•: {roi_data['technique']}")
                report.append(f"   - F1 ì ìˆ˜: {roi_data['f1_score']:.4f}")
                report.append(f"   - í•™ìŠµ ì‹œê°„: {roi_data['training_hours']:.1f}ì‹œê°„")
                report.append(f"   - ROI: {roi_data['roi']:.3f}")
                report.append(f"")
        
        # ì•™ìƒë¸” ì¶”ì²œ
        ensemble_candidates = self.recommend_ensemble_candidates()
        if 'message' not in ensemble_candidates:
            report.append("## ğŸ¤ ì•™ìƒë¸” í›„ë³´ ì¶”ì²œ")
            report.append(f"")
            
            report.append("### ì„±ëŠ¥ ê¸°ë°˜ ì¶”ì²œ")
            report.append(f"")
            for i, candidate in enumerate(ensemble_candidates['performance_based'], 1):
                report.append(f"{i}. {candidate['experiment_id']} - {candidate['model']} + {candidate['technique']} (F1: {candidate['f1_score']:.4f})")
            report.append(f"")
            
            report.append("### ë‹¤ì–‘ì„± ê¸°ë°˜ ì¶”ì²œ")
            report.append(f"")
            for i, candidate in enumerate(ensemble_candidates['diversity_based'], 1):
                report.append(f"{i}. {candidate['experiment_id']} - {candidate['model']} + {candidate['technique']} (F1: {candidate['f1_score']:.4f})")
            report.append(f"")
        
        # ê²°ë¡  ë° ì œì•ˆ
        report.append("## ğŸ’¡ ê²°ë¡  ë° ì œì•ˆ")
        report.append(f"")
        
        if top_performers:
            best_result = top_performers[0]
            report.append(f"- **ìµœê³  ì„±ëŠ¥ ì¡°í•©**: {best_result.model} + {best_result.technique} (F1: {best_result.local_f1:.4f})")
        
        if roi_analysis:
            best_roi = roi_analysis[0]
            report.append(f"- **ìµœê³  íš¨ìœ¨ ì¡°í•©**: {best_roi['model']} + {best_roi['technique']} (ROI: {best_roi['roi']:.3f})")
        
        if 'message' not in gap_analysis and gap_analysis['positive_ratio'] > 0.5:
            report.append(f"- **ì„œë²„ ì„±ëŠ¥**: ëŒ€ë¶€ë¶„ì˜ ì‹¤í—˜ì—ì„œ ë¡œì»¬ ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒ í™•ì¸")
        
        report.append(f"- **ë‹¤ìŒ ë‹¨ê³„**: ìµœê³  ì„±ëŠ¥ ì¡°í•©ë“¤ë¡œ ì•™ìƒë¸” êµ¬ì„± ê¶Œì¥")
        report.append(f"")
        
        return "\n".join(report)
    
    def save_report(self, output_path: str = None) -> str:
        """ë¦¬í¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = self.base_dir / "experiments" / f"analysis_report_{timestamp}.md"
        
        report_content = self.generate_markdown_report()
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        return str(output_path)
    
    def print_summary(self):
        """ìš”ì•½ ì •ë³´ ì¶œë ¥"""
        total_experiments = len(self.results)
        success_experiments = len(self.get_success_results())
        
        print("ğŸ”¬ ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ìš”ì•½")
        print("=" * 60)
        print(f"ğŸ“Š ì´ ì‹¤í—˜ ìˆ˜: {total_experiments}ê°œ")
        print(f"âœ… ì„±ê³µí•œ ì‹¤í—˜: {success_experiments}ê°œ")
        print(f"âŒ ì‹¤íŒ¨í•œ ì‹¤í—˜: {total_experiments - success_experiments}ê°œ")
        print(f"ğŸ“ˆ ì„±ê³µë¥ : {(success_experiments/total_experiments*100):.1f}%" if total_experiments > 0 else "ğŸ“ˆ ì„±ê³µë¥ : 0%")
        print()
        
        # ìµœê³  ì„±ëŠ¥ ê²°ê³¼
        top_performers = self.get_top_performers(3)
        if top_performers:
            print("ğŸ† TOP 3 ìµœê³  ì„±ëŠ¥:")
            for i, result in enumerate(top_performers, 1):
                print(f"   {i}. {result.experiment_id}")
                print(f"      {result.model} + {result.technique}")
                print(f"      F1: {result.local_f1:.4f}, ì •í™•ë„: {result.local_acc:.4f}")
            print()
        
        # ROI ë¶„ì„
        roi_analysis = self.calculate_roi_analysis()
        if roi_analysis:
            print("âš¡ ìµœê³  íš¨ìœ¨ ì‹¤í—˜:")
            best_roi = roi_analysis[0]
            print(f"   {best_roi['experiment_id']}")
            print(f"   {best_roi['model']} + {best_roi['technique']}")
            print(f"   ROI: {best_roi['roi']:.3f} (F1: {best_roi['f1_score']:.4f}, ì‹œê°„: {best_roi['training_hours']:.1f}h)")
            print()


def main():
    parser = argparse.ArgumentParser(description='ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ê¸°')
    parser.add_argument('--base-dir', '-d',
                       default='',
                       help='í”„ë¡œì íŠ¸ ê¸°ë³¸ ë””ë ‰í† ë¦¬')
    parser.add_argument('--generate-report', '-r', action='store_true',
                       help='ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±')
    parser.add_argument('--output', '-o',
                       help='ë¦¬í¬íŠ¸ ì¶œë ¥ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--summary-only', '-s', action='store_true',
                       help='ìš”ì•½ ì •ë³´ë§Œ ì¶œë ¥')
    
    args = parser.parse_args()
    
    try:
        # ë¶„ì„ê¸° ì´ˆê¸°í™”
        analyzer = ResultsAnalyzer(args.base_dir)
        
        if args.summary_only:
            analyzer.print_summary()
            return
        
        if args.generate_report:
            output_path = analyzer.save_report(args.output)
            print(f"ğŸ“‹ ë¶„ì„ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
        else:
            # ì½˜ì†”ì— ë¦¬í¬íŠ¸ ì¶œë ¥
            report = analyzer.generate_markdown_report()
            print(report)
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
