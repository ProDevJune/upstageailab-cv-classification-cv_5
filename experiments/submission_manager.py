#!/usr/bin/env python3
"""
ì œì¶œ ê´€ë¦¬ ì‹œìŠ¤í…œ (OCR ì§€ì› ë²„ì „)
ì‹¤í—˜ ê²°ê³¼ì˜ ì œì¶œ ìƒíƒœë¥¼ ê´€ë¦¬í•˜ê³  ì„œë²„ ê²°ê³¼ë¥¼ ì¶”ì í•©ë‹ˆë‹¤.
"""

import os
import sys
import json
import argparse
import yaml
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import pandas as pd


@dataclass
class SubmissionInfo:
    """ì œì¶œ ì •ë³´ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤ (OCR ì§€ì›)"""
    experiment_id: str
    model_name: str
    technique_name: str
    ocr_enabled: bool
    local_f1: float
    local_acc: float
    csv_path: str
    memo: str
    submission_ready: bool
    submitted: bool = False
    server_score: Optional[float] = None
    server_rank: Optional[int] = None
    performance_gap: Optional[float] = None


class SubmissionManager:
    """ì œì¶œ ê´€ë¦¬ í´ë˜ìŠ¤ (OCR ì§€ì›)"""
    
    def __init__(self, base_dir: str):
        self.base_dir = Path(base_dir)
        self.logs_dir = self.base_dir / "experiments" / "logs"
        self.submissions_dir = self.base_dir / "experiments" / "submissions"
        
        # ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ ë¡œë“œ
        self.experiment_results = self._load_all_experiment_results()
    
    def _load_all_experiment_results(self) -> List[Dict]:
        """ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ JSON íŒŒì¼ë“¤ì„ ë¡œë“œ"""
        results = []
        
        if not self.logs_dir.exists():
            return results
        
        for log_file in self.logs_dir.glob("*.json"):
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    result_data = json.load(f)
                    results.append(result_data)
            except Exception as e:
                print(f"âš ï¸  ë¡œê·¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {log_file}: {e}")
        
        return results
    
    def _get_submission_info_list(self) -> List[SubmissionInfo]:
        """ì œì¶œ ê°€ëŠ¥í•œ ì‹¤í—˜ë“¤ì˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸ ìƒì„±"""
        submissions = []
        
        for result in self.experiment_results:
            # ì„±ê³µí•œ ì‹¤í—˜ë§Œ ì²˜ë¦¬
            if not result.get('success', False):
                continue
            
            local_results = result.get('local_results', {})
            submission_data = result.get('submission', {})
            memo_data = result.get('memo_suggestion', {})
            server_data = result.get('server_evaluation', {})
            
            if not submission_data.get('submission_ready', False):
                continue
            
            # OCR ì •ë³´ ì¶”ì¶œ
            ocr_enabled = False
            if 'ocr' in result:
                ocr_enabled = result['ocr'].get('enabled', False)
            elif 'ocr_enabled' in result:
                ocr_enabled = result['ocr_enabled']
            elif '_ocr_' in result['experiment_id']:
                ocr_enabled = True
            
            submission_info = SubmissionInfo(
                experiment_id=result['experiment_id'],
                model_name=result['model'],
                technique_name=result['technique'],
                ocr_enabled=ocr_enabled,
                local_f1=local_results.get('validation_f1', 0.0),
                local_acc=local_results.get('validation_acc', 0.0),
                csv_path=submission_data.get('csv_path', ''),
                memo=memo_data.get('auto_generated', ''),
                submission_ready=submission_data.get('submission_ready', False),
                submitted=server_data.get('submitted', False),
                server_score=server_data.get('server_score'),
                server_rank=server_data.get('server_rank'),
                performance_gap=server_data.get('performance_gap')
            )
            
            submissions.append(submission_info)
        
        return submissions
    
    def list_pending_submissions(self) -> List[SubmissionInfo]:
        """ì œì¶œ ëŒ€ê¸° ì¤‘ì¸ ì‹¤í—˜ë“¤ì„ F1 ì ìˆ˜ ìˆœìœ¼ë¡œ ë°˜í™˜"""
        submissions = self._get_submission_info_list()
        
        # ì•„ì§ ì œì¶œí•˜ì§€ ì•Šì€ ê²ƒë“¤ë§Œ í•„í„°ë§
        pending = [s for s in submissions if not s.submitted]
        
        # F1 ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
        pending.sort(key=lambda x: x.local_f1, reverse=True)
        
        return pending
    
    def list_pending_by_ocr(self) -> Dict[str, List[SubmissionInfo]]:
        """OCR ì ìš© ì—¬ë¶€ë³„ë¡œ ì œì¶œ ëŒ€ê¸° ëª©ë¡ ë¶„ë¥˜"""
        pending = self.list_pending_submissions()
        
        ocr_submissions = [s for s in pending if s.ocr_enabled]
        no_ocr_submissions = [s for s in pending if not s.ocr_enabled]
        
        return {
            'ocr_enabled': ocr_submissions,
            'ocr_disabled': no_ocr_submissions
        }
    
    def get_submission_info(self, experiment_id: str) -> Optional[SubmissionInfo]:
        """íŠ¹ì • ì‹¤í—˜ì˜ ì œì¶œ ì •ë³´ ë°˜í™˜"""
        submissions = self._get_submission_info_list()
        
        for submission in submissions:
            if submission.experiment_id == experiment_id:
                return submission
        
        return None
    
    def add_server_result(self, experiment_id: str, score: float, 
                         rank: int, notes: str = "") -> bool:
        """ì„œë²„ ì±„ì  ê²°ê³¼ ì¶”ê°€"""
        # í•´ë‹¹ ì‹¤í—˜ì˜ ë¡œê·¸ íŒŒì¼ ì°¾ê¸°
        log_file = self.logs_dir / f"{experiment_id}.json"
        
        if not log_file.exists():
            print(f"âŒ ì‹¤í—˜ ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {experiment_id}")
            return False
        
        try:
            # ê¸°ì¡´ ê²°ê³¼ ë¡œë“œ
            with open(log_file, 'r', encoding='utf-8') as f:
                result_data = json.load(f)
            
            # ì„œë²„ ê²°ê³¼ ì—…ë°ì´íŠ¸
            server_evaluation = result_data.get('server_evaluation', {})
            server_evaluation.update({
                'submitted': True,
                'submission_date': datetime.now().isoformat(),
                'server_score': score,
                'server_rank': rank,
                'notes': notes
            })
            
            # ì„±ëŠ¥ ì°¨ì´ ê³„ì‚°
            local_f1 = result_data.get('local_results', {}).get('validation_f1', 0.0)
            if local_f1 > 0:
                performance_gap = score - local_f1
                server_evaluation['performance_gap'] = performance_gap
            
            result_data['server_evaluation'] = server_evaluation
            
            # íŒŒì¼ ì—…ë°ì´íŠ¸
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, indent=2, ensure_ascii=False)
            
            # OCR ì •ë³´ í‘œì‹œ
            ocr_info = ""
            if 'ocr' in result_data and result_data['ocr'].get('enabled', False):
                ocr_info = " (OCR ì ìš©)"
            elif '_ocr_' in experiment_id:
                ocr_info = " (OCR ì ìš©)"
            
            print(f"âœ… ì„œë²„ ê²°ê³¼ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤: {experiment_id}{ocr_info}")
            print(f"   ğŸ† ì„œë²„ ì ìˆ˜: {score:.4f}")
            print(f"   ğŸ“Š ìˆœìœ„: {rank}")
            if local_f1 > 0:
                gap = score - local_f1
                gap_str = f"+{gap:.4f}" if gap >= 0 else f"{gap:.4f}"
                print(f"   ğŸ“ˆ ì„±ëŠ¥ ì°¨ì´: {gap_str} (ë¡œì»¬ ëŒ€ë¹„)")
            
            return True
            
        except Exception as e:
            print(f"âŒ ì„œë²„ ê²°ê³¼ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False
    
    def print_pending_list(self):
        """ì œì¶œ ëŒ€ê¸° ëª©ë¡ ì¶œë ¥ (OCR ì •ë³´ í¬í•¨)"""
        pending = self.list_pending_submissions()
        
        if not pending:
            print("ğŸ“­ ì œì¶œ ëŒ€ê¸° ì¤‘ì¸ ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ğŸ“‹ ì œì¶œ ëŒ€ê¸° ì¤‘ì¸ ì‹¤í—˜ ({len(pending)}ê°œ)")
        print("=" * 110)
        print(f"{'ìˆœìœ„':<4} {'ì‹¤í—˜ ID':<30} {'ëª¨ë¸':<15} {'ê¸°ë²•':<12} {'OCR':<5} {'F1 ì ìˆ˜':<8} {'ì •í™•ë„':<8} {'ë©”ëª¨':<25}")
        print("-" * 110)
        
        for i, submission in enumerate(pending, 1):
            ocr_status = "ğŸ”¤" if submission.ocr_enabled else "ğŸ“·"
            print(f"{i:<4} {submission.experiment_id:<30} {submission.model_name:<15} "
                  f"{submission.technique_name:<12} {ocr_status:<5} {submission.local_f1:<8.4f} "
                  f"{submission.local_acc:<8.4f} {submission.memo:<25}")
        
        print("-" * 110)
        print(f"ğŸ† ìµœê³  ì„±ëŠ¥: {pending[0].experiment_id} (F1: {pending[0].local_f1:.4f})")
        
        # OCRë³„ í†µê³„
        ocr_pending = [s for s in pending if s.ocr_enabled]
        no_ocr_pending = [s for s in pending if not s.ocr_enabled]
        print(f"ğŸ”¤ OCR ì ìš©: {len(ocr_pending)}ê°œ")
        print(f"ğŸ“· OCR ë¯¸ì ìš©: {len(no_ocr_pending)}ê°œ")
    
    def print_pending_by_ocr(self):
        """OCRë³„ ì œì¶œ ëŒ€ê¸° ëª©ë¡ ì¶œë ¥"""
        ocr_groups = self.list_pending_by_ocr()
        
        print("ğŸ”¤ OCR ì ìš© ì‹¤í—˜ë“¤:")
        print("-" * 80)
        if ocr_groups['ocr_enabled']:
            for i, submission in enumerate(ocr_groups['ocr_enabled'][:5], 1):
                print(f"   {i}. {submission.experiment_id}")
                print(f"      {submission.model_name} + {submission.technique_name}")
                print(f"      F1: {submission.local_f1:.4f}")
        else:
            print("   ì—†ìŒ")
        
        print("\nğŸ“· OCR ë¯¸ì ìš© ì‹¤í—˜ë“¤:")
        print("-" * 80)
        if ocr_groups['ocr_disabled']:
            for i, submission in enumerate(ocr_groups['ocr_disabled'][:5], 1):
                print(f"   {i}. {submission.experiment_id}")
                print(f"      {submission.model_name} + {submission.technique_name}")
                print(f"      F1: {submission.local_f1:.4f}")
        else:
            print("   ì—†ìŒ")
    
    def print_submission_info(self, experiment_id: str):
        """íŠ¹ì • ì‹¤í—˜ì˜ ì œì¶œ ì •ë³´ ì¶œë ¥ (OCR ì •ë³´ í¬í•¨)"""
        submission = self.get_submission_info(experiment_id)
        
        if not submission:
            print(f"âŒ ì‹¤í—˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {experiment_id}")
            return
        
        ocr_icon = "ğŸ”¤" if submission.ocr_enabled else "ğŸ“·"
        print(f"ğŸ“Š ì‹¤í—˜ ì œì¶œ ì •ë³´: {ocr_icon} {experiment_id}")
        print("=" * 70)
        print(f"ğŸ¤– ëª¨ë¸: {submission.model_name}")
        print(f"ğŸ”§ ê¸°ë²•: {submission.technique_name}")
        print(f"ğŸ”¤ OCR: {'ì ìš©ë¨' if submission.ocr_enabled else 'ë¯¸ì ìš©'}")
        print(f"ğŸ“ˆ ë¡œì»¬ F1 ì ìˆ˜: {submission.local_f1:.4f}")
        print(f"ğŸ“ˆ ë¡œì»¬ ì •í™•ë„: {submission.local_acc:.4f}")
        print(f"ğŸ“„ CSV íŒŒì¼: {submission.csv_path}")
        print(f"ğŸ“ ì œì¶œ ë©”ëª¨: {submission.memo}")
        print(f"ğŸ“‹ ì œì¶œ ì¤€ë¹„: {'âœ… ì™„ë£Œ' if submission.submission_ready else 'âŒ ë¯¸ì™„ë£Œ'}")
        
        if submission.submitted:
            print(f"ğŸ† ì„œë²„ ì ìˆ˜: {submission.server_score:.4f}")
            print(f"ğŸ¥‡ ì„œë²„ ìˆœìœ„: {submission.server_rank}")
            if submission.performance_gap is not None:
                gap_str = f"+{submission.performance_gap:.4f}" if submission.performance_gap >= 0 else f"{submission.performance_gap:.4f}"
                print(f"ğŸ“Š ì„±ëŠ¥ ì°¨ì´: {gap_str}")
        else:
            print(f"ğŸ“¤ ì œì¶œ ìƒíƒœ: ëŒ€ê¸° ì¤‘")
        
        print("=" * 70)
        print("ğŸ“‹ ì œì¶œ ëª…ë ¹ì–´:")
        print(f"   CSV íŒŒì¼ ê²½ë¡œ: {submission.csv_path}")
        print(f"   ì œì¶œ ë©”ëª¨: {submission.memo}")


def main():
    parser = argparse.ArgumentParser(description='ì œì¶œ ê´€ë¦¬ ì‹œìŠ¤í…œ (OCR ì§€ì›)')
    parser.add_argument('--base-dir', '-d',
                       default='',
                       help='í”„ë¡œì íŠ¸ ê¸°ë³¸ ë””ë ‰í† ë¦¬')
    
    # ì„œë¸Œì»¤ë§¨ë“œ ì„¤ì •
    subparsers = parser.add_subparsers(dest='command', help='ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´')
    
    # ì œì¶œ ëŒ€ê¸° ëª©ë¡
    subparsers.add_parser('list-pending', help='ì œì¶œ ëŒ€ê¸° ì¤‘ì¸ ì‹¤í—˜ë“¤ì„ F1 ì ìˆ˜ ìˆœìœ¼ë¡œ í‘œì‹œ')
    
    # OCRë³„ ì œì¶œ ëŒ€ê¸° ëª©ë¡
    subparsers.add_parser('list-pending-ocr', help='OCRë³„ë¡œ ì œì¶œ ëŒ€ê¸° ëª©ë¡ í‘œì‹œ')
    
    # íŠ¹ì • ì‹¤í—˜ ì •ë³´
    info_parser = subparsers.add_parser('get-submission-info', help='íŠ¹ì • ì‹¤í—˜ì˜ CSV ê²½ë¡œì™€ ì œì¶œ ë©”ëª¨ ì¶œë ¥')
    info_parser.add_argument('experiment_id', help='ì‹¤í—˜ ID')
    
    # ì„œë²„ ê²°ê³¼ ì¶”ê°€
    server_parser = subparsers.add_parser('add-server-result', help='ì„œë²„ ì±„ì  ê²°ê³¼ ì¶”ê°€')
    server_parser.add_argument('--experiment', required=True, help='ì‹¤í—˜ ID')
    server_parser.add_argument('--score', type=float, required=True, help='ì„œë²„ ì ìˆ˜')
    server_parser.add_argument('--rank', type=int, required=True, help='ì„œë²„ ìˆœìœ„')
    server_parser.add_argument('--notes', default='', help='ì¶”ê°€ ë©”ëª¨')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    try:
        # ì œì¶œ ê´€ë¦¬ì ì´ˆê¸°í™”
        manager = SubmissionManager(args.base_dir)
        
        if args.command == 'list-pending':
            manager.print_pending_list()
            
        elif args.command == 'list-pending-ocr':
            manager.print_pending_by_ocr()
            
        elif args.command == 'get-submission-info':
            manager.print_submission_info(args.experiment_id)
            
        elif args.command == 'add-server-result':
            success = manager.add_server_result(
                args.experiment, args.score, args.rank, args.notes
            )
            if not success:
                sys.exit(1)
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
