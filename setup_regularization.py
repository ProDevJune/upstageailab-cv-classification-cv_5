#!/usr/bin/env python3
"""
ì •ê·œí™” ê°•í™” ì„¤ì •ì„ ìœ„í•œ HPO ì„¤ì • ìƒì„±ê¸°
"""

import yaml
import numpy as np

def create_regularization_configs():
    """ë‹¤ì–‘í•œ ì •ê·œí™” ìˆ˜ì¤€ì˜ ì„¤ì • íŒŒì¼ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    print("ğŸ›¡ï¸ ì •ê·œí™” ê°•í™” ì„¤ì • ìƒì„±ê¸°")
    print("=" * 50)
    
    # ê¸°ë³¸ ì„¤ì • ë¡œë“œ
    with open('codes/config.yaml', 'r') as f:
        base_config = yaml.safe_load(f)
    
    regularization_levels = {
        'light': {
            'description': 'ê°€ë²¼ìš´ ì •ê·œí™”',
            'weight_decay': 1e-4,    # 10ë°° ì¦ê°€
            'dropout_rate': 0.3,     # ê¸°ë³¸ë³´ë‹¤ ì¦ê°€
            'label_smoothing': 0.1,   # ìƒˆë¡œ ì¶”ê°€
            'mixup_alpha': 0.2,      # MixUp ì¶”ê°€
            'cutmix_alpha': 1.0,     # CutMix ì¶”ê°€
        },
        'medium': {
            'description': 'ì¤‘ê°„ ì •ê·œí™”',
            'weight_decay': 5e-4,    # 50ë°° ì¦ê°€
            'dropout_rate': 0.4,     
            'label_smoothing': 0.15,  
            'mixup_alpha': 0.4,      
            'cutmix_alpha': 1.0,     
            'stochastic_depth': 0.1, # ìƒˆë¡œ ì¶”ê°€
        },
        'strong': {
            'description': 'ê°•í•œ ì •ê·œí™”',
            'weight_decay': 1e-3,    # 100ë°° ì¦ê°€
            'dropout_rate': 0.5,     
            'label_smoothing': 0.2,   
            'mixup_alpha': 0.6,      
            'cutmix_alpha': 1.0,     
            'stochastic_depth': 0.2,
            'ema_decay': 0.9999,     # EMA ì¶”ê°€
        }
    }
    
    for level, params in regularization_levels.items():
        config = base_config.copy()
        
        # ì •ê·œí™” íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
        config['weight_decay'] = params['weight_decay']
        config['experiment_id'] = f'exp_reg_{level}'
        config['experiment_type'] = f'regularization_{level}'
        
        # ìƒˆë¡œìš´ ì •ê·œí™” ì„¹ì…˜ ì¶”ê°€
        config['regularization'] = {
            'level': level,
            'description': params['description'],
            'dropout_rate': params['dropout_rate'],
            'label_smoothing': params.get('label_smoothing', 0.0),
            'stochastic_depth': params.get('stochastic_depth', 0.0),
            'ema_decay': params.get('ema_decay', None)
        }
        
        # ì¦ê°• ì„¹ì…˜ ì—…ë°ì´íŠ¸
        config['augmentation']['mixup'] = params.get('mixup_alpha', 0.0) > 0
        config['augmentation']['cutmix'] = params.get('cutmix_alpha', 0.0) > 0
        config['mixup_alpha'] = params.get('mixup_alpha', 0.0)
        config['cutmix_alpha'] = params.get('cutmix_alpha', 0.0)
        
        # íŒŒì¼ ì €ì¥
        filename = f'codes/config_reg_{level}.yaml'
        with open(filename, 'w') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"âœ… {filename} ìƒì„± ({params['description']})")

def explain_regularization_techniques():
    """ì •ê·œí™” ê¸°ë²•ë“¤ì„ ìì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤."""
    
    print(f"\nğŸ¯ ì •ê·œí™” ê¸°ë²•ë³„ ìƒì„¸ ì„¤ëª…:")
    print(f"=" * 60)
    
    techniques = {
        'Weight Decay (L2 ì •ê·œí™”)': {
            'concept': 'ê°€ì¤‘ì¹˜ê°€ ë„ˆë¬´ ì»¤ì§€ì§€ ì•Šë„ë¡ í˜ë„í‹° ë¶€ì—¬',
            'effect': 'ëª¨ë¸ì˜ ë³µì¡ë„ ê°ì†Œ, ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ',
            'example': 'loss = original_loss + Î» * ||weights||Â²',
            'values': '1e-5 â†’ 1e-3 (100ë°° ì¦ê°€)'
        },
        'Dropout': {
            'concept': 'í•™ìŠµ ì‹œ ì¼ë¶€ ë‰´ëŸ°ì„ ëœë¤í•˜ê²Œ ë¹„í™œì„±í™”',
            'effect': 'íŠ¹ì • ë‰´ëŸ°ì— ì˜ì¡´í•˜ì§€ ì•ŠëŠ” robustí•œ íŠ¹ì§• í•™ìŠµ',
            'example': '50% í™•ë¥ ë¡œ ë‰´ëŸ°ì„ 0ìœ¼ë¡œ ë§Œë“¦',
            'values': '0.2 â†’ 0.5 (ë” ë§ì€ ë‰´ëŸ° ë¹„í™œì„±í™”)'
        },
        'Label Smoothing': {
            'concept': 'Hard target (0,1)ì„ Soft target (0.1,0.9)ë¡œ ë³€ê²½',
            'effect': 'ê³¼ì‹ (overconfidence) ë°©ì§€, ì¼ë°˜í™” í–¥ìƒ',
            'example': '[0,0,1,0] â†’ [0.05,0.05,0.85,0.05]',
            'values': '0.0 â†’ 0.2 (20% ìŠ¤ë¬´ë”©)'
        },
        'MixUp': {
            'concept': 'ë‘ ì´ë¯¸ì§€ì™€ ë¼ë²¨ì„ ì„ í˜• ê²°í•©',
            'effect': 'ê²°ì • ê²½ê³„ ìŠ¤ë¬´ë”©, ìƒˆë¡œìš´ ë°ì´í„° ìƒì„± íš¨ê³¼',
            'example': 'new_img = Î±*img1 + (1-Î±)*img2',
            'values': 'Î± ~ Beta(0.2, 0.2) ë¶„í¬'
        },
        'CutMix': {
            'concept': 'í•œ ì´ë¯¸ì§€ì˜ ì¼ë¶€ë¥¼ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¡œ êµì²´',
            'effect': 'ì§€ì—­ì  íŠ¹ì§•ê³¼ ì „ì—­ì  íŠ¹ì§• ëª¨ë‘ í•™ìŠµ',
            'example': 'ì´ë¯¸ì§€ Aì˜ ì¼ë¶€ ì˜ì—­ì„ ì´ë¯¸ì§€ Bë¡œ ë®ê¸°',
            'values': 'Î±=1.0 (ë² íƒ€ ë¶„í¬ íŒŒë¼ë¯¸í„°)'
        },
        'Stochastic Depth': {
            'concept': 'í•™ìŠµ ì‹œ ì¼ë¶€ ë ˆì´ì–´ë¥¼ ëœë¤í•˜ê²Œ ê±´ë„ˆë›°ê¸°',
            'effect': 'ê¹Šì€ ë„¤íŠ¸ì›Œí¬ì˜ ê³¼ì í•© ë°©ì§€',
            'example': 'ResNetì˜ ì¼ë¶€ ë¸”ë¡ì„ í™•ë¥ ì ìœ¼ë¡œ skip',
            'values': '10-20% í™•ë¥ ë¡œ ë¸”ë¡ ìŠ¤í‚µ'
        }
    }
    
    for technique, info in techniques.items():
        print(f"\nğŸ“š {technique}:")
        print(f"   ğŸ’¡ ê°œë…: {info['concept']}")
        print(f"   ğŸ¯ íš¨ê³¼: {info['effect']}")
        print(f"   ğŸ“ ì˜ˆì‹œ: {info['example']}")
        print(f"   âš™ï¸  ì„¤ì •: {info['values']}")

def create_regularization_hpo():
    """ì •ê·œí™” íŒŒë¼ë¯¸í„°ë¥¼ í¬í•¨í•œ HPO ì„¤ì •ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    hpo_script = '''#!/usr/bin/env python3
"""
ì •ê·œí™” ê°•í™” HPO ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸
"""

import optuna
import yaml

def objective(trial):
    """ì •ê·œí™” íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ ìœ„í•œ ëª©ì  í•¨ìˆ˜"""
    
    # ì •ê·œí™” íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§
    params = {
        'weight_decay': trial.suggest_loguniform('weight_decay', 1e-5, 1e-2),
        'dropout_rate': trial.suggest_uniform('dropout_rate', 0.2, 0.6),
        'label_smoothing': trial.suggest_uniform('label_smoothing', 0.0, 0.3),
        'mixup_alpha': trial.suggest_uniform('mixup_alpha', 0.0, 0.8),
        'cutmix_alpha': trial.suggest_uniform('cutmix_alpha', 0.0, 2.0),
    }
    
    # ê¸°ë³¸ ì„¤ì • ë¡œë“œ
    with open('codes/config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    # ì •ê·œí™” íŒŒë¼ë¯¸í„° ì ìš©
    config.update(params)
    config['experiment_id'] = f"exp_reg_hpo_{trial.number:03d}"
    
    # ì‹¤ì œ í•™ìŠµ ì‹¤í–‰ (ì—¬ê¸°ì„œëŠ” mock)
    # f1_score = train_and_evaluate(config)
    
    # Mock F1 score (ì‹¤ì œë¡œëŠ” í•™ìŠµ ê²°ê³¼)
    import random
    f1_score = random.uniform(0.80, 0.94)
    
    return f1_score

def run_regularization_hpo():
    """ì •ê·œí™” ê°•í™” HPO ì‹¤í–‰"""
    
    print("ğŸš€ ì •ê·œí™” ê°•í™” HPO ì‹œì‘")
    
    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=20)
    
    print(f"\\nğŸ† ìµœê³  ì„±ê³¼:")
    print(f"   F1 Score: {study.best_value:.4f}")
    print(f"   íŒŒë¼ë¯¸í„°: {study.best_params}")
    
    return study.best_params

if __name__ == "__main__":
    best_params = run_regularization_hpo()
    print("\\nâœ… ì •ê·œí™” HPO ì™„ë£Œ!")
'''
    
    with open('regularization_hpo.py', 'w') as f:
        f.write(hpo_script)
    
    print(f"\nâœ… ì •ê·œí™” HPO ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: regularization_hpo.py")

if __name__ == "__main__":
    create_regularization_configs()
    explain_regularization_techniques()
    create_regularization_hpo()
    
    print(f"\nğŸš€ ì •ê·œí™” ê°•í™” ë‹¨ê³„:")
    print(f"1. python codes/gemini_main.py --config codes/config_reg_light.yaml")
    print(f"2. python codes/gemini_main.py --config codes/config_reg_medium.yaml") 
    print(f"3. python codes/gemini_main.py --config codes/config_reg_strong.yaml")
    print(f"4. python regularization_hpo.py (ê³ ê¸‰ ìµœì í™”)")
    print(f"5. ì„±ëŠ¥ ë¹„êµ í›„ ìµœì  ì •ê·œí™” ìˆ˜ì¤€ ì„ íƒ")
