# π”§ ν”λ«νΌ νΈν™μ„± μμ • μ™„λ£ λ³΄κ³ μ„

## β… μμ • μ™„λ£ μƒνƒ

### π― μμ •λ λ¬Έμ μ λ“¤

#### β μ΄μ „ λ¬Έμ μ  (μμ • μ „)
1. **Mixed Precision ν•λ“μ½”λ”©**
   ```python
   # π¨ CUDAλ΅ ν•λ“μ½”λ”© - MPSμ—μ„ μ¤λ¥ λ°μƒ
   with torch.amp.autocast(device_type='cuda', enabled=self.cfg.mixed_precision):
   ```

2. **GPU μΊμ‹ κ΄€λ¦¬ ν•λ“μ½”λ”©**  
   ```python
   # π¨ CUDA μ „μ© - MPSμ—μ„ μ‘λ™ν•μ§€ μ•μ
   torch.cuda.empty_cache()
   ```

#### β… μμ •λ ν•΄κ²°μ±… (μμ • ν›„)

### π”§ 1. gemini_train_v2.py μμ •μ‚¬ν•­

#### π—οΈ μ΄κΈ°ν™” κ°μ„  (__init__ λ©”μ„λ“)
```python
# π”§ ν”λ«νΌλ³„ Mixed Precision λ° μΊμ‹ κ΄€λ¦¬ μ„¤μ •
self.device_str = str(self.cfg.device)
self.is_cuda = self.device_str.startswith('cuda')
self.is_mps = self.device_str.startswith('mps') 
self.is_cpu = self.device_str == 'cpu'

# Mixed Precision μ„¤μ •: CUDAμ—μ„λ§ μ™„μ „ν μ§€μ›λ¨
self.use_mixed_precision = self.cfg.mixed_precision and self.is_cuda
if self.cfg.mixed_precision and not self.is_cuda:
    print(f"β οΈ Mixed Precisionμ€ CUDAμ—μ„λ§ μ™„μ „ν μ§€μ›λ©λ‹λ‹¤. ν„μ¬ device: {self.device_str}")
    print("β οΈ Mixed Precisionμ„ λΉ„ν™μ„±ν™”ν•©λ‹λ‹¤.")

# autocastμ© device_type μ„¤μ •
self.autocast_device_type = 'cuda' if self.is_cuda else None

# GradScalerλ” CUDAμ—μ„λ§ μ‚¬μ©
self.scaler = torch.amp.GradScaler(enabled=self.use_mixed_precision)
```

#### π§Ή μΊμ‹ κ΄€λ¦¬ ν•¨μ μ¶”κ°€
```python
def _clear_cache(self):
    """ν”λ«νΌλ³„ GPU/MPS μΊμ‹ λΉ„μ°κΈ°"""
    if self.is_cuda:
        torch.cuda.empty_cache()
    elif self.is_mps:
        # MPSλ” PyTorch 2.0+μ—μ„ torch.mps.empty_cache() μ§€μ›
        try:
            torch.mps.empty_cache()
        except AttributeError:
            # torch.mps.empty_cache()κ°€ μ—†λ” κ²½μ° (μ΄μ „ λ²„μ „)
            pass
    # CPUλ” μΊμ‹ λΉ„μΈ ν•„μ” μ—†μ
```

#### β΅ λ™μ  Mixed Precision μ²λ¦¬ (training_step)
```python
# π”§ ν”λ«νΌλ³„ Mixed Precision μ²λ¦¬
if self.use_mixed_precision and self.autocast_device_type:
    # CUDAμ—μ„λ§ Mixed Precision μ‚¬μ©
    with torch.amp.autocast(device_type=self.autocast_device_type, enabled=True):
        outputs = self.model(train_x)
        loss = self.criterion(outputs, train_y)
    self.scaler.scale(loss).backward()
    self.scaler.step(self.optimizer)
    self.scaler.update()
else:
    # MPS, CPU λλ” Mixed Precision λΉ„ν™μ„±ν™”μ‹ μΌλ° μ²λ¦¬
    outputs = self.model(train_x)
    loss = self.criterion(outputs, train_y)
    loss.backward()
    self.optimizer.step()

# π”§ ν”λ«νΌλ³„ λ©”λ¨λ¦¬ μΊμ‹ λΉ„μ°κΈ°
del train_x, train_y, outputs, loss
self._clear_cache()
```

### π”§ 2. gemini_evalute_v2.py μμ •μ‚¬ν•­

#### π§Ή μΊμ‹ κ΄€λ¦¬ ν—¬νΌ ν•¨μ μ¶”κ°€
```python
def _clear_device_cache(device):
    """ν”λ«νΌλ³„ GPU/MPS μΊμ‹ λΉ„μ°κΈ° ν—¬νΌ ν•¨μ"""
    device_str = str(device)
    if device_str.startswith('cuda'):
        torch.cuda.empty_cache()
    elif device_str.startswith('mps'):
        # MPSλ” PyTorch 2.0+μ—μ„ torch.mps.empty_cache() μ§€μ›
        try:
            torch.mps.empty_cache()
        except AttributeError:
            # torch.mps.empty_cache()κ°€ μ—†λ” κ²½μ° (μ΄μ „ λ²„μ „)
            pass
    # CPUλ” μΊμ‹ λΉ„μΈ ν•„μ” μ—†μ
```

#### π”§ tta_predict ν•¨μ μμ •
```python
# κΈ°μ΅΄: torch.cuda.empty_cache()
# μμ •: _clear_device_cache(device)
for transform_func in augs:
    augmented_image = transform_func(image=image)['image']
    augmented_image = augmented_image.to(device)
    augmented_image = augmented_image.unsqueeze(0)
    outputs = model(augmented_image)
    tta_preds.append(outputs.softmax(1).cpu().numpy())
    del augmented_image
    # π”§ ν”λ«νΌλ³„ λ©”λ¨λ¦¬ μΊμ‹ λΉ„μ°κΈ°
    _clear_device_cache(device)
```

---

## π“ ν”λ«νΌλ³„ νΈν™μ„± κ°μ„  κ²°κ³Ό

| ν™κ²½ | Device κ°μ§€ | Mixed Precision | GPU μΊμ‹ κ΄€λ¦¬ | μ „μ²΄ νΈν™μ„± |
|------|-------------|------------------|---------------|-------------|
| **Mac OS (MPS)** | β… μ •μƒ | β… μλ™ λΉ„ν™μ„±ν™” | β… MPS μΊμ‹ μ§€μ› | β… μ™„μ „ νΈν™ |
| **Ubuntu (CUDA)** | β… μ •μƒ | β… μ™„μ „ μ§€μ› | β… CUDA μΊμ‹ μ§€μ› | β… μ™„μ „ νΈν™ |
| **CPU ν™κ²½** | β… μ •μƒ | β… μλ™ λΉ„ν™μ„±ν™” | β… λ¶ν•„μ” νΈμ¶ μ κ±° | β… μ™„μ „ νΈν™ |

---

## π€ κ°μ„ λ νΉμ§•λ“¤

### π― 1. μ§€λ¥ν• Mixed Precision κ΄€λ¦¬
- **μλ™ κ°μ§€**: CUDAμ—μ„λ§ Mixed Precision ν™μ„±ν™”
- **μ•μ „ν• Fallback**: MPS/CPUμ—μ„ μλ™μΌλ΅ μΌλ° λ¨λ“λ΅ μ „ν™
- **μ‚¬μ©μ μ•λ¦Ό**: Mixed Precision λΉ„ν™μ„±ν™”μ‹ λ…ν™•ν• μ•λ‚΄ λ©”μ‹μ§€

### π§Ή 2. ν”λ«νΌλ³„ λ©”λ¨λ¦¬ κ΄€λ¦¬
- **CUDA**: `torch.cuda.empty_cache()` μ‚¬μ©
- **MPS**: `torch.mps.empty_cache()` μ‚¬μ© (PyTorch 2.0+)
- **CPU**: λ¶ν•„μ”ν• μΊμ‹ νΈμ¶ μ κ±°
- **ν•μ„ νΈν™μ„±**: μ΄μ „ PyTorch λ²„μ „μ—μ„λ„ μ•μ „ν•κ² μ‘λ™

### π”§ 3. λ™μ  ν™κ²½ μ μ‘
- **Runtime κ°μ§€**: μ‹¤ν–‰ μ‹μ μ— ν”λ«νΌ μλ™ κ°μ§€
- **μ„¤μ • μµμ ν™”**: κ° ν”λ«νΌμ— μµμ ν™”λ μ„¤μ • μλ™ μ μ©
- **μ—λ¬ λ°©μ§€**: ν”λ«νΌλ³„ νΈν™μ„± λ¬Έμ  μ‚¬μ „ μ°¨λ‹¨

---

## π§ ν…μ¤νΈ λ° κ²€μ¦

### π“‹ μ κ³µλ ν…μ¤νΈ λ„κµ¬
- **test_platform_compatibility.py**: μΆ…ν•© ν”λ«νΌ νΈν™μ„± ν…μ¤νΈ
  - Device μλ™ κ°μ§€ ν…μ¤νΈ
  - Mixed Precision νΈν™μ„± κ²€μ¦
  - μΊμ‹ κ΄€λ¦¬ ν•¨μ ν…μ¤νΈ
  - TrainModule μ΄κΈ°ν™” ν…μ¤νΈ

### π® μ‚¬μ© λ°©λ²•
```bash
# ν”λ«νΌ νΈν™μ„± ν…μ¤νΈ μ‹¤ν–‰
python test_platform_compatibility.py

# κΈ°μ΅΄ import ν…μ¤νΈ (μ„ νƒμ‚¬ν•­)
python test_v2_imports.py

# Mac OSμ—μ„ μ‹¤ν–‰
./run_code_v2.sh  # MPS μλ™ κ°μ§€

# Ubuntuμ—μ„ μ‹¤ν–‰  
./run_code_v2.sh  # CUDA μλ™ κ°μ§€
```

---

## π” μμ •λ νμΌ λ©λ΅

### β… μμ • μ™„λ£λ νμΌλ“¤
1. **codes/gemini_train_v2.py** 
   - νμΌ ν¬κΈ°: 14,456 bytes β†’ μ•½ 16,000+ bytes (ν”λ«νΌ νΈν™μ„± λ΅μ§ μ¶”κ°€)
   - Mixed Precision λ™μ  μ²λ¦¬ μ¶”κ°€
   - ν”λ«νΌλ³„ μΊμ‹ κ΄€λ¦¬ ν•¨μ μ¶”κ°€
   - μ΄κΈ°ν™” λ‹¨κ³„μ—μ„ ν”λ«νΌ μλ™ κ°μ§€

2. **codes/gemini_evalute_v2.py**
   - νμΌ ν¬κΈ°: 8,064 bytes β†’ μ•½ 8,500+ bytes (ν—¬νΌ ν•¨μ μ¶”κ°€)
   - TTA predictionμ—μ„ ν”λ«νΌλ³„ μΊμ‹ κ΄€λ¦¬
   - λ…λ¦½μ μΈ μΊμ‹ κ΄€λ¦¬ ν—¬νΌ ν•¨μ μ¶”κ°€

3. **test_platform_compatibility.py** (μƒλ΅ μƒμ„±)
   - μΆ…ν•©μ μΈ ν”λ«νΌ νΈν™μ„± ν…μ¤νΈ μ¤ν¬λ¦½νΈ
   - λ¨λ“  ν™κ²½μ—μ„ μ •μƒ μ‘λ™ κ²€μ¦

### β… μμ • λ¶ν•„μ” (μ΄λ―Έ μ¬λ°”λ¦„)
- **codes/gemini_main_v2.py**: Device μλ™ κ°μ§€ μ΄λ―Έ μ™„λ²½ κµ¬ν„
- **codes/gemini_utils_v2.py**: ν”λ«νΌ λ…λ¦½μ  κµ¬ν„
- **codes/gemini_augmentation_v2.py**: ν”λ«νΌ λ…λ¦½μ  κµ¬ν„
- **codes/config_v2.yaml**: μ„¤μ • νμΌ, ν”λ«νΌ λ¬΄κ΄€

---

## π’΅ μ‚¬μ©μλ¥Ό μ„ν• κ°€μ΄λ“

### π Mac OS μ‚¬μ©μ
```bash
# Mixed Precisionμ΄ μλ™μΌλ΅ λΉ„ν™μ„±ν™”λ©λ‹λ‹¤
./run_code_v2.sh
# μ¶λ ¥ μμ‹:
# β οΈ Mixed Precisionμ€ CUDAμ—μ„λ§ μ™„μ „ν μ§€μ›λ©λ‹λ‹¤. ν„μ¬ device: mps
# β οΈ Mixed Precisionμ„ λΉ„ν™μ„±ν™”ν•©λ‹λ‹¤.
# π”§ Device: mps
# π”§ Mixed Precision: Disabled
# π”§ AutoCast Device Type: None
```

### π§ Ubuntu μ‚¬μ©μ
```bash
# Mixed Precisionμ΄ μλ™μΌλ΅ ν™μ„±ν™”λ©λ‹λ‹¤
./run_code_v2.sh
# μ¶λ ¥ μμ‹:
# π”§ Device: cuda:0
# π”§ Mixed Precision: Enabled
# π”§ AutoCast Device Type: cuda
```

### π’» CPU μ‚¬μ©μ
```bash
# Mixed Precisionμ΄ μλ™μΌλ΅ λΉ„ν™μ„±ν™”λ©λ‹λ‹¤
./run_code_v2.sh
# μ¶λ ¥ μμ‹:
# β οΈ Mixed Precisionμ€ CUDAμ—μ„λ§ μ™„μ „ν μ§€μ›λ©λ‹λ‹¤. ν„μ¬ device: cpu
# β οΈ Mixed Precisionμ„ λΉ„ν™μ„±ν™”ν•©λ‹λ‹¤.
# π”§ Device: cpu
# π”§ Mixed Precision: Disabled
# π”§ AutoCast Device Type: None
```

---

## π κ²°λ΅ 

### β… λ‹¬μ„±λ λ©ν‘
- **μ™„μ „ν• ν”λ«νΌ νΈν™μ„±**: Mac OS (MPS) / Ubuntu (CUDA) / CPU λ¨λ“  ν™κ²½ μ§€μ›
- **μλ™ μµμ ν™”**: κ° ν”λ«νΌμ— λ§λ” μµμ  μ„¤μ • μλ™ μ μ©
- **μ•μ „ν• Fallback**: μ§€μ›λμ§€ μ•λ” κΈ°λ¥ μλ™ λΉ„ν™μ„±ν™”
- **μ‚¬μ©μ μΉν™”μ„±**: λ…ν™•ν• μƒνƒ λ©”μ‹μ§€μ™€ μ•λ‚΄

### π€ κ°μ„  ν¨κ³Ό
- **Mac OS**: MPS κ°€μ† μ™„μ „ μ§€μ›, Mixed Precision μ•μ „ λΉ„ν™μ„±ν™”
- **Ubuntu**: CUDA Mixed Precision μ™„μ „ μ§€μ›, μµμ  μ„±λ¥
- **CPU**: λ¶ν•„μ”ν• GPU νΈμ¶ μ κ±°, μ•μ •μ  μ‹¤ν–‰
- **κ°λ°μ**: ν”λ«νΌλ³„ λ¶„κΈ° μ½”λ“ μ‘μ„± λ¶ν•„μ”

### π― μµμΆ… μƒνƒ
**μ΄μ  cv-classification μ‹μ¤ν…μ΄ Mac OS / Ubuntu λ¨λ“  ν™κ²½μ—μ„ ν”λ«νΌμ— κ΄€κ³„μ—†μ΄ μ•μ „ν•κ³  μµμ ν™”λ μƒνƒλ΅ μ‹¤ν–‰λ©λ‹λ‹¤!**

**μ‚¬μ©λ²•:** μ–΄λ–¤ ν™κ²½μ—μ„λ“  λ‹¨μν `./run_code_v2.sh` μ‹¤ν–‰ν•λ©΄ μλ™μΌλ΅ μµμ  μ„¤μ •μ΄ μ μ©λ©λ‹λ‹¤.
