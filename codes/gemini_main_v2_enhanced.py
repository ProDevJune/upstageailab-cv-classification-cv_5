import sys
import os
import yaml
import random
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import torch.optim.lr_scheduler as lr_scheduler
import torch.nn.init as init
from torch.utils.data import Dataset, DataLoader, ConcatDataset, WeightedRandomSampler
from torchvision import transforms
import timm
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import wandb
from types import SimpleNamespace
import cv2
import albumentations as A
from albumentations.pytorch import ToTensorV2
from tqdm import tqdm
import copy
import time
from PIL import Image
from zoneinfo import ZoneInfo
from datetime import datetime
import argparse

#ğŸ“¢ í¬ë¡œìŠ¤ í”Œë«í¼ ìƒëŒ€ ê²½ë¡œ ì„¤ì •
# í˜„ì¬ íŒŒì¼ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ì°¾ê¸°
current_file_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_file_dir)  # codes/ ì˜ ìƒìœ„ ë””ë ‰í† ë¦¬
sys.path.insert(0, project_root)  # ìµœìš°ì„ ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€

# ìƒëŒ€ ê²½ë¡œë¡œ ëª¨ë“ˆ import
try:
    from codes.gemini_utils_v2 import *
    from codes.gemini_train_v2 import *
    from codes.gemini_augmentation_v2 import *
    from codes.gemini_evalute_v2 import *
except ImportError as e:
    print(f"âŒ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    print(f"í˜„ì¬ ë””ë ‰í† ë¦¬: {os.getcwd()}")
    print(f"í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
    print(f"Python ê²½ë¡œ: {sys.path[:3]}")
    raise

if __name__ == "__main__":
    # run ë³€ìˆ˜ë¥¼ ì „ì—­ ìŠ¤ì½”í”„ì—ì„œ ì´ˆê¸°í™”
    run = None
    
    try:
        # python íŒŒì¼ ì‹¤í–‰í•  ë•Œ config.yaml íŒŒì¼ ì´ë¦„ì„ ì…ë ¥ë°›ì•„ì„œ ì„¤ì • íŒŒì¼ì„ ì§€ì •í•œë‹¤.
        parser = argparse.ArgumentParser(description="Run deep learning training with specified configuration.")
        parser.add_argument(
            '--config',
            type=str,
            default='config_v2.yaml', # ê¸°ë³¸ê°’ ì„¤ì •
            help='Name of the configuration YAML file (e.g., config.yaml, experiment_A.yaml)'
        )
        parser.add_argument(
            '--config2', # 2-stage ëª¨ë¸ì„ ìœ„í•œ config
            type=str,
            default='config_v2_2.yaml', # ê¸°ë³¸ê°’ ì„¤ì •
            help='Name of the second configuration YAML file for 2-stage training'
        )
        
        args = parser.parse_args()

        # Yaml íŒŒì¼ ì½ê¸° - ìƒëŒ€ ê²½ë¡œ ì²˜ë¦¬
        config_path = args.config
        if not os.path.isabs(config_path):
            # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° codes/ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê²°í•©
            config_path = os.path.join(current_file_dir, config_path)
        
        cfg = load_config(config_path=config_path)
        
        # ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ë³€ê²½ (ìƒëŒ€ ê²½ë¡œ ì •ìƒ ì‘ë™)
        original_cwd = os.getcwd()
        os.chdir(project_root)
        print(f"ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
        # ëœë¤ì„± ì œì–´
        set_seed(cfg.random_seed)

        # device ì„¤ì •
        device = 'cpu'
        if torch.backends.mps.is_available():
            device = torch.device('mps')
        elif torch.cuda.is_available():
            device = torch.device('cuda')
        print("âš™ï¸ Device :",device)
        cfg.device = device
        CURRENT_TIME = datetime.now(ZoneInfo("Asia/Seoul")).strftime("%y%m%d%H%M")
        print(f"âŒš ì‹¤í—˜ ì‹œê°„: {CURRENT_TIME}")

        # W&B ì„¤ì •
        # ì¦ê°• ê¸°ë²• ë¬¸ìì—´ ìƒì„± ë¡œì§ ê°œì„ 
        aug_str_parts = ""
        if cfg.online_augmentation:
            aug_str_parts += "on"
            if hasattr(cfg, 'dynamic_augmentation') and cfg.dynamic_augmentation and cfg.dynamic_augmentation.get('enabled', False):
                aug_str_parts += "daug"                
            else:
                # ì¼ë°˜ augmentation ê¸°ë²•ë“¤ë§Œ ë‚˜ì—´
                aug_str_parts += "aug"
        else:
            aug_str_parts += "offaug"

        next_run_name = (
            f"{CURRENT_TIME}-"
            f"{cfg.model_name}-"
            f"opt_{cfg.optimizer_name}-"
            f"sch_{cfg.scheduler_name}-"
            f"img{cfg.image_size}-"
            f"es{cfg.patience}-"
            f"{aug_str_parts}-"  # ê°œì„ ëœ ì¦ê°• ë¬¸ìì—´
            f"cv{cfg.n_folds}-"
            f"2stage_{1 if getattr(cfg, 'two_stage', False) else 0}-" # 2-stage ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€
            f"clsaug_{1 if getattr(cfg, 'class_imbalance', False) else 0}-"
            f"vTTA_{1 if getattr(cfg, 'val_TTA', False) else 0}-"
            f"tTTA_{1 if getattr(cfg, 'test_TTA', False) else 0}-"
            f"MP_{1 if cfg.mixed_precision else 0}"
        )

        run = None 
        if hasattr(cfg, 'wandb') and cfg.wandb['log']:
            run = wandb.init(
                project=cfg.wandb['project'],
                name=next_run_name,
                config=vars(cfg),
            )

        ### submission í´ë” ìƒì„±
        # ëª¨ë¸ ì €ì¥, ì‹œê°í™” ê·¸ë˜í”„ ì €ì¥, submission íŒŒì¼ ë“±ë“± ì €ì¥ ìš©ë„
        submission_dir = os.path.join(cfg.data_dir, 'submissions', next_run_name)
        try:
            os.makedirs(submission_dir, exist_ok=False)
            # cfgì— ì¶”ê°€ 
            cfg.submission_dir = submission_dir
        except:
            raise ValueError("ê°™ì€ ì´ë¦„ì˜ submission í´ë”ê°€ ìˆìŠµë‹ˆë‹¤.", submission_dir)

        ### Data Load
        if hasattr(cfg, 'train_data'):
            df = pd.read_csv(os.path.join(cfg.data_dir, cfg.train_data))
        else:
            df = pd.read_csv(os.path.join(cfg.data_dir, "train.csv"))
            
        # Augmentation ì„¤ì •
        train_transforms, val_transform, val_tta_transform, test_tta_transform = get_augmentation(cfg, epoch=0)
        val_augmented_ids = []
        
        # Cross validation if n_folds >= 3
        if cfg.n_folds >= 3:            
            folds_es, folds_val_f1 = [], []

            skf = StratifiedKFold(n_splits=cfg.n_folds, shuffle=True, random_state=cfg.random_seed)
            for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['target'])):
                try:
                    train_losses_for_plot, val_losses_for_plot = [], []
                    train_acc_for_plot, val_acc_for_plot = [], []
                    train_f1_for_plot, val_f1_for_plot = [], []

                    print(f"===== FOLD {fold+1} =====")
                    print("="*20)
                    train_df, val_df = df.iloc[train_idx], df.iloc[val_idx]

                    trainer, fold_augmented_ids, fold_val_augmented_ids, val_df, val_loader = run_training_cycle(
                        train_df, val_df, cfg, run=None, train_transforms=train_transforms, val_transform=val_transform
                    ) # cross validation ì‹œì—ëŠ” wandbì— ê¸°ë¡í•˜ì§€ ì•ŠëŠ”ë‹¤.

                    # save fold results
                    train_losses_for_plot.append(trainer.train_losses_for_plot)
                    train_acc_for_plot.append(trainer.train_acc_for_plot)
                    train_f1_for_plot.append(trainer.train_f1_for_plot)
                    val_losses_for_plot.append(trainer.val_losses_for_plot)
                    val_acc_for_plot.append(trainer.val_acc_for_plot)
                    val_f1_for_plot.append(trainer.val_f1_for_plot)

                    # fold early stopped moment
                    folds_es.append(trainer.es.best_loss_epoch)

                    # evaluate
                    val_preds, val_f1 = do_validation(
                        df=val_df,
                        model=trainer.model,
                        data=val_loader,
                        transform_func=val_tta_transform,
                        cfg=cfg,
                        run=None,
                        show=False,
                        savepath=os.path.join(cfg.submission_dir, f"val_confusion_matrix{'_TTA' if getattr(cfg, 'val_TTA', False) else ''}_Fold{fold}.png")
                    )
                    folds_val_f1.append(val_f1)
                finally:
                    delete_offline_augmented_images(cfg=cfg, augmented_ids=fold_augmented_ids)
                    delete_offline_augmented_images(cfg=cfg, augmented_ids=fold_val_augmented_ids)
                
                print("="*20)
                print("="*20)

            # out of cross-validation
            # 1. plot
            # 2. print average val f1
            # 3. set epoch
            # 4. train whole dataset & make final model
            plot_cross_validation(train_losses_for_plot, val_losses_for_plot, "Loss", cfg, show=False)
            plot_cross_validation(train_acc_for_plot, val_acc_for_plot, "Accuracy", cfg, show=False)
            plot_cross_validation(train_f1_for_plot, val_f1_for_plot, "F1-score", cfg, show=False)
            best_epoch = int(np.mean(folds_es))
            print(f"ğŸ“¢  Avg F1: {np.mean(folds_val_f1):.5f}, Best Epoch: {best_epoch}")
            # ì „ì²´ í•™ìŠµ.
            trainer, _, _, _, _ = run_training_cycle(
                df, None, cfg, run, train_transforms=train_transforms, val_transform=val_transform
            ) # ì „ì²´ train ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ í•™ìŠµ. val_df ì—†ìŒ.
            trainer.save_experiments(savepath=os.path.join(cfg.submission_dir, f'{next_run_name}.pth'))
            

        # No Cross Validation
        else:
            try:
                # Train-validation ë¶„í• 
                train_df, val_df = train_test_split(df, test_size=cfg.val_split_ratio, random_state=cfg.random_seed, stratify=df['target'] if cfg.stratify else None)
                
                trainer, augmented_ids, val_augmented_ids, val_df, val_loader = run_training_cycle(
                    train_df, val_df, cfg, run, train_transforms=train_transforms, val_transform=val_transform
                )

                ### Save Model
                trainer.save_experiments(savepath=os.path.join(cfg.submission_dir, f'{next_run_name}.pth'))
                ## í•™ìŠµ ê²°ê³¼ ì‹œê°í™” ì €ì¥.
                trainer.plot_loss(
                    show=False,
                    savewandb=cfg.wandb['log'],
                    savedir=cfg.submission_dir
                )

                ### Evaluate
                val_preds, val_f1 = do_validation(
                    df=val_df, 
                    model=trainer.model, 
                    # data=val_dataset_raw if cfg.val_TTA else val_loader, # online validation TTA
                    data = val_loader, # offline validation TTA
                    transform_func=val_tta_transform, 
                    cfg=cfg, 
                    run=run, 
                    show=False, 
                    savepath=os.path.join(cfg.submission_dir, f"val_confusion_matrix{'_TTA' if getattr(cfg, 'val_TTA', False) else ''}.png")
                )
                print("ğŸ“¢ Validation F1-score:",val_f1)
                
            finally:
                delete_offline_augmented_images(cfg=cfg, augmented_ids=augmented_ids)
                delete_offline_augmented_images(cfg=cfg, augmented_ids=val_augmented_ids)

            # Save incorrect validation results
            try:
                save_validation_images(val_df, val_preds, cfg, images_per_row=5, show=False)
            except:
                print("âš ï¸Saving incorrect validation results Failed...")

        # 2-stage í•™ìŠµ ì§€ì›
        if getattr(cfg, 'two_stage', False):
            print("ğŸš€ Starting 2-stage training...")
            
            # Load second config
            config2_path = args.config2
            if not os.path.isabs(config2_path):
                config2_path = os.path.join(current_file_dir, config2_path)
            
            cfg2 = load_config(config_path=config2_path)
            cfg2.device = device
            cfg2.submission_dir = submission_dir
            
            # Use the trained model as starting point for stage 2
            print("ğŸ“¢ Stage 2: Fine-tuning with different configuration...")
            
            # Reload data with new augmentation
            train_transforms2, val_transform2, val_tta_transform2, test_tta_transform2 = get_augmentation(cfg2, epoch=0)
            
            if cfg.n_folds >= 3:
                # For CV, train on full dataset for stage 2
                trainer_stage2, _, _, _, _ = run_training_cycle(
                    df, None, cfg2, run, train_transforms=train_transforms2, val_transform=val_transform2
                )
            else:
                # For single train/val split
                trainer_stage2, augmented_ids2, val_augmented_ids2, val_df2, val_loader2 = run_training_cycle(
                    train_df, val_df, cfg2, run, train_transforms=train_transforms2, val_transform=val_transform2
                )
                delete_offline_augmented_images(cfg=cfg2, augmented_ids=augmented_ids2)
                delete_offline_augmented_images(cfg=cfg2, augmented_ids=val_augmented_ids2)
            
            # Use stage 2 model for final inference
            trainer = trainer_stage2
            test_tta_transform = test_tta_transform2
            val_transform = val_transform2
            cfg = cfg2  # Use stage 2 config for final inference settings

        # Inference
        test_df = pd.read_csv(os.path.join(cfg.data_dir, "sample_submission.csv"))

        if getattr(cfg, 'test_TTA', getattr(cfg, 'TTA', False)):
            # For TTA, we need a loader with raw images
            raw_transform = A.Compose([
                ToTensorV2()
            ])
            test_dataset_raw = ImageDataset(test_df, os.path.join(cfg.data_dir, "test"), transform=raw_transform)
            test_loader_raw = DataLoader(test_dataset_raw, batch_size=cfg.batch_size, shuffle=False, num_workers=8, pin_memory=True)
            print("Running TTA on test set...")
            test_preds = tta_predict(trainer.model, test_dataset_raw, test_tta_transform, device, cfg, flag='test')
        else:
            test_dataset = ImageDataset(test_df, os.path.join(cfg.data_dir, "test"), transform=val_transform)
            test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size, shuffle=False, num_workers=8, pin_memory=True)
            print("Running inference on test set...")
            test_preds = predict(trainer.model, test_loader, device)

        print(pd.Series(test_preds).value_counts())
        pred_df = pd.read_csv(os.path.join(cfg.data_dir, "sample_submission.csv"))
        pred_df['target'] = test_preds

        # Submission
        sample_submission_df = pd.read_csv(os.path.join(cfg.data_dir, "sample_submission.csv"))
        assert (sample_submission_df['ID'] == pred_df['ID']).all(), "pred_dfì—ì„œ test ì´ë¯¸ì§€ê°€ ì•„ë‹Œ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤."
        assert set(pred_df['target']).issubset(set(range(17))), "target ì»¬ëŸ¼ì— 0~16 ì™¸ì˜ ê°’ì´ ìˆìŠµë‹ˆë‹¤."

        submission_path = os.path.join(cfg.submission_dir, f"{next_run_name}.csv")
        pred_df.to_csv(submission_path, index=False)
        print(f"ğŸ“¢Submission file saved to {submission_path}")

        ### prediction classë³„ ê°œìˆ˜
        try:
            class_counts = pred_df['target'].value_counts().sort_index()
            class_counts = class_counts.reset_index(drop=False)
            meta = pd.read_csv(os.path.join(cfg.data_dir, "meta.csv"))
            meta_dict = zip(meta['target'], meta['class_name'])
            meta_dict = dict(meta_dict)
            targets_class = list(map(lambda x: meta_dict[x], class_counts['target']))
            class_counts['meta'] = targets_class
            class_counts.to_csv(os.path.join(cfg.submission_dir, "submission_class_distribution.csv"), index=False)
        except Exception as e:
            print(e)

        if run:
            # Log submission artifact
            artifact = wandb.Artifact(f'submission-{next_run_name[:60]}...', type='submission')
            artifact.add_file(submission_path)
            run.log_artifact(artifact)
            run.finish()

    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        if 'run' in locals() and run:
            run.finish()
        raise

    finally:
        # ì‘ì—… ë””ë ‰í† ë¦¬ ë³µì›
        if 'original_cwd' in locals():
            os.chdir(original_cwd)
            
        if 'run' in locals() and run:
            run.finish()
        # augmented_idsê°€ ì •ì˜ëœ ê²½ìš°ì—ë§Œ ì‚­ì œ
        if 'augmented_ids' in locals() and augmented_ids:
            ### Offline Augmentation íŒŒì¼ ì‚­ì œ
            delete_offline_augmented_images(cfg=cfg, augmented_ids=augmented_ids)
        if 'val_augmented_ids' in locals() and val_augmented_ids:
            delete_offline_augmented_images(cfg=cfg, augmented_ids=val_augmented_ids)
