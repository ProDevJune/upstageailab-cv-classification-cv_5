# V2_1 with Mixup - ëŒ€íšŒ ìµœì í™” ì„¤ì •
# Configuration for the training process - v2_1 style with Mixup
model_name: 'convnextv2_base.fcmae_ft_in22k_in1k_384' # timm model name
pretrained: True
fine_tuning: "full"

# Loss Function
criterion: 'FocalLoss' # Mixupê³¼ ì˜ ì–´ìš¸ë¦¬ëŠ” FocalLoss
class_weighting: False
label_smooth: 0.0

# Optimizer
optimizer_name: 'AdamW'
lr: 0.0001
weight_decay: 0.00001

# Scheduler
scheduler_name: 'CosineAnnealingWarmupRestarts'
scheduler_params:
  T_max: 5000  # ë¹ ë¥¸ ì‹¤í—˜ì„ ìœ„í•´ ë‹¨ì¶•
  max_lr: 0.0001
  min_lr: 0.00001
  warmup_steps: 5
  gamma: 0.9

# Other variables
random_seed: 256
n_folds: 0
val_split_ratio: 0.15
stratify: True
image_size: 384

# Normalization
norm_mean: [0.5, 0.5, 0.5]
norm_std: [0.5, 0.5, 0.5]

# Techniques
weighted_random_sampler: False
class_imbalance: 
  aug_class: [1, 13, 14]
  max_samples: 78
offline_aug:
  max_samples: 500
online_augmentation: True

# ğŸ”¥ Mixup ì˜¨ë¼ì¸ ì¦ê°• ì„¤ì •
online_aug:
  mixup: True     # Mixup í™œì„±í™”
  cutmix: False   # CutMix ë¹„í™œì„±í™”  
  alpha: 0.4      # Mixup alpha íŒŒë¼ë¯¸í„°
  num_classes: 17 # í´ë˜ìŠ¤ ìˆ˜

augmentation:
  eda: True
  dilation: True
  erosion: True
  mixup: False  # ë ˆê±°ì‹œ ì„¤ì •
  cutmix: False

# Dynamic augmentation ë¹„í™œì„±í™” (Mixupì— ì§‘ì¤‘)
dynamic_augmentation:
  enabled: False

val_TTA: True
test_TTA: True
tta_dropout: False
mixed_precision: True

# Model hyperparameters
timm:
  activation: None
custom_layer: null

# Training hyperparameters
epochs: 50  # ğŸ”¥ ë¹ ë¥¸ ì‹¤í—˜ì„ ìœ„í•´ ë‹¨ì¶•
patience: 5
batch_size: 32

# W&B
wandb:
  project: "upstage-img-clf-mixup"
  log: True

# Paths
data_dir: "./data"
train_data: train0705a.csv
