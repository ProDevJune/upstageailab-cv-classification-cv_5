# V2_1 ë¹„êµêµ° - Mixup/CutMix ì—†ëŠ” ê¸°ë³¸ ì„¤ì •
# Configuration for the training process - v2_1 baseline (no mixup/cutmix)
model_name: 'convnextv2_base.fcmae_ft_in22k_in1k_384' # timm model name
pretrained: True
fine_tuning: "full"

# Loss Function
criterion: 'FocalLoss' # ë™ì¼í•œ ì¡°ê±´ìœ¼ë¡œ ë¹„êµ
class_weighting: False
label_smooth: 0.0

# Optimizer
optimizer_name: 'AdamW'
lr: 0.0001
weight_decay: 0.00001

# Scheduler
scheduler_name: 'CosineAnnealingWarmupRestarts'
scheduler_params:
  T_max: 5000
  max_lr: 0.0001
  min_lr: 0.00001
  warmup_steps: 5
  gamma: 0.9

# Other variables
random_seed: 256
n_folds: 0
val_split_ratio: 0.15
stratify: True
image_size: 384

# Normalization
norm_mean: [0.5, 0.5, 0.5]
norm_std: [0.5, 0.5, 0.5]

# Techniques
weighted_random_sampler: False
class_imbalance: 
  aug_class: [1, 13, 14]
  max_samples: 78
offline_aug:
  max_samples: 500
online_augmentation: True

# ğŸš« Mixup/CutMix ë¹„í™œì„±í™” (ë¹„êµêµ°)
online_aug:
  mixup: False    # Mixup ë¹„í™œì„±í™”
  cutmix: False   # CutMix ë¹„í™œì„±í™”
  alpha: 0.4      # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
  num_classes: 17

augmentation:
  eda: True
  dilation: True
  erosion: True
  mixup: False
  cutmix: False

dynamic_augmentation:
  enabled: False

val_TTA: True
test_TTA: True
tta_dropout: False
mixed_precision: True

# Model hyperparameters
timm:
  activation: None
custom_layer: null

# Training hyperparameters
epochs: 50  # ë™ì¼í•œ epochs
patience: 5
batch_size: 32

# W&B
wandb:
  project: "upstage-img-clf-baseline"
  log: True

# Paths
data_dir: "./data"
train_data: train0705a.csv
