"""
ê¸°ë³¸ HPO ìë™í™” ì‹¤í—˜ ì—”ì§„
Grid Search + Random Search ê¸°ë°˜
"""

import os
import sys
import yaml
import itertools
import random
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Any
import subprocess
import json
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from codes.platform_detector import PlatformDetector
from codes.enhanced_config_manager import EnhancedConfigManager

class BasicHPO:
    """ê¸°ë³¸ Grid Search + Random Search HPO"""
    
    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root) if project_root else Path(__file__).parent.parent
        self.detector = PlatformDetector()
        self.config_manager = EnhancedConfigManager(self.detector)
        self.results_file = self.project_root / "experiment_results.csv"
        self.practice_dir = self.project_root / "codes" / "practice"
        
        # ê²°ê³¼ íŒŒì¼ ì´ˆê¸°í™”
        self._initialize_results_file()
        
        print("ğŸ¯ ê¸°ë³¸ HPO ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        self.detector.print_system_summary()
    
    def _initialize_results_file(self):
        """ì‹¤í—˜ ê²°ê³¼ íŒŒì¼ ì´ˆê¸°í™”"""
        if not self.results_file.exists():
            columns = [
                'experiment_id', 'timestamp', 'platform', 'device', 'status',
                'model_name', 'image_size', 'lr', 'batch_size', 'augmentation_level',
                'TTA', 'epochs_run', 'final_f1', 'val_accuracy', 'training_time_min',
                'config_path', 'model_path', 'submission_path', 'error_message'
            ]
            df = pd.DataFrame(columns=columns)
            df.to_csv(self.results_file, index=False)
            print(f"ğŸ“Š ì‹¤í—˜ ê²°ê³¼ íŒŒì¼ ìƒì„±: {self.results_file}")
    
    def define_experiment_space(self, experiment_type: str = "quick") -> Dict:
        """ì‹¤í—˜ ê³µê°„ ì •ì˜"""
        
        # ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê³µê°„
        base_space = {
            'models': ['resnet34.tv_in1k', 'resnet50.tv2_in1k', 'efficientnet_b3.ra2_in1k'],
            'image_sizes': [224, 320, 384],
            'learning_rates': [0.001, 0.0001, 0.00001],
            'augmentation_levels': ['minimal', 'moderate', 'strong'],
            'TTA': [True, False]
        }
        
        # í”Œë«í¼ë³„ ì œí•œ ì ìš©
        device = self.detector.device_info['primary_device']
        
        if device == 'cpu':
            # CPU: ê°€ì¥ ì œí•œì 
            space = {
                'models': ['resnet34.tv_in1k'],
                'image_sizes': [224],
                'learning_rates': [0.0001, 0.00001],
                'augmentation_levels': ['minimal', 'moderate'],
                'TTA': [False]
            }
        elif device == 'mps':
            # MPS: ì¤‘ê°„ ì œí•œ
            space = {
                'models': ['resnet34.tv_in1k', 'resnet50.tv2_in1k'],
                'image_sizes': [224, 320],
                'learning_rates': base_space['learning_rates'],
                'augmentation_levels': base_space['augmentation_levels'],
                'TTA': [True, False]
            }
        else:
            # CUDA: ì „ì²´ ê³µê°„
            space = base_space
        
        # ì‹¤í—˜ íƒ€ì…ë³„ ì œí•œ
        if experiment_type == "quick":
            # ë¹ ë¥¸ ì‹¤í—˜: ë” ì œí•œì 
            space['learning_rates'] = space['learning_rates'][:2]  # ìƒìœ„ 2ê°œë§Œ
            space['TTA'] = [False]  # TTA ë¹„í™œì„±í™”ë¡œ ì†ë„ í–¥ìƒ
        
        return space
    
    def generate_experiments(self, experiment_type: str = "quick", 
                           max_experiments: int = 20, 
                           search_method: str = "smart_grid") -> List[str]:
        """ì‹¤í—˜ ì¡°í•© ìƒì„±"""
        
        space = self.define_experiment_space(experiment_type)
        
        if search_method == "grid":
            combinations = self._grid_search(space, max_experiments)
        elif search_method == "random":
            combinations = self._random_search(space, max_experiments)
        else:  # smart_grid
            combinations = self._smart_grid_search(space, max_experiments)
        
        config_files = []
        
        for i, combination in enumerate(combinations):
            # ì‹¤í—˜ ID ìƒì„±
            timestamp = datetime.now().strftime("%y%m%d%H%M")
            experiment_id = f"exp_{experiment_type}_{i+1:03d}_{timestamp}"
            
            # ê¸°ë³¸ ì„¤ì • ìƒì„±
            config = self.config_manager.generate_platform_config(experiment_type)
            
            # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš©
            config.update({
                'experiment_id': experiment_id,
                'model_name': combination['model'],
                'image_size': combination['image_size'],
                'lr': combination['lr'],
                'augmentation_level': combination['augmentation'],
                'TTA': combination['TTA'],
                'augmentation': self._get_augmentation_config(combination['augmentation'])
            })
            
            # ì„¤ì • íŒŒì¼ ì €ì¥
            config_filename = f"{experiment_id}.yaml"
            config_path = self.practice_dir / config_filename
            
            self.config_manager.save_config(config, str(config_path))
            config_files.append(str(config_path))
            
            print(f"ğŸ“ ì‹¤í—˜ ì„¤ì • ìƒì„±: {experiment_id}")
        
        print(f"âœ… ì´ {len(config_files)}ê°œ ì‹¤í—˜ ì„¤ì • ìƒì„± ì™„ë£Œ")
        return config_files
    
    def _grid_search(self, space: Dict, max_experiments: int) -> List[Dict]:
        """Grid Search ì¡°í•© ìƒì„±"""
        keys, values = zip(*space.items())
        combinations = list(itertools.product(*values))
        
        # ìµœëŒ€ ì‹¤í—˜ ìˆ˜ë¡œ ì œí•œ
        if len(combinations) > max_experiments:
            combinations = random.sample(combinations, max_experiments)
        
        return [
            {
                'model': combo[0],
                'image_size': combo[1], 
                'lr': combo[2],
                'augmentation': combo[3],
                'TTA': combo[4]
            }
            for combo in combinations
        ]
    
    def _random_search(self, space: Dict, max_experiments: int) -> List[Dict]:
        """Random Search ì¡°í•© ìƒì„±"""
        combinations = []
        
        for _ in range(max_experiments):
            combo = {
                'model': random.choice(space['models']),
                'image_size': random.choice(space['image_sizes']),
                'lr': random.choice(space['learning_rates']),
                'augmentation': random.choice(space['augmentation_levels']),
                'TTA': random.choice(space['TTA'])
            }
            combinations.append(combo)
        
        return combinations
    
    def _smart_grid_search(self, space: Dict, max_experiments: int) -> List[Dict]:
        """Smart Grid Search: ì¤‘ìš”í•œ íŒŒë¼ë¯¸í„° ìš°ì„  íƒìƒ‰"""
        
        # 1ë‹¨ê³„: ëª¨ë¸ + í•™ìŠµë¥  ì¡°í•© ìš°ì„ 
        important_combos = []
        for model in space['models']:
            for lr in space['learning_rates']:
                important_combos.append({
                    'model': model,
                    'image_size': space['image_sizes'][0],  # ê¸°ë³¸ í¬ê¸°
                    'lr': lr,
                    'augmentation': 'moderate',  # ê¸°ë³¸ ì¦ê°•
                    'TTA': False  # ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™”
                })
        
        # 2ë‹¨ê³„: ë‚˜ë¨¸ì§€ ê³µê°„ ëœë¤ ìƒ˜í”Œë§
        remaining_count = max_experiments - len(important_combos)
        if remaining_count > 0:
            additional_combos = self._random_search(space, remaining_count)
            important_combos.extend(additional_combos)
        
        return important_combos[:max_experiments]
    
    def _get_augmentation_config(self, level: str) -> Dict:
        """ì¦ê°• ë ˆë²¨ì— ë”°ë¥¸ ì„¤ì •"""
        configs = {
            'minimal': {
                'eda': True,
                'dilation': False,
                'erosion': False,
                'mixup': False,
                'cutmix': False
            },
            'moderate': {
                'eda': True,
                'dilation': True,
                'erosion': False,
                'mixup': False,
                'cutmix': False
            },
            'strong': {
                'eda': True,
                'dilation': True,
                'erosion': True,
                'mixup': True,
                'cutmix': False
            }
        }
        return configs.get(level, configs['moderate'])
    
    def run_single_experiment(self, config_path: str) -> Dict:
        """ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰"""
        
        # ì„¤ì • ë¡œë“œ
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        experiment_id = config['experiment_id']
        print(f"\nğŸš€ ì‹¤í—˜ ì‹œì‘: {experiment_id}")
        
        # ì‹¤í—˜ ê²°ê³¼ ì´ˆê¸°í™”
        result = {
            'experiment_id': experiment_id,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'platform': f"{self.detector.system_info['os']}_{self.detector.device_info['primary_device']}",
            'device': self.detector.device_info['primary_device'],
            'status': 'running',
            'config_path': config_path,
            'error_message': None
        }
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ê¸°ë¡
        result.update({
            'model_name': config.get('model_name'),
            'image_size': config.get('image_size'),
            'lr': config.get('lr'),
            'batch_size': config.get('batch_size'),
            'augmentation_level': config.get('augmentation_level'),
            'TTA': config.get('TTA'),
        })
        
        start_time = time.time()
        
        try:
            # ì‹¤ì œ gemini_main.py ì‹¤í–‰
            print(f"   ëª¨ë¸: {config['model_name']}")
            print(f"   ì´ë¯¸ì§€ í¬ê¸°: {config['image_size']}")
            print(f"   í•™ìŠµë¥ : {config['lr']}")
            print(f"   ì¦ê°• ë ˆë²¨: {config['augmentation_level']}")
            
            # ì‹¤ì œ í›ˆë ¨ ì‹¤í–‰
            print(f"   ğŸš€ ì‹¤ì œ í›ˆë ¨ ì‹œì‘...")
            
            # gemini_main.py ì‹¤í–‰ ëª…ë ¹ì–´
            cmd = f"cd {self.project_root} && python codes/gemini_main.py --config {config_path}"
            
            # subprocessë¡œ ì‹¤ì œ í›ˆë ¨ ì‹¤í–‰
            process = subprocess.run(
                cmd, 
                shell=True, 
                capture_output=True, 
                text=True,
                cwd=str(self.project_root)
            )
            
            if process.returncode != 0:
                raise Exception(f"Training failed: {process.stderr}")
            
            # í›ˆë ¨ ê²°ê³¼ íŒŒì‹± (ì‹¤ì œ ì¶œë ¥ì—ì„œ ì¶”ì¶œ)
            output = process.stdout
            
            # ê²°ê³¼ íŒŒì‹± (ê¸°ë³¸ê°’ ì„¤ì •)
            training_time = (time.time() - start_time) / 60
            final_f1 = self._extract_metric_from_output(output, 'f1', 0.75)
            val_accuracy = self._extract_metric_from_output(output, 'accuracy', 80.0)
            epochs_run = self._extract_metric_from_output(output, 'epochs', 50)
            
            print(f"   âœ… í›ˆë ¨ ì™„ë£Œ! ({training_time:.1f}ë¶„)")
            
            # ê²°ê³¼ ì—…ë°ì´íŠ¸
            result.update({
                'status': 'completed',
                'epochs_run': epochs_run,
                'final_f1': final_f1,
                'val_accuracy': val_accuracy,
                'training_time_min': training_time,
                'model_path': f"models/{experiment_id}.pth",
                'submission_path': f"data/submissions/{experiment_id}.csv"
            })
            
            print(f"âœ… ì‹¤í—˜ ì™„ë£Œ: F1={final_f1:.4f}, Acc={val_accuracy:.2f}%")
            
        except Exception as e:
            # ì‹¤í—˜ ì‹¤íŒ¨ ì²˜ë¦¬
            result.update({
                'status': 'failed',
                'training_time_min': (time.time() - start_time) / 60,
                'error_message': str(e)
            })
            print(f"âŒ ì‹¤í—˜ ì‹¤íŒ¨: {e}")
        
        # ê²°ê³¼ ì €ì¥
        self._save_experiment_result(result)
        
        return result
    
    def run_experiments(self, config_files: List[str], max_parallel: int = 1) -> List[Dict]:
        """ì‹¤í—˜ë“¤ ì‹¤í–‰"""
        
        print(f"\nğŸ¯ ì´ {len(config_files)}ê°œ ì‹¤í—˜ ì‹œì‘")
        print(f"   ë³‘ë ¬ ì‹¤í–‰: {max_parallel}ê°œ")
        print(f"   í”Œë«í¼: {self.detector.system_info['os']} + {self.detector.device_info['primary_device'].upper()}")
        
        results = []
        
        # í˜„ì¬ëŠ” ìˆœì°¨ ì‹¤í–‰ (ì¶”í›„ ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥)
        for i, config_path in enumerate(config_files):
            print(f"\nğŸ“Š ì§„í–‰ë¥ : {i+1}/{len(config_files)}")
            result = self.run_single_experiment(config_path)
            results.append(result)
            
            # ì„±ê³µë¥  ì²´í¬
            completed = sum(1 for r in results if r['status'] == 'completed')
            success_rate = completed / len(results) * 100
            print(f"   í˜„ì¬ ì„±ê³µë¥ : {success_rate:.1f}% ({completed}/{len(results)})")
        
        print(f"\nğŸ‰ ëª¨ë“  ì‹¤í—˜ ì™„ë£Œ!")
        print(f"   ì„±ê³µ: {sum(1 for r in results if r['status'] == 'completed')}ê°œ")
        print(f"   ì‹¤íŒ¨: {sum(1 for r in results if r['status'] == 'failed')}ê°œ")
        
        return results
    
    def _extract_metric_from_output(self, output: str, metric_name: str, default_value: float) -> float:
        """í›ˆë ¨ ì¶œë ¥ì—ì„œ ë©”íŠ¸ë¦­ ì¶”ì¶œ"""
        try:
            import re
            
            # F1 ì ìˆ˜ ì¶”ì¶œ
            if metric_name == 'f1':
                f1_pattern = r'f1[\s:=]+(\d+\.\d+)'
                matches = re.findall(f1_pattern, output, re.IGNORECASE)
                if matches:
                    return float(matches[-1])  # ë§ˆì§€ë§‰ ê°’ ì‚¬ìš©
            
            # ì •í™•ë„ ì¶”ì¶œ
            elif metric_name == 'accuracy':
                acc_pattern = r'acc[uracy]*[\s:=]+(\d+\.\d+)'
                matches = re.findall(acc_pattern, output, re.IGNORECASE)
                if matches:
                    return float(matches[-1])
            
            # ì—í¬í¬ ì¶”ì¶œ
            elif metric_name == 'epochs':
                epoch_pattern = r'epoch[\s:=]+(\d+)'
                matches = re.findall(epoch_pattern, output, re.IGNORECASE)
                if matches:
                    return int(matches[-1])
            
            return default_value
            
        except:
            return default_value
    
    def _save_experiment_result(self, result: Dict):
        """ì‹¤í—˜ ê²°ê³¼ ì €ì¥"""
        
        # CSVì— ì¶”ê°€
        df = pd.read_csv(self.results_file)
        new_row = pd.DataFrame([result])
        df = pd.concat([df, new_row], ignore_index=True)
        df.to_csv(self.results_file, index=False)
    
    def get_experiment_summary(self) -> Dict:
        """ì‹¤í—˜ ìš”ì•½ ì •ë³´"""
        
        if not self.results_file.exists():
            return {'total': 0, 'completed': 0, 'failed': 0, 'running': 0}
        
        df = pd.read_csv(self.results_file)
        
        if df.empty:
            return {'total': 0, 'completed': 0, 'failed': 0, 'running': 0}
        
        summary = {
            'total': len(df),
            'completed': len(df[df['status'] == 'completed']),
            'failed': len(df[df['status'] == 'failed']),
            'running': len(df[df['status'] == 'running']),
        }
        
        if summary['completed'] > 0:
            completed_df = df[df['status'] == 'completed']
            summary.update({
                'best_f1': completed_df['final_f1'].max(),
                'avg_f1': completed_df['final_f1'].mean(),
                'avg_training_time': completed_df['training_time_min'].mean()
            })
        
        return summary
    
    def get_top_experiments(self, n: int = 5) -> pd.DataFrame:
        """ìƒìœ„ Nê°œ ì‹¤í—˜ ì¡°íšŒ"""
        
        if not self.results_file.exists():
            return pd.DataFrame()
        
        df = pd.read_csv(self.results_file)
        completed_df = df[df['status'] == 'completed']
        
        if completed_df.empty:
            return pd.DataFrame()
        
        return completed_df.nlargest(n, 'final_f1')[
            ['experiment_id', 'model_name', 'image_size', 'lr', 'final_f1', 'val_accuracy', 'training_time_min']
        ]

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ê¸°ë³¸ HPO ì‹¤í–‰")
    parser.add_argument('--type', choices=['quick', 'full', 'targeted'], default='quick',
                        help='ì‹¤í—˜ íƒ€ì…')
    parser.add_argument('--max', type=int, default=20,
                        help='ìµœëŒ€ ì‹¤í—˜ ìˆ˜')
    parser.add_argument('--method', choices=['grid', 'random', 'smart_grid'], default='smart_grid',
                        help='íƒìƒ‰ ë°©ë²•')
    
    args = parser.parse_args()
    
    # HPO ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    hpo = BasicHPO()
    
    # ì‹¤í—˜ ìƒì„±
    config_files = hpo.generate_experiments(
        experiment_type=args.type,
        max_experiments=args.max,
        search_method=args.method
    )
    
    # ì‹¤í—˜ ì‹¤í–‰
    results = hpo.run_experiments(config_files)
    
    # ê²°ê³¼ ìš”ì•½
    summary = hpo.get_experiment_summary()
    print(f"\nğŸ“Š ì‹¤í—˜ ìš”ì•½:")
    for key, value in summary.items():
        print(f"   {key}: {value}")
    
    # ìƒìœ„ ì‹¤í—˜ ì¶œë ¥
    top_experiments = hpo.get_top_experiments(5)
    if not top_experiments.empty:
        print(f"\nğŸ† ìƒìœ„ 5ê°œ ì‹¤í—˜:")
        print(top_experiments.to_string(index=False))

if __name__ == "__main__":
    main()
