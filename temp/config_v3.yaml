# ğŸ† Phase 1 ê³ ê¸‰ ê¸°ë²• í†µí•© Configuration - v3 ì‹œìŠ¤í…œ
# ê¸°ì¡´ v2 ì‹œìŠ¤í…œ ê¸°ë°˜ìœ¼ë¡œ Focal Loss, Label Smoothing, CutMix/MixUp ì¶”ê°€

# Model Configuration
model_name: 'swin_base_patch4_window12_384.ms_in1k' # timm model name
pretrained: True # timm pretrained ê°€ì¤‘ì¹˜ ì‚¬ìš© ì—¬ë¶€
fine_tuning: "full" # fine-tuning ë°©ë²•ë¡ 
  # full : pretrained=True, pretrainedê°€ì¤‘ì¹˜ë¥¼ ì „ë¶€ ì¬í•™ìŠµì‹œí‚¨ë‹¤. 
  # head : pretrained=True, model backbone ë¶€ë¶„ì€ freezeí•˜ê³  head ë¶€ë¶„ì„ ì¬í•™ìŠµì‹œí‚¨ë‹¤.
  # custom : pretrained=True, backboneì—ì„œë„ ì¼ë¶€ë¶„ì„ ì¬í•™ìŠµì‹œí‚¨ë‹¤.
  # scratch : pretrained=False, ëª¨ë¸ êµ¬ì¡°ë§Œ ì‚¬ìš©í•˜ê³  ëª¨ë“  ê°€ì¤‘ì¹˜ë¥¼ ì²˜ìŒë¶€í„° í•™ìŠµì‹œí‚¨ë‹¤.

# ğŸ”¥ Phase 1 ê³ ê¸‰ ì†ì‹¤ í•¨ìˆ˜ ì„¤ì •
criterion: 'FocalLoss' # CrossEntropyLoss, FocalLoss, LabelSmoothingCrossEntropy
focal_loss:
  alpha: 1.0 # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ (Noneì´ë©´ ìë™ ê³„ì‚°)
  gamma: 2.0 # focusing parameter (í´ìˆ˜ë¡ hard exampleì— ë” ì§‘ì¤‘)
  reduction: 'mean'
label_smoothing:
  smoothing: 0.1 # 0.0ì´ë©´ ë¹„í™œì„±í™”, 0.1ì€ ì¼ë°˜ì ì¸ ê°’

# Optimizer
optimizer_name: 'AdamW'
lr: 0.0001 # 1e-4
weight_decay: 0.00001 # 1e-5

# Scheduler  
scheduler_name: 'CosineAnnealingLR'

# Other variables
random_seed: 256
n_folds: 0 # number of folds for cross-validation
val_split_ratio: 0.15 # train-val split ë¹„ìœ¨
stratify: True # validation set ë¶„í•  ì‹œ stratify ì „ëµ ì‚¬ìš© ì—¬ë¶€
image_size: 384 # ë§Œì•½ multi-scale train/test ì‹œ Noneìœ¼ë¡œ ì„¤ì •

# Normalization
norm_mean: [0.5, 0.5, 0.5]
norm_std: [0.5, 0.5, 0.5]

# Techniques
class_imbalance: 
  aug_class: [1, 13, 14]
  max_samples: 78
online_augmentation: True
augmentation: # normal augmentation
  eda: True
  dilation: False
  erosion: False
  # ğŸ”¥ Phase 1: CutMix & MixUp í™œì„±í™”
  mixup: True # MixUp í™œì„±í™”
  cutmix: True # CutMix í™œì„±í™”

# ğŸ”¥ Phase 1: CutMix & MixUp ê³ ê¸‰ ì„¤ì •
mixup_cutmix:
  mixup_alpha: 1.0 # MixUp mixing parameter (ë² íƒ€ ë¶„í¬ì˜ ì•ŒíŒŒ ê°’)
  cutmix_alpha: 1.0 # CutMix mixing parameter
  cutmix_minmax: null # CutMix ìµœì†Œ/ìµœëŒ€ ë¹„ìœ¨ ì œí•œ (nullì´ë©´ ë² íƒ€ ë¶„í¬ ì‚¬ìš©)
  prob: 0.5 # MixUp/CutMix ì ìš© í™•ë¥  (0.5ë©´ 50% í™•ë¥ ë¡œ ì ìš©)
  switch_prob: 0.5 # MixUpê³¼ CutMix ê°„ ì „í™˜ í™•ë¥  (0.5ë©´ ê°ê° 25% í™•ë¥ )
  mode: 'batch' # 'batch' ë˜ëŠ” 'elem' (ë°°ì¹˜ ë‹¨ìœ„ ë˜ëŠ” ìš”ì†Œ ë‹¨ìœ„ ì ìš©)
  correct_lam: True # lambda ë³´ì • (ì‹¤ì œ mixing ë¹„ìœ¨ë¡œ ì¡°ì •)
  label_smoothing: 0.1 # MixUp/CutMixìš© ë¼ë²¨ ìŠ¤ë¬´ë”©

# dynamic augmentationì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì¦ê°•ê¸°ë²•ì„ ë³€í™˜í•˜ëŠ” ë°©ë²•
dynamic_augmentation:
  enabled: True
  policies:
    weak:
      end_epoch: 5
      augs: ['basic']
    middle:
      end_epoch: 15
      augs: ['middle', 'mixup'] # ğŸ”¥ MixUp ì¶”ê°€
    strong:
      end_epoch: 300
      augs: ['aggressive','eda', 'cutmix'] # ğŸ”¥ CutMix ì¶”ê°€

val_TTA: True # Validation ì‹œ, Test Time Augmentation ì‚¬ìš© ì—¬ë¶€
test_TTA: True # Inference ì‹œ, Test Time Augmentation ì‚¬ìš© ì—¬ë¶€
tta_dropout: False # inference ì‹œì—ë„ model.train() ëª¨ë“œë¥¼ ì‚¬ìš©í•´ dropoutì„ í™œì„±í™”í•˜ëŠ” ë°©ë²•
mixed_precision: True # Mixed Precision í•™ìŠµ ì‚¬ìš© ì—¬ë¶€

# Model hyperparameters
timm:
  activation: None # ReLU, LeakyReLU, ELU, SELU, GELU, Tanh, PReLU, SiLU

custom_layer: # custom classifier headë¥¼ ì‚¬ìš©í•˜ê³  ì‹¶ì€ ê²½ìš° ì„¤ì •
  # head_type: "simple_dropout"
  # drop: 0.2
  # activation: 'GELU'

# Training hyperparameters
epochs: 10000 # max epoch
patience: 20 # early stopping patience
batch_size: 32 # image_size, model_size, GPU RAM ì— ë”°ë¼ OOMì´ ë°œìƒí•˜ì§€ ì•Šë„ë¡ ì„¤ì •.

# W&B
wandb:
  project: "upstage-img-clf-v3"
  log: False # log using wandb

# Paths
data_dir: "/Users/jayden/Developer/Projects/cv-classification/data"
