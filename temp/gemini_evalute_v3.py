import os
from tqdm import tqdm
import torch
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import f1_score, confusion_matrix
import wandb
import albumentations as A
import matplotlib.image as mpimg

def _clear_device_cache(device):
    """í”Œë«í¼ë³„ GPU/MPS ìºì‹œ ë¹„ìš°ê¸° í—¬í¼ í•¨ìˆ˜"""
    device_str = str(device)
    if device_str.startswith('cuda'):
        torch.cuda.empty_cache()
    elif device_str.startswith('mps'):
        # MPSëŠ” PyTorch 2.0+ì—ì„œ torch.mps.empty_cache() ì§€ì›
        try:
            torch.mps.empty_cache()
        except AttributeError:
            # torch.mps.empty_cache()ê°€ ì—†ëŠ” ê²½ìš° (ì´ì „ ë²„ì „)
            pass
    # CPUëŠ” ìºì‹œ ë¹„ìš¸ í•„ìš” ì—†ìŒ

def tta_predict(model, dataset, tta_transform, device, cfg, flag='val'):
    if cfg.tta_dropout:
        model.train()
    else:
        model.eval()
    predictions = []
    with torch.no_grad():
        if flag=='val':
            for image, _ in tqdm(dataset, desc="validation TTA Prediction"): # load batch
                # read raw images from dataset_raw
                tta_preds = []
                image = image.clamp(0, 255).to(torch.uint8) 
                image = image.permute(1, 2, 0).cpu().numpy() # H,W,C ë¡œ ë³€í˜•
                for _ in range(5): # 5 TTA iterations
                    augmented_image = tta_transform(image=image)['image']
                    augmented_image = augmented_image.to(device)
                    augmented_image = augmented_image.unsqueeze(0) # batch, H,W,C ë¡œ ë³€í˜•
                    outputs = model(augmented_image) # inference
                    tta_preds.append(outputs.softmax(1).cpu().numpy()) # append inference result
                avg_preds = np.mean(tta_preds, axis=0) # 5 TTA ì˜ˆì¸¡ ê²°ê³¼ í™•ë¥ ê°’ì„ í‰ê·  ë‚¸ë‹¤.
                predictions.extend(avg_preds.argmax(1))
        else: # inference time transform
            for image, _ in tqdm(dataset, desc="test TTA Prediction"): # load batch
                tta_preds = []
                image = image.clamp(0, 255).to(torch.uint8) 
                image = image.permute(1, 2, 0).cpu().numpy() # H,W,C ë¡œ ë³€í˜•
                augs = []
                a1 = A.Compose([A.Compose(A.HorizontalFlip(p=1.0)),tta_transform]) # ìˆ˜í‰ ë°˜ì „
                augs.append(a1)
                a2 = A.Compose([A.Compose(A.VerticalFlip(p=1.0)),tta_transform]) # ìˆ˜ì§ ë°˜ì „
                augs.append(a2)
                a3 = A.Compose([A.Compose(A.Transpose(p=1.0)),tta_transform]) # ëŒ€ì¹­
                augs.append(a3)
                a4 = A.Compose([A.Compose(A.Rotate(limit=(-10, 10), p=1.0)),tta_transform]) # ë¯¸ì„¸í•œ íšŒì „ ë³€í™˜
                augs.append(a4)
                augs.append(tta_transform) # ì¦ê°• ì•ˆ í•˜ëŠ” ë²„ì „
                for transform_func in augs:
                    augmented_image = transform_func(image=image)['image']
                    augmented_image = augmented_image.to(device)
                    augmented_image = augmented_image.unsqueeze(0) # batch, H,W,C ë¡œ ë³€í˜•
                    outputs = model(augmented_image) # inference
                    tta_preds.append(outputs.softmax(1).cpu().numpy()) # append inference result
                    del augmented_image
                    # ğŸ”§ í”Œë«í¼ë³„ ë©”ëª¨ë¦¬ ìºì‹œ ë¹„ìš°ê¸°
                    _clear_device_cache(device)
                avg_preds = np.mean(tta_preds, axis=0) # 5 TTA ì˜ˆì¸¡ ê²°ê³¼ í™•ë¥ ê°’ì„ í‰ê·  ë‚¸ë‹¤.
                predictions.extend(avg_preds.argmax(1))
    return predictions

def predict(model, loader, device):
    model.eval()
    predictions = []
    with torch.no_grad():
        for images, _ in tqdm(loader, desc="Prediction"):
            images = images.to(device)
            outputs = model(images)
            predictions.extend(outputs.argmax(1).cpu().numpy())
    return predictions

def do_validation(df, model, data, transform_func, cfg, run=None, show=False, savepath=None):
    if cfg.val_TTA:
        print("Running TTA on validation set...")
        # offline ì¦ê°•ì„ ìˆ˜í–‰í–ˆì„ ë•ŒëŠ” tta_predict() í˜¸ì¶œí•  í•„ìš”ê°€ ì—†ë‹¤.
        # val_preds = tta_predict(model, data, transform_func, cfg.device, flag='val')
        # offline TTA ì¦ê°• ì‹œì—ëŠ” predict í˜¸ì¶œ
        val_preds = predict(model, data, cfg.device)
    else:
        print("Running Normal Validation...")
        val_preds = predict(model, data, cfg.device)
    val_targets = df['target'].values
    val_f1 = f1_score(val_targets, val_preds, average='macro')
    # ë©”íƒ€ë°ì´í„° ë¡œë“œ
    meta = pd.read_csv(os.path.join(cfg.data_dir, 'meta.csv'))
    meta_dict = zip(meta['target'], meta['class_name'])
    meta_dict = dict(meta_dict)
    # meta_dict[-1] = "None"
    val_targets_class = list(map(lambda x: meta_dict[x], val_targets))
    val_preds_class = list(map(lambda x: meta_dict[x], val_preds))
    all_classes = sorted(list(set(val_targets_class + val_preds_class)))
    cm = confusion_matrix(val_targets_class, val_preds_class, labels=all_classes)
    plt.figure(figsize=(10, 8), dpi=100)
    sns.heatmap(cm, annot=True, fmt='d', xticklabels=all_classes, yticklabels=all_classes)
    plt.title(f"Validation Confusion Matrix - F1: {val_f1:.4f}")
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.tight_layout()
    if run:
        run.log({"tta_val_confusion_matrix": wandb.Image(plt)})
    if savepath is not None:
        plt.savefig(savepath)
    if show:
        plt.show()
    else:
        plt.clf()
    return val_preds, val_f1

def save_validation_images(val_df, val_preds, cfg, images_per_row=5, show=False):
    # 1. ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì„ í¬í•¨í•˜ëŠ” ìƒˆë¡œìš´ DataFrame ìƒì„±
    # val_dfì˜ 'ID'ì™€ 'target'ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ , 'predicted_target' ì»¬ëŸ¼ ì¶”ê°€
    results_df = val_df[['ID', 'target']].copy()
    results_df['predicted_target'] = val_preds
    # 2. ì˜ˆì¸¡ì´ í‹€ë¦° ë°ì´í„° í•„í„°ë§
    # 'target' ì»¬ëŸ¼ê³¼ 'predicted_target' ì»¬ëŸ¼ì´ ë‹¤ë¥¸ ê²½ìš°ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    misclassified_df = results_df[results_df['target'] != results_df['predicted_target']].copy()
    if misclassified_df.empty:
        print("No misclassified images to visualize.")
        return None

    # 3. ê°€ë…ì„±ì„ ìœ„í•´ í´ë˜ìŠ¤ ì´ë¦„ ì¶”ê°€ (ì„ íƒ ì‚¬í•­)
    # ì‹¤ì œ í´ë˜ìŠ¤ ì´ë¦„ê³¼ ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ì´ë¦„ì„ ë§¤í•‘í•˜ì—¬ ì»¬ëŸ¼ ì¶”ê°€
    # ë©”íƒ€ë°ì´í„° ë¡œë“œ
    meta = pd.read_csv(os.path.join(cfg.data_dir, 'meta.csv'))
    meta_dict = zip(meta['target'], meta['class_name'])
    meta_dict = dict(meta_dict)
    misclassified_df['actual_class_name'] = misclassified_df['target'].map(meta_dict)
    misclassified_df['predicted_class_name'] = misclassified_df['predicted_target'].map(meta_dict)

    # ì‹œê°í™” ë° ê²°ê³¼ ì €ì¥.
    # 1. targetìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
    misclassified_df = misclassified_df.sort_values(by='target', ascending=True)

    # 2. ì‹œê°í™”
    num_images = len(misclassified_df)
    num_rows = (num_images + images_per_row - 1) // images_per_row # ì˜¬ë¦¼ ê³„ì‚°
    
    plt.figure(figsize=(6 * images_per_row, 6 * num_rows), dpi=200) # ê° ì´ë¯¸ì§€ ë‹¹ 3x3 ì¸ì¹˜ í• ë‹¹

    for i, row in tqdm(enumerate(misclassified_df.itertuples()), desc="Visualizing Wrong Validation Results..."):
        # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ êµ¬ì„±
        # ë§Œì•½ ì´ë¯¸ì§€ê°€ data_dir/images/ ì— ìˆë‹¤ë©´, os.path.join(data_dir, 'images', row.ID)
        image_path = os.path.join(cfg.data_dir, 'train', row.ID)

        if not os.path.exists(image_path):
            print(f"Warning: Image file not found at {image_path}. Skipping.")
            continue

        try:
            img = mpimg.imread(image_path)
        except Exception as e:
            print(f"Error loading image {image_path}: {e}. Skipping.")
            continue

        ax = plt.subplot(num_rows, images_per_row, i + 1)
        ax.imshow(img)

        # íƒ€ì´í‹€ ì„¤ì •: A-{actual_class_name}_P-{predicted_class_name}
        title = f"ID-{row.ID}\nA-{row.actual_class_name}\nP-{row.predicted_class_name}"
        ax.set_title(title, fontsize=10) # í°íŠ¸ í¬ê¸° ì¡°ì •

        ax.axis('off') # ì¶• ì •ë³´ ìˆ¨ê¸°ê¸°

    plt.tight_layout() # ì„œë¸Œí”Œë¡¯ ê°„ê²© ìë™ ì¡°ì ˆ
    plt.suptitle("Misclassified Images", fontsize=16, y=1.02) # ì „ì²´ ì œëª©
    if os.path.exists(cfg.submission_dir):
        val_wrong_img_dir = os.path.join(cfg.submission_dir, 'val_img')
        os.makedirs(val_wrong_img_dir, exist_ok=True)
        plt.savefig(os.path.join(val_wrong_img_dir,"validation_wrong_images.png"))
    if show:
        plt.show()
