#!/usr/bin/env python3
"""
ğŸ”§ ìˆ˜ì •ëœ í”Œë«í¼ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
Mac OS (MPS) / Ubuntu (CUDA) / CPU ìë™ ê°ì§€ ë° Mixed Precision í…ŒìŠ¤íŠ¸
"""

import sys
import os
import torch

# cv-classification í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.append(project_root)

def test_device_detection():
    """Device ìë™ ê°ì§€ í…ŒìŠ¤íŠ¸"""
    
    print("ğŸ–¥ï¸ Device ìë™ ê°ì§€ í…ŒìŠ¤íŠ¸...")
    print("=" * 50)
    
    # gemini_main_v2.pyì™€ ë™ì¼í•œ ë¡œì§
    device = 'cpu'
    if torch.backends.mps.is_available():
        device = torch.device('mps')
        print("âœ… MPS (Mac OS Metal) ê°ì§€ë¨")
    elif torch.cuda.is_available():
        device = torch.device('cuda')
        print(f"âœ… CUDA ê°ì§€ë¨ - GPU: {torch.cuda.get_device_name(0)}")
    else:
        print("âœ… CPU ëª¨ë“œë¡œ ì‹¤í–‰")
    
    print(f"ğŸ¯ ì„ íƒëœ Device: {device}")
    return device

def test_mixed_precision_compatibility(device):
    """Mixed Precision í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸"""
    
    print("\nğŸ”§ Mixed Precision í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸...")
    print("=" * 50)
    
    device_str = str(device)
    is_cuda = device_str.startswith('cuda')
    is_mps = device_str.startswith('mps')
    is_cpu = device_str == 'cpu'
    
    print(f"ğŸ“± Device Type: {device_str}")
    print(f"ğŸ”¸ CUDA: {is_cuda}")
    print(f"ğŸ”¸ MPS: {is_mps}")
    print(f"ğŸ”¸ CPU: {is_cpu}")
    
    # Mixed Precision ì„¤ì • í…ŒìŠ¤íŠ¸
    use_mixed_precision = True and is_cuda  # CUDAì—ì„œë§Œ í™œì„±í™”
    autocast_device_type = 'cuda' if is_cuda else None
    
    print(f"âš¡ Mixed Precision ì‚¬ìš©: {'Yes' if use_mixed_precision else 'No'}")
    print(f"âš¡ AutoCast Device Type: {autocast_device_type}")
    
    # GradScaler í…ŒìŠ¤íŠ¸
    try:
        scaler = torch.amp.GradScaler(enabled=use_mixed_precision)
        print("âœ… GradScaler ì´ˆê¸°í™” ì„±ê³µ")
    except Exception as e:
        print(f"âŒ GradScaler ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False
    
    # AutoCast í…ŒìŠ¤íŠ¸
    try:
        if use_mixed_precision and autocast_device_type:
            with torch.amp.autocast(device_type=autocast_device_type, enabled=True):
                # ê°„ë‹¨í•œ í…ì„œ ì—°ì‚° í…ŒìŠ¤íŠ¸
                x = torch.randn(2, 3).to(device)
                y = torch.randn(3, 2).to(device)
                z = torch.mm(x, y)
            print("âœ… Mixed Precision AutoCast í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        else:
            # ì¼ë°˜ ì—°ì‚° í…ŒìŠ¤íŠ¸
            x = torch.randn(2, 3).to(device)
            y = torch.randn(3, 2).to(device)
            z = torch.mm(x, y)
            print("âœ… ì¼ë°˜ ì—°ì‚° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
    except Exception as e:
        print(f"âŒ ì—°ì‚° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False
    
    return True

def test_cache_management(device):
    """ìºì‹œ ê´€ë¦¬ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
    
    print("\nğŸ§¹ ìºì‹œ ê´€ë¦¬ í…ŒìŠ¤íŠ¸...")
    print("=" * 50)
    
    device_str = str(device)
    
    def _clear_device_cache(device):
        """gemini_train_v2.pyì™€ ë™ì¼í•œ í•¨ìˆ˜"""
        device_str = str(device)
        if device_str.startswith('cuda'):
            torch.cuda.empty_cache()
            return "CUDA ìºì‹œ ë¹„ìš°ê¸°"
        elif device_str.startswith('mps'):
            try:
                torch.mps.empty_cache()
                return "MPS ìºì‹œ ë¹„ìš°ê¸°"
            except AttributeError:
                return "MPS ìºì‹œ ë¹„ìš°ê¸° (torch.mps.empty_cache ë¯¸ì§€ì›)"
        return "CPU (ìºì‹œ ë¹„ìš°ê¸° ë¶ˆí•„ìš”)"
    
    try:
        result = _clear_device_cache(device)
        print(f"âœ… {result} ì„±ê³µ")
        return True
    except Exception as e:
        print(f"âŒ ìºì‹œ ê´€ë¦¬ ì‹¤íŒ¨: {e}")
        return False

def test_imports():
    """ìˆ˜ì •ëœ v2 íŒŒì¼ë“¤ì˜ import í…ŒìŠ¤íŠ¸"""
    
    print("\nğŸ“¦ Import í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸...")
    print("=" * 50)
    
    try:
        print("ğŸ“¦ Testing gemini_utils_v2 import...")
        from codes.gemini_utils_v2 import load_config, set_seed, ImageDataset
        print("âœ… gemini_utils_v2 import successful")
        
        print("ğŸ“¦ Testing gemini_augmentation_v2 import...")
        from codes.gemini_augmentation_v2 import get_augmentation
        print("âœ… gemini_augmentation_v2 import successful")
        
        print("ğŸ“¦ Testing gemini_train_v2 import...")
        from codes.gemini_train_v2 import EarlyStopping, TrainModule
        print("âœ… gemini_train_v2 import successful")
        
        print("ğŸ“¦ Testing gemini_evalute_v2 import...")
        from codes.gemini_evalute_v2 import tta_predict, predict, do_validation
        print("âœ… gemini_evalute_v2 import successful")
        
        return True
        
    except ImportError as e:
        print(f"âŒ Import Error: {e}")
        return False
    except Exception as e:
        print(f"âŒ Unexpected Error: {e}")
        return False

def test_train_module_initialization():
    """TrainModule ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ (í”Œë«í¼ë³„ ì„¤ì • í™•ì¸)"""
    
    print("\nğŸ‹ï¸ TrainModule í”Œë«í¼ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸...")
    print("=" * 50)
    
    try:
        from codes.gemini_utils_v2 import load_config
        from codes.gemini_train_v2 import TrainModule
        
        # Config ë¡œë“œ
        config_path = os.path.join(project_root, 'codes', 'config_v2.yaml')
        if not os.path.exists(config_path):
            print(f"âŒ Config file not found: {config_path}")
            return False
            
        cfg = load_config(config_path)
        
        # Device ì„¤ì •
        device = 'cpu'
        if torch.backends.mps.is_available():
            device = torch.device('mps')
        elif torch.cuda.is_available():
            device = torch.device('cuda')
        cfg.device = device
        
        # ê°„ë‹¨í•œ ëª¨ë¸ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
        import torch.nn as nn
        model = nn.Sequential(
            nn.Linear(10, 5),
            nn.ReLU(),
            nn.Linear(5, 3)
        )
        
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10)
        
        # ë”ë¯¸ ë°ì´í„°ë¡œë” (ì‹¤ì œë¡œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        from torch.utils.data import TensorDataset, DataLoader
        dummy_data = TensorDataset(torch.randn(10, 10), torch.randint(0, 3, (10,)))
        dummy_loader = DataLoader(dummy_data, batch_size=2)
        
        # TrainModule ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
        trainer = TrainModule(
            model=model,
            criterion=criterion,
            optimizer=optimizer,
            scheduler=scheduler,
            train_loader=dummy_loader,
            valid_loader=dummy_loader,
            cfg=cfg,
            verbose=1,
            run=None
        )
        
        print("âœ… TrainModule ì´ˆê¸°í™” ì„±ê³µ")
        print(f"âœ… Device ì„¤ì •: {trainer.device_str}")
        print(f"âœ… Mixed Precision: {'Enabled' if trainer.use_mixed_precision else 'Disabled'}")
        print(f"âœ… AutoCast Device Type: {trainer.autocast_device_type}")
        
        return True
        
    except Exception as e:
        print(f"âŒ TrainModule ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ í”Œë«í¼ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"ğŸ“‚ Project root: {project_root}")
    print(f"ğŸ Python version: {sys.version}")
    print(f"ğŸ”¥ PyTorch version: {torch.__version__}")
    print()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    device = test_device_detection()
    mixed_precision_ok = test_mixed_precision_compatibility(device)
    cache_ok = test_cache_management(device)
    import_ok = test_imports()
    train_module_ok = test_train_module_initialization()
    
    print("\n" + "=" * 50)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 50)
    print(f"ğŸ–¥ï¸ Device ê°ì§€: {'âœ… ì„±ê³µ' if device else 'âŒ ì‹¤íŒ¨'}")
    print(f"âš¡ Mixed Precision: {'âœ… ì„±ê³µ' if mixed_precision_ok else 'âŒ ì‹¤íŒ¨'}")
    print(f"ğŸ§¹ ìºì‹œ ê´€ë¦¬: {'âœ… ì„±ê³µ' if cache_ok else 'âŒ ì‹¤íŒ¨'}")
    print(f"ğŸ“¦ Import í˜¸í™˜ì„±: {'âœ… ì„±ê³µ' if import_ok else 'âŒ ì‹¤íŒ¨'}")
    print(f"ğŸ‹ï¸ TrainModule í˜¸í™˜ì„±: {'âœ… ì„±ê³µ' if train_module_ok else 'âŒ ì‹¤íŒ¨'}")
    
    all_passed = all([mixed_precision_ok, cache_ok, import_ok, train_module_ok])
    
    print("\n" + "=" * 50)
    if all_passed:
        print("ğŸŠ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! í”Œë«í¼ í˜¸í™˜ì„± ìˆ˜ì • ì™„ë£Œ!")
        print("ğŸš€ ì´ì œ Mac OS/Ubuntu ëª¨ë“  í™˜ê²½ì—ì„œ ì•ˆì „í•˜ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        if str(device).startswith('mps'):
            print("ğŸ Mac OS (MPS) í™˜ê²½ ìµœì í™” ì™„ë£Œ")
        elif str(device).startswith('cuda'):
            print("ğŸ§ Ubuntu (CUDA) í™˜ê²½ ìµœì í™” ì™„ë£Œ")
        else:
            print("ğŸ’» CPU í™˜ê²½ í˜¸í™˜ì„± í™•ì¸ ì™„ë£Œ")
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ë¬¸ì œë¥¼ í•´ê²°í•œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
    print("=" * 50)
