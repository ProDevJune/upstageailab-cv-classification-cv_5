import cv2
import albumentations as A
from albumentations.pytorch import ToTensorV2
import os
import torch
import numpy as np
import random

# ğŸ”¥ Phase 1: MixUp êµ¬í˜„
def mixup_data(x, y, alpha=1.0, device='cpu'):
    """MixUp data augmentation
    
    Args:
        x: input images (batch_size, channels, height, width)
        y: input labels (batch_size,)
        alpha: mixup interpolation coefficient
        device: device to perform operations on
    
    Returns:
        mixed_x: mixed images
        y_a, y_b: original labels
        lam: mixing coefficient
    """
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1
    
    batch_size = x.size(0)
    index = torch.randperm(batch_size).to(device)
    
    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    
    return mixed_x, y_a, y_b, lam

# ğŸ”¥ Phase 1: CutMix êµ¬í˜„
def cutmix_data(x, y, alpha=1.0, device='cpu'):
    """CutMix data augmentation
    
    Args:
        x: input images (batch_size, channels, height, width)
        y: input labels (batch_size,)
        alpha: cutmix interpolation coefficient
        device: device to perform operations on
    
    Returns:
        mixed_x: mixed images
        y_a, y_b: original labels
        lam: mixing coefficient (adjusted)
    """
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1
    
    batch_size = x.size(0)
    index = torch.randperm(batch_size).to(device)
    
    # Generate random bounding box
    _, _, H, W = x.shape
    cut_rat = np.sqrt(1. - lam)  # paper recommendation
    cut_w = int(W * cut_rat)
    cut_h = int(H * cut_rat)
    
    # Uniform random location
    cx = np.random.randint(W)
    cy = np.random.randint(H)
    
    bbx1 = np.clip(cx - cut_w // 2, 0, W)
    bby1 = np.clip(cy - cut_h // 2, 0, H)
    bbx2 = np.clip(cx + cut_w // 2, 0, W)
    bby2 = np.clip(cy + cut_h // 2, 0, H)
    
    # Apply cutmix
    mixed_x = x.clone()
    mixed_x[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]
    
    # Adjust lambda to match the actual area ratio
    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))
    
    y_a, y_b = y, y[index]
    
    return mixed_x, y_a, y_b, lam

# ğŸ”¥ Phase 1: MixUp/CutMix ì†ì‹¤ ê³„ì‚°
def mixup_criterion(criterion, pred, y_a, y_b, lam):
    """Calculate mixed loss for MixUp/CutMix"""
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)

# ğŸ”¥ Phase 1: MixUp/CutMix ì ìš© í•¨ìˆ˜
def apply_mixup_cutmix(x, y, cfg, device='cpu'):
    """Apply MixUp or CutMix based on configuration
    
    Args:
        x: input images
        y: input labels  
        cfg: configuration with mixup_cutmix settings
        device: device to perform operations on
    
    Returns:
        mixed_x, y_a, y_b, lam, use_mixup_cutmix
    """
    mixup_cutmix_config = getattr(cfg, 'mixup_cutmix', {})
    
    # Check if we should apply mixup/cutmix
    prob = mixup_cutmix_config.get('prob', 0.0)
    if prob <= 0 or np.random.rand() > prob:
        return x, y, y, 1.0, False
    
    # Choose between MixUp and CutMix
    switch_prob = mixup_cutmix_config.get('switch_prob', 0.5)
    use_cutmix = np.random.rand() < switch_prob
    
    mixup_alpha = mixup_cutmix_config.get('mixup_alpha', 1.0)
    cutmix_alpha = mixup_cutmix_config.get('cutmix_alpha', 1.0)
    
    if use_cutmix:
        mixed_x, y_a, y_b, lam = cutmix_data(x, y, cutmix_alpha, device)
    else:
        mixed_x, y_a, y_b, lam = mixup_data(x, y, mixup_alpha, device)
    
    return mixed_x, y_a, y_b, lam, True

AUG = {
    'eda': A.Compose([
        # Brightness, Contrast, ColorJitter
        A.ColorJitter(brightness=0.1, contrast=0.07, saturation=0.07, hue=0.07, p=1.0),
        # ê³µê°„ ë³€í˜•ì— ëŒ€í•œ ì¦ê°•
        A.Affine(
            scale=(0.85, 1.15),
            translate_percent=(-0.05,0.05),
            rotate=(-20,30),
            fill=(255,255,255),
            shear=(-5, 5),
            p=1.0
        ),
        # x,y ì¢Œí‘œ ë°˜ì „ 
        A.HorizontalFlip(p=0.6),
        A.VerticalFlip(p=0.6),
        A.Transpose(p=0.6),    
        # Blur & Noise
        A.OneOf([
            A.GaussianBlur(sigma_limit=(0.5, 2.5), p=1.0),
            A.Blur(blur_limit=(3, 9), p=1.0),
        ], p=1.0),
        A.GaussNoise(std_range=(0.0025, 0.2), p=1.0),            
    ]),
    'dilation': A.Compose([
        A.Morphological(p=1, scale=(1, 3), operation="dilation"),
        # ê³µê°„ ë³€í˜•ì— ëŒ€í•œ ì¦ê°•
        A.Affine(
            scale=(0.85, 1.15),
            translate_percent=(-0.05,0.05),
            rotate=(-20,30),
            fill=(255,255,255),
            shear=(-5, 5),
            p=0.9
        ),
        # x,y ì¢Œí‘œ ë°˜ì „ 
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
        A.Transpose(p=0.5),    
        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=1),
        A.RandomBrightnessContrast(p=1),
    ]),
    'erosion': A.Compose([
        A.Morphological(p=1, scale=(2, 4), operation="erosion"),
        # ê³µê°„ ë³€í˜•ì— ëŒ€í•œ ì¦ê°•
        A.Affine(
            scale=(0.85, 1.15),
            translate_percent=(-0.05,0.05),
            rotate=(-20,30),
            fill=(255,255,255),
            shear=(-5, 5),
            p=0.9
        ),
        # x,y ì¢Œí‘œ ë°˜ì „ 
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
        A.Transpose(p=0.5),    
        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=1),
        A.RandomBrightnessContrast(p=1),
    ]),
    'basic': A.Compose([ ### ìƒ‰ì¡°/ë°ê¸°/ëŒ€ë¹„ ë³€í™”ë¥¼ ìµœì†Œí™”í•˜ê³  ê¸°í•˜í•™ì „ ë³€í™˜ì— ì´ˆì ì„ ë‘” ì•½í•œ ì¦ê°•. ë…¸ì´ì¦ˆ/ë¸”ëŸ¬ë„ ì—†ìŒ.
        # 1. í”½ì…€ ê°’ ê¸°ë°˜ ë³€í™˜ (ì´ë¯¸ì§€ ìì²´ì˜ í”½ì…€ ê°’ì— ì˜í–¥ì„ ì¤Œ)
        # ì´ ë³€í™˜ë“¤ì€ ê¸°í•˜í•™ì  ë³€í™˜ ì „ì— ì ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
        A.RGBShift(
            r_shift_limit=20,  # Red ì±„ë„ ìµœëŒ€ ë³€í™”ëŸ‰ (-20 ~ +20)
            g_shift_limit=20,  # Green ì±„ë„ ìµœëŒ€ ë³€í™”ëŸ‰ (-20 ~ +20)
            b_shift_limit=20,  # Blue ì±„ë„ ìµœëŒ€ ë³€í™”ëŸ‰ (-20 ~ +20)
            p=0.5 # 50% í™•ë¥ ë¡œ ì ìš©
        ),
        A.RandomBrightnessContrast(
            brightness_limit=0.2, # ë°ê¸° ë³€í™”ëŸ‰ (-0.2 ~ +0.2)
            contrast_limit=0.2,   # ëŒ€ë¹„ ë³€í™”ëŸ‰ (-0.2 ~ +0.2)
            p=0.5 # 50% í™•ë¥ ë¡œ ì ìš©
        ),
        
        # 2. ê¸°í•˜í•™ì  ë³€í™˜ (ì´ë¯¸ì§€ì˜ í˜•íƒœ, ìœ„ì¹˜, í¬ê¸°ì— ì˜í–¥ì„ ì¤Œ)
        # ì´ ë³€í™˜ë“¤ì€ í”½ì…€ ê¸°ë°˜ ë³€í™˜ ì´í›„ì— ì ìš©í•˜ì—¬ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
        # TransposeëŠ” ì´ë¯¸ì§€ë¥¼ ì „ì¹˜(transpose)í•©ë‹ˆë‹¤ (í–‰ê³¼ ì—´ì„ ë°”ê¿‰ë‹ˆë‹¤).
        # ì´ëŠ” ì´ë¯¸ì§€ì˜ 90ë„ íšŒì „ê³¼ ëŒ€ì¹­ ì¡°í•©ê³¼ ìœ ì‚¬í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤.
        # ShiftScaleRotateì™€ í•¨ê»˜ ì‚¬ìš©í•˜ë©´ ë” ë‹¤ì–‘í•œ ë°©í–¥ì˜ ë³€í˜•ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        A.Affine(
            scale={"x": (0.8, 1.2), "y": (0.8, 1.2)}, # X, Y ì¶• ê°œë³„ ìŠ¤ì¼€ì¼
            translate_percent={"x": (-0.1, 0.1), "y": (-0.1, 0.1)}, # X, Y ì¶• ê°œë³„ ì´ë™
            rotate=(-15, 20), # íšŒì „ ê°ë„
            shear=(-10, 10),  # ì „ë‹¨ ë³€í™˜ (ì´ë¯¸ì§€ë¥¼ ê¸°ìš¸ì„)
            p=0.5, # 50% í™•ë¥ ë¡œ ì ìš©
            fill=(255,255,255) # ì´ë¯¸ì§€ ì™¸ë¶€ = í°ìƒ‰ìœ¼ë¡œ ì±„ìš°ê¸°
        ),
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
        A.Transpose(p=0.5),            
    ]),
    'middle': A.Compose([ # ë…¸ì´ì¦ˆ/ë¸”ëŸ¬ + ê¸°í•˜í•™ì  ë³€í™˜ì— ì´ˆì ì„ ë‘” ì¤‘ê°„ ë‚œì´ë„ì˜ ë³€í™˜
        
        # ë…¸ì´ì¦ˆ íš¨ê³¼ (ë‘˜ ì¤‘ í•˜ë‚˜ë§Œ ì ìš©, ë¬¸ì„œ í’ˆì§ˆ ì €í•˜ë¥¼ ì‹œë®¬ë ˆì´ì…˜)
        A.OneOf([
            A.GaussNoise(std_range=(0.01, 0.3), p=1.0),
            A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=1.0)
        ], p=0.3), # ë…¸ì´ì¦ˆë„ ë„ˆë¬´ ê°•í•˜ë©´ ì¸ì‹ ì–´ë µê¸°ì— ì ë‹¹í•œ í™•ë¥  (0.2 ìœ ì§€)

        # 2. ê¸°í•˜í•™ì  ë³€í™˜ ë° ë¬¸ì„œ íŠ¹í™” ë³€í˜• (í˜•íƒœ ì™œê³¡, ì‹œì  ë³€í™”)
        # Perspective, GridDistortion, ElasticTransformì€ ê°•í•œ ë¹„ì„ í˜• ë³€í™˜ì´ë¯€ë¡œ
        # OneOfë¡œ ë¬¶ê±°ë‚˜ ê°ìì˜ í™•ë¥ ì„ ë‚®ì¶° ê³¼ë„í•œ ì™œê³¡ì„ ë°©ì§€í•©ë‹ˆë‹¤.
        # ì—¬ê¸°ì„œëŠ” ë¬¸ì„œì˜ "ì°Œê·¸ëŸ¬ì§/ì™œê³¡"ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ê¸° ìœ„í•´ OneOfë¡œ ë¬¶ëŠ” ê²ƒì´ íš¨ê³¼ì ì…ë‹ˆë‹¤.
        A.OneOf([
            # ë¬¸ì„œ ì›ê·¼ ë³€í™˜ (0.05~0.1 ìŠ¤ì¼€ì¼ì€ ì ì ˆ)
            A.Perspective(scale=(0.05, 0.1), p=1.0),
            # ê·¸ë¦¬ë“œ ì™œê³¡ (num_steps=5, distort_limit=0.1 ì ì ˆ)
            A.GridDistortion(num_steps=5, distort_limit=0.2, p=1.0),
        ], p=0.3), # ì´ ì„¸ ê°€ì§€ ê°•í•œ ì™œê³¡ ì¤‘ í•˜ë‚˜ë¥¼ 30% í™•ë¥ ë¡œ ì ìš© (ê°œë³„ pê°’ì´ 1.0ì´ë¯€ë¡œ OneOfì˜ pê°€ ì¤‘ìš”)
        # ì›ë³¸ì—ì„œ ê° p=0.3, 0.2, 0.1ë¡œ ê°ê° ì ìš©ë˜ì—ˆìœ¼ë‚˜, ì´ì œëŠ” OneOfë¡œ ë¬¶ì–´ ì´ ì ìš© í™•ë¥ ì„ 0.3ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.
        # ì´ë ‡ê²Œ í•˜ë©´ ì„¸ ê°€ì§€ ì¤‘ë³µë˜ëŠ” ì™œê³¡ íš¨ê³¼ë¥¼ ë™ì‹œì— ì–»ëŠ” ê²½ìš°ë¥¼ ì¤„ì—¬ì¤ë‹ˆë‹¤.
        
        # ê¸°ë³¸ ê¸°í•˜í•™ì  ë³€í™˜ (Shift, Scale, Rotate)
        # ë¬¸ì„œì˜ ê²½ìš° íšŒì „ ì œí•œì´ ì¤‘ìš” (ì›ë³¸ì—ì„œ min(config.rotation_limit, 15)ë¡œ ì œí•œ)
        A.Affine(
            scale=(0.8, 1.2),
            translate_percent=(-0.0625, 0.0625),
            rotate=(-120, 120), # íšŒì „ ê°ë„
            shear=(-5, 5),  # ì „ë‹¨ ë³€í™˜ (ì´ë¯¸ì§€ë¥¼ ê¸°ìš¸ì„)
            p=1.0, 
            fill=(255,255,255) # ì´ë¯¸ì§€ ì™¸ë¶€ = í°ìƒ‰ìœ¼ë¡œ ì±„ìš°ê¸°
        ),

        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
        A.Transpose(p=0.5)
    ]),
    'aggressive': A.Compose([
        # ì •ë³´ ê°€ë¦¬ê¸° ë° í˜¼í•© (Occlusion & Mixing)
        # Trainì˜ ë§ˆìŠ¤í‚¹ê³¼ ìœ ì‚¬í•œ íš¨ê³¼ë¥¼ ì£¼ì–´ ëª¨ë¸ì´ íŠ¹ì • ì˜ì—­ì— ì˜ì¡´í•˜ì§€ ì•Šë„ë¡í•¨
        A.CoarseDropout(
            num_holes_range=(3, 5),
            hole_height_range=(10, 35),
            hole_width_range=(5, 45),
            fill=(0,0,0),
            p=0.9
        ),
        # ê°•ë ¥í•œ ê¸°í•˜í•™ì  ë³€í™˜
        A.OneOf([
            # Affineì˜ ë²”ìœ„ë¥¼ í¬ê²Œ ëŠ˜ë¦¬ê³ , Perspective ë³€í™˜ì„ ì¶”ê°€í•˜ì—¬ ì™œê³¡ ì‹œë®¬ë ˆì´ì…˜
            A.Affine(
                scale=(0.7, 1.3),
                translate_percent=(-0.15,0.2),
                rotate=(-45, 45), # íšŒì „ ê°ë„
                shear=(-10, 10),  # ì „ë‹¨ ë³€í™˜ (ì´ë¯¸ì§€ë¥¼ ê¸°ìš¸ì„)
                p=1.0, # 50% í™•ë¥ ë¡œ ì ìš©
                fill=(255,255,255) # ì´ë¯¸ì§€ ì™¸ë¶€ = í°ìƒ‰ìœ¼ë¡œ ì±„ìš°ê¸°
            ),
            A.Perspective(scale=(0.05, 0.1),fill=(255,255,255),p=1.0),
        ], p=0.9),
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
        A.Transpose(p=0.5),
        # ë…¸ì´ì¦ˆ íš¨ê³¼ (ë‘˜ ì¤‘ í•˜ë‚˜ë§Œ ì ìš©, ë¬¸ì„œ í’ˆì§ˆ ì €í•˜ë¥¼ ì‹œë®¬ë ˆì´ì…˜)
        A.OneOf([
            A.GaussNoise(std_range=(0.01, 0.3), p=1.0), 
            A.ISONoise(color_shift=(0.01, 0.2), intensity=(0.1, 0.5), p=1.0)
        ], p=0.3), # ë…¸ì´ì¦ˆë„ ë„ˆë¬´ ê°•í•˜ë©´ ì¸ì‹ ì–´ë µê¸°ì— ì ë‹¹í•œ í™•ë¥  
        A.OneOf([
            # ìŠ¤ìº”/ì´¬ì˜ ì‹œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¸”ëŸ¬ íš¨ê³¼
            A.GaussianBlur(blur_limit=(3, 7), p=1.0),
            A.MotionBlur(blur_limit=(3, 7), p=1.0),
            # ì´ë¯¸ì§€ í’ˆì§ˆì„ ë‚®ì¶° ì••ì¶•/í•´ìƒë„ ì €í•˜ íš¨ê³¼ ëª¨ë°©
            A.Downscale(scale_range=(0.5, 0.75), p=1.0),
        ], p=0.5),

        # ìƒ‰ìƒ ë° ëŒ€ë¹„ì˜ ê¸‰ê²©í•œ ë³€í™”
        A.OneOf([
            # ë¬¸ì„œì˜ ì¡°ëª…, ìŠ¤ìº” í’ˆì§ˆ ë³€í™” ëª¨ë°©
            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=1.0),
            A.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1, p=1.0),
            # íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”ë¥¼ í†µí•´ ëŒ€ë¹„ë¥¼ ê·¹ì ìœ¼ë¡œ ë³€ê²½
            A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=1.0),
        ], p=0.8),
    ]),
    # ğŸ”¥ Phase 1: MixUpê³¼ CutMixëŠ” ì´ë¯¸ pytorch ë ˆë²¨ì—ì„œ êµ¬í˜„í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” í”Œë ˆì´ìŠ¤í™€ë”ë§Œ ì¶”ê°€
    'mixup': A.Compose([
        # MixUpì€ pytorch ë ˆë²¨ì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì¼ë°˜ ì¦ê°•ë§Œ
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
    ]),
    'cutmix': A.Compose([
        # CutMixëŠ” pytorch ë ˆë²¨ì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì¼ë°˜ ì¦ê°•ë§Œ
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
    ]),
}

def get_augmentation(cfg, epoch=0):
    common_resize_transform = A.Compose([
        # ê¸´ ë³€ì„ ê¸°ì¤€ìœ¼ë¡œ ì¢…íš¡ë¹„ë¥¼ ìœ ì§€í•˜ë©° resize
        A.LongestMaxSize(max_size=cfg.image_size),
        # cfg.image_size ì •ì‚¬ê°í˜•ìœ¼ë¡œ ë§Œë“¤ê³ , ì—¬ë°±ì€ í°ìƒ‰ìœ¼ë¡œ ì±„ì›€.
        A.PadIfNeeded(min_height=cfg.image_size, min_width=cfg.image_size, border_mode=cv2.BORDER_CONSTANT, fill=(255, 255, 255), p=1.0),
        A.Normalize(mean=cfg.norm_mean, std=cfg.norm_std),
        ToTensorV2(),
    ])

    # epochì— ë”°ë¼ ë™ì ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì¦ê°• ê¸°ë²•
    if cfg.dynamic_augmentation['enabled']:
        
        weak_policy = cfg.dynamic_augmentation['policies']['weak']
        middle_policy = cfg.dynamic_augmentation['policies']['middle']
        strong_policy = cfg.dynamic_augmentation['policies']['strong']

        if epoch < weak_policy['end_epoch']:
            print("âš™ï¸ Using weak_policy augmentation...")
            active_augs = [AUG[aug] for aug in weak_policy['augs'] if aug in AUG]
        elif epoch < middle_policy['end_epoch']:
            print("âš™ï¸ Using middle_policy augmentation...")
            active_augs = [AUG[aug] for aug in middle_policy['augs'] if aug in AUG]
        elif epoch < strong_policy['end_epoch']:
            print("âš™ï¸ Using strong_policy augmentation...")
            active_augs = [AUG[aug] for aug in strong_policy['augs'] if aug in AUG]
        else:
            active_augs = [AUG[aug] for aug in strong_policy['augs'] if aug in AUG]
    else:
        active_augs = [AUG[aug] for aug, active in cfg.augmentation.items() if active and aug in AUG]

    train_transforms = []

    if cfg.online_augmentation:
        # online augmentation í•™ìŠµ : ì‹¤ì‹œê°„ìœ¼ë¡œ ì¦ê°• ê¸°ë²•ì„ ì ìš©í•˜ì—¬, ë” ë‹¤ì–‘í•œ ì¦ê°• í˜•íƒœì˜ ë°ì´í„°ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.
        # ì¥ì  : ë¬´í•œí•œ ë‹¤ì–‘ì„±, ê³¼ì í•© ë°©ì§€ íš¨ê³¼ ì¦ëŒ€, ì €ì¥ ê³µê°„ íš¨ìœ¨ì„±
        # ë‹¨ì  : ì „ì²˜ë¦¬ ê³¼ì •ì˜ ì¦ê°€ë¡œ í•™ìŠµ ì‹œê°„ ì¦ê°€, ì¬í˜„ì„±ì´ ë–¨ì–´ì§. ë„ˆë¬´ ë§ì€ ì¦ê°• ê¸°ë²•ì„ ì ìš©í•˜ë©´, ì˜ë„ì¹˜ ì•Šì€ ê²°ê³¼ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆë‹¤.
        if active_augs:
            online_transform = A.Compose([
                A.OneOf(active_augs, p=0.85), # 85% í™•ë¥ ë¡œ active_augsì— ì„¤ì •ëœ ì¦ê°• ê¸°ë²•ë“¤ì´ ì ìš©ëœë‹¤. 15% í™•ë¥ ë¡œ ì›ë³¸ train ë°ì´í„°ë¥¼ ì‚¬ìš©í•œë‹¤.
                common_resize_transform # Resize ê¸°ë²•ì€ í•­ìƒ ë™ì¼í•˜ê²Œ.
            ])
            train_transforms.append(online_transform)
        else: # ë”°ë¡œ ì§€ì •í•œ ì¦ê°• ê¸°ë²•ì´ ì—†ëŠ” ê²½ìš°, Resize ê¸°ë²•ë§Œ ì‚¬ìš©
            train_transforms.append(common_resize_transform)
    else:
        # offline augmentation í•™ìŠµ : ê°œë³„ì ìœ¼ë¡œ datasetì„ ë§Œë“¤ì–´ ConcatDatasetì„ ìµœì¢… ìƒì„±í•œë‹¤. ëª¨ë“  ì¦ê°• ê¸°ë²•ì„ ì ìš© ê°€ëŠ¥í•˜ê³ , ë§ˆì¹˜ ë°ì´í„°ì…‹ ê°œìˆ˜ ìì²´ê°€ ëŠ˜ì–´ë‚œ ê²ƒ ê°™ì€ íš¨ê³¼ë¥¼ ì¤€ë‹¤. (ì›ë˜ë¼ë©´, ì¦ê°•í•œ ë°ì´í„°ë¥¼ ì €ì¥í•´ì•¼ í•˜ì§€ë§Œ ì´ê±´ ìƒëµ.)
        # ë‹¨ì  : ë‹¤ì–‘ì„± ì œí•œ
        if active_augs:
            for aug_pipeline in active_augs: # ê°ê°ì˜ augë¥¼ transform_funcìœ¼ë¡œ ë§Œë“ ë‹¤.
                train_transforms.append(A.Compose([aug_pipeline, common_resize_transform]))
        else:
            train_transforms.append(common_resize_transform)

    # validation ì¦ê°•ì€ ê¸°ë³¸ ì¦ê°•ë§Œ ì‚¬ìš©í•œë‹¤.
    val_transform = common_resize_transform

    # Validation transform with 'eda' augmentation to simulate test conditions
    # tta_transformì€ TTAì—ì„œë„ ì‚¬ìš©í•  ì¦ê°•ì´ë‹¤.
    val_tta_transform = A.Compose([
        AUG['eda'],
        common_resize_transform
    ])
    test_tta_transform = A.Compose([
        # inference time transformì€ í•´ë‹¹ ì½”ë“œì—ì„œ ì§ì ‘ êµ¬í˜„.
        common_resize_transform
    ])


    return train_transforms, val_transform, val_tta_transform, test_tta_transform

### Offline augmentation
def augment_class_imbalance(cfg, train_df):
    # Cutout ì¦ê°• íŒŒì´í”„ë¼ì¸ ì„¤ì •
    cutout_transform = A.Compose([
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
        A.CoarseDropout(
            num_holes_range=(1, 2), # ë§ˆìŠ¤í‚¹ ê°œìˆ˜
            hole_height_range=(int(cfg.image_size * 0.05), int(cfg.image_size * 0.1)), # ë§ˆìŠ¤í‚¹ì˜ ë†’ì´ ë²”ìœ„
            hole_width_range=(int(cfg.image_size * 0.05), int(cfg.image_size * 0.2)), # ë§ˆìŠ¤í‚¹ì˜ ë„ˆë¹„ ë²”ìœ„
            fill=(0,0,0), # ê²€ì •ìƒ‰ ë§ˆìŠ¤í‚¹
            p=1.0
        )
    ])
    # ì¦ê°• ëŒ€ìƒ í´ë˜ìŠ¤
    augment_classes = cfg.class_imbalance['aug_class']
    max_samples = cfg.class_imbalance['max_samples']

    # ì¦ê°• ì´ë¯¸ì§€, ë¼ë²¨, ID ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    augmented_labels = []    # ì¦ê°•ëœ ì´ë¯¸ì§€ ë¼ë²¨
    augmented_ids = []       # ì¦ê°•ëœ ì´ë¯¸ì§€ ID
    total_augmented = 0
    # ì¦ê°• ëŒ€ìƒ í´ë˜ìŠ¤ ë£¨í”„
    for cls in augment_classes:
        print(cls, "í´ë˜ìŠ¤")
        cls_df = train_df[train_df['target'] == cls]
        current_count = len(cls_df)
        print("í˜„ì¬ ê°œìˆ˜:", current_count)
        # ëª©í‘œ ìƒ˜í”Œ ìˆ˜ì— ë„ë‹¬í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì¦ê°• ì´ë¯¸ì§€ ê°œìˆ˜ ê³„ì‚°
        # (current_countê°€ max_samplesë³´ë‹¤ ë§ìœ¼ë©´ 0 ë˜ëŠ” ìŒìˆ˜ê°€ ë¨)
        to_generate = max_samples - current_count
        print("ì¦ê°• ê°œìˆ˜:", to_generate)
        # ë§Œì•½ í˜„ì¬ ì´ë¯¸ì§€ ìˆ˜ê°€ ëª©í‘œì¹˜ë³´ë‹¤ ë§ê±°ë‚˜ ê°™ìœ¼ë©´ ì¦ê°•í•  í•„ìš” ì—†ìœ¼ë¯€ë¡œ ë‹¤ìŒ í´ë˜ìŠ¤ë¡œ ë„˜ì–´ê°
        if to_generate <= 0:
            continue
        # ì¦ê°•í•  ì´ë¯¸ì§€ë“¤ì„ ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì—ì„œ ìƒ˜í”Œë§ (ì¤‘ë³µ í—ˆìš©: replace=True)
        # ëª©í‘œ ìƒ˜í”Œ ìˆ˜ (to_generate)ë§Œí¼ ì´ë¯¸ì§€ë¥¼ ìƒ˜í”Œë§í•˜ë©°,
        # ë§Œì•½ í˜„ì¬ ì´ë¯¸ì§€ ê°œìˆ˜(current_count)ê°€ to_generateë³´ë‹¤ ì ìœ¼ë©´ ì¤‘ë³µ ì„ íƒ(replace=True)
        # ì´ ë¶€ë¶„ì€ ì›ë˜ ì½”ë“œì˜ `if/else` ì¡°ê±´ë¬¸ì„ í†µí•©í•œ ê²ƒì…ë‹ˆë‹¤.
        sampled_df = cls_df.sample(n=to_generate, replace=False, random_state=cfg.random_seed).reset_index(drop=True)
        # ìƒ˜í”Œë§ëœ ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ì¦ê°• ìˆ˜í–‰ ë° ì €ì¥
        for idx, row in sampled_df.iterrows():
            img_id = row['ID']
            img_path = os.path.join(cfg.data_dir, 'train', img_id)
            # ì´ë¯¸ì§€ ë¡œë“œ (OpenCVëŠ” ê¸°ë³¸ì ìœ¼ë¡œ BGRë¡œ ë¡œë“œ)
            img = cv2.imread(img_path)
            # BGR ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜ (AlbumentationsëŠ” RGBë¥¼ ê¸°ëŒ€)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

            # ì •ì˜ëœ Cutout ì¦ê°• ì ìš©
            augmented_img = cutout_transform(image=img)['image']

            # ì¦ê°•ëœ ì´ë¯¸ì§€ì˜ ìƒˆë¡œìš´ ID ìƒì„± (ê¸°ì¡´ ID ì•ì— 'aug_' ì ‘ë‘ì‚¬ ì¶”ê°€)
            new_id = f"aug_{img_id}"
            save_path = os.path.join(cfg.data_dir, 'train', new_id)

            # ì¦ê°•ëœ RGB ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ BGRë¡œ ë³€í™˜í•˜ì—¬ íŒŒì¼ë¡œ ì €ì¥
            cv2.imwrite(save_path, cv2.cvtColor(augmented_img, cv2.COLOR_RGB2BGR))

            # ì¦ê°•ëœ ì´ë¯¸ì§€ì˜ ë¼ë²¨ê³¼ IDë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            augmented_labels.append(cls)
            augmented_ids.append(new_id)
            total_augmented += 1
        print(f"ì´ {total_augmented} ê°œì˜ ì´ë¯¸ì§€ ì¦ê°•")
    return augmented_ids, augmented_labels

def augment_validation(cfg, val_df):
    # ì¦ê°• ì´ë¯¸ì§€, ë¼ë²¨, ID ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    augmented_labels = []    # ì¦ê°•ëœ ì´ë¯¸ì§€ ë¼ë²¨
    augmented_ids = []       # ì¦ê°•ëœ ì´ë¯¸ì§€ ID
    total_augmented = 0
    val_tta_transform = AUG['eda']
    # ì¦ê°• ëŒ€ìƒ í´ë˜ìŠ¤ ë£¨í”„
    for idx, row in val_df.iterrows():
        img_id = row['ID']
        cls = row['target']
        img_path = os.path.join(cfg.data_dir, 'train', img_id)
        # ì´ë¯¸ì§€ ë¡œë“œ (OpenCVëŠ” ê¸°ë³¸ì ìœ¼ë¡œ BGRë¡œ ë¡œë“œ)
        img = cv2.imread(img_path)
        # BGR ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜ (AlbumentationsëŠ” RGBë¥¼ ê¸°ëŒ€)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # ì •ì˜ëœ Cutout ì¦ê°• ì ìš© > ì´ 4ë²ˆ ì ìš©
        for i_ in range(4):
            augmented_img = val_tta_transform(image=img)['image']

            # ì¦ê°•ëœ ì´ë¯¸ì§€ì˜ ìƒˆë¡œìš´ ID ìƒì„± (ê¸°ì¡´ ID ì•ì— 'aug_' ì ‘ë‘ì‚¬ ì¶”ê°€)
            new_id = f"val{i_}_{img_id}"
            save_path = os.path.join(cfg.data_dir, 'train', new_id)

            # ì¦ê°•ëœ RGB ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ BGRë¡œ ë³€í™˜í•˜ì—¬ íŒŒì¼ë¡œ ì €ì¥
            cv2.imwrite(save_path, cv2.cvtColor(augmented_img, cv2.COLOR_RGB2BGR))

            # ì¦ê°•ëœ ì´ë¯¸ì§€ì˜ ë¼ë²¨ê³¼ IDë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            augmented_labels.append(cls)
            augmented_ids.append(new_id)
            total_augmented += 1
    print(f"ì´ {total_augmented} ê°œì˜ validation ì´ë¯¸ì§€ ì¦ê°•")
    return augmented_ids, augmented_labels

def delete_offline_augmented_images(cfg, augmented_ids):
    train_dir = os.path.join(cfg.data_dir, 'train')
    _ = 0
    for filename in augmented_ids:
        file_path = os.path.join(train_dir, filename)
        if os.path.exists(file_path):
            os.remove(file_path)
            _ += 1
        else:
            print("Wrong filename:", file_path)
    print(_,"ê°œ ì´ë¯¸ì§€ ì œê±°")
