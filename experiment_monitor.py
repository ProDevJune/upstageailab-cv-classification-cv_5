#!/usr/bin/env python3
"""
ì‹¤í—˜ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
ì‹¤í–‰ ì¤‘ì¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì‹¤í—˜ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ë¥¼ ì¶”ì í•©ë‹ˆë‹¤.
"""

import os
import sys
import time
import psutil
import threading
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any

class ExperimentMonitor:
    """ì‹¤í—˜ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.monitoring = False
        self.config = {
            'cpu_threshold': 95.0,
            'memory_threshold': 90.0,
            'disk_threshold': 95.0,
            'gpu_memory_threshold': 95.0,
            'long_running_threshold': 7200,  # 2ì‹œê°„
            'check_interval': 30  # 30ì´ˆë§ˆë‹¤ ì²´í¬
        }
        self.system_alerts = []
        self.monitor_thread = None
        
    def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.monitoring:
            print("âš ï¸ ëª¨ë‹ˆí„°ë§ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
            return
            
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self.monitor_thread.start()
        print("âœ… ì‹¤í—˜ ëª¨ë‹ˆí„°ë§ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=2)
        print("ğŸ›‘ ì‹¤í—˜ ëª¨ë‹ˆí„°ë§ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    def _monitoring_loop(self):
        """ëª¨ë‹ˆí„°ë§ ë©”ì¸ ë£¨í”„"""
        while self.monitoring:
            try:
                self._check_system_resources()
                self._check_running_experiments()
                time.sleep(self.config['check_interval'])
            except Exception as e:
                self._log_event("monitor_error", f"ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                
    def _check_system_resources(self):
        """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì²´í¬"""
        # CPU ì²´í¬
        cpu_percent = psutil.cpu_percent(interval=1)
        if cpu_percent > self.config['cpu_threshold']:
            self._log_event("cpu_high", f"CPU ì‚¬ìš©ë¥  ë†’ìŒ: {cpu_percent:.1f}%")
            
        # ë©”ëª¨ë¦¬ ì²´í¬
        memory = psutil.virtual_memory()
        if memory.percent > self.config['memory_threshold']:
            self._log_event("memory_high", f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: {memory.percent:.1f}%")
            
        # ë””ìŠ¤í¬ ì²´í¬
        disk = psutil.disk_usage('/')
        disk_percent = (disk.used / disk.total) * 100
        if disk_percent > self.config['disk_threshold']:
            self._log_event("disk_high", f"ë””ìŠ¤í¬ ì‚¬ìš©ë¥  ë†’ìŒ: {disk_percent:.1f}%")
            
        # GPU ì²´í¬ (ê°€ëŠ¥í•œ ê²½ìš°)
        try:
            import torch
            if torch.cuda.is_available():
                for i in range(torch.cuda.device_count()):
                    allocated = torch.cuda.memory_allocated(i) / torch.cuda.max_memory_allocated(i) * 100
                    if allocated > self.config['gpu_memory_threshold']:
                        self._log_event("gpu_memory_high", f"GPU {i} ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: {allocated:.1f}%")
        except ImportError:
            pass
            
    def _check_running_experiments(self):
        """ì‹¤í–‰ ì¤‘ì¸ ì‹¤í—˜ í”„ë¡œì„¸ìŠ¤ ì²´í¬"""
        long_running_processes = []
        
        for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'create_time']):
            try:
                if proc.info['name'] in ['python', 'python3']:
                    cmdline = ' '.join(proc.info['cmdline']) if proc.info['cmdline'] else ''
                    
                    # ì‹¤í—˜ ê´€ë ¨ í”„ë¡œì„¸ìŠ¤ ê°ì§€
                    if any(keyword in cmdline for keyword in ['gemini_main_v2.py', 'run_experiments.py', 'experiment_runner.py']):
                        # ì‹¤í–‰ ì‹œê°„ ì²´í¬
                        runtime = time.time() - proc.info['create_time']
                        
                        if runtime > self.config['long_running_threshold']:
                            long_running_processes.append({
                                'pid': proc.info['pid'],
                                'runtime_hours': runtime / 3600,
                                'cmdline': cmdline[:100] + "..." if len(cmdline) > 100 else cmdline
                            })
                            
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue
                
        # ì¥ì‹œê°„ ì‹¤í–‰ í”„ë¡œì„¸ìŠ¤ ì•Œë¦¼
        for proc in long_running_processes:
            self._log_event("long_running", f"ì¥ì‹œê°„ ì‹¤í–‰ ì‹¤í—˜: PID {proc['pid']} ({proc['runtime_hours']:.1f}ì‹œê°„)")
            
    def _log_event(self, event_type: str, message: str):
        """ì´ë²¤íŠ¸ ë¡œê¹…"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        alert = {
            'timestamp': timestamp,
            'type': event_type,
            'message': message
        }
        
        self.system_alerts.append(alert)
        
        # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
        if len(self.system_alerts) > 100:
            self.system_alerts = self.system_alerts[-100:]
            
        # ì½˜ì†” ì¶œë ¥
        print(f"âš ï¸ [{timestamp}] {message}")
        
    def get_monitoring_status(self) -> Dict[str, Any]:
        """í˜„ì¬ ëª¨ë‹ˆí„°ë§ ìƒíƒœ ë°˜í™˜"""
        try:
            # ì‹œìŠ¤í…œ ì •ë³´
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            
            # GPU ì •ë³´
            gpu_info = {'available': False, 'count': 0}
            try:
                import torch
                if torch.cuda.is_available():
                    gpu_info = {
                        'available': True,
                        'count': torch.cuda.device_count(),
                        'devices': []
                    }
                    for i in range(torch.cuda.device_count()):
                        gpu_info['devices'].append({
                            'id': i,
                            'name': torch.cuda.get_device_name(i),
                            'memory_allocated': torch.cuda.memory_allocated(i) / (1024**3),
                            'memory_total': torch.cuda.get_device_properties(i).total_memory / (1024**3)
                        })
            except ImportError:
                pass
                
            return {
                'monitoring_active': self.monitoring,
                'system': {
                    'cpu_percent': cpu_percent,
                    'memory_percent': memory.percent,
                    'memory_total_gb': memory.total / (1024**3),
                    'memory_available_gb': memory.available / (1024**3),
                    'disk_percent': (disk.used / disk.total) * 100,
                    'disk_total_gb': disk.total / (1024**3),
                    'free_space_gb': disk.free / (1024**3)
                },
                'gpu': gpu_info,
                'alerts_count': len(self.system_alerts),
                'recent_alerts': self.system_alerts[-10:] if self.system_alerts else []
            }
            
        except Exception as e:
            self._log_event("status_error", f"ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    def print_status_report(self):
        """ìƒíƒœ ë¦¬í¬íŠ¸ ì¶œë ¥"""
        status = self.get_monitoring_status()
        
        if 'error' in status:
            print(f"âŒ ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜: {status['error']}")
            return
        
        print("\nğŸ” ì‹¤í—˜ ëª¨ë‹ˆí„°ë§ ìƒíƒœ ë¦¬í¬íŠ¸")
        print("=" * 50)
        
        # ëª¨ë‹ˆí„°ë§ ìƒíƒœ
        if status['monitoring_active']:
            print("âœ… ëª¨ë‹ˆí„°ë§ í™œì„±í™”")
        else:
            print("âš ï¸ ëª¨ë‹ˆí„°ë§ ë¹„í™œì„±í™”")
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        sys_info = status['system']
        print(f"\nğŸ–¥ï¸ ì‹œìŠ¤í…œ ìƒíƒœ:")
        print(f"   CPU: {sys_info['cpu_percent']:.1f}%")
        print(f"   ë©”ëª¨ë¦¬: {sys_info['memory_percent']:.1f}%")
        print(f"   ë””ìŠ¤í¬: {sys_info['disk_percent']:.1f}% (ì—¬ìœ : {sys_info['free_space_gb']:.1f}GB)")
        
        # GPU ìƒíƒœ
        gpu_info = status['gpu']
        if gpu_info['available']:
            print(f"   GPU: {gpu_info['count']}ê°œ ì‚¬ìš© ê°€ëŠ¥")
            for device in gpu_info.get('devices', []):
                usage = (device['memory_allocated'] / device['memory_total']) * 100 if device['memory_total'] > 0 else 0
                print(f"     GPU {device['id']}: {device['name']} ({usage:.1f}% ì‚¬ìš©)")
        else:
            print("   GPU: ì‚¬ìš© ë¶ˆê°€")
        
        # ê²½ê³  ìƒíƒœ
        alert_count = status['alerts_count']
        if alert_count > 0:
            print(f"\nâš ï¸ ê²½ê³ : {alert_count}ê°œ")
            recent_alerts = status['recent_alerts']
            for alert in recent_alerts:
                print(f"   â€¢ [{alert['timestamp']}] {alert['message']}")
        else:
            print("\nâœ… ê²½ê³  ì—†ìŒ")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ì‹¤í—˜ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ")
    parser.add_argument('--start', action='store_true', help='ëª¨ë‹ˆí„°ë§ ì‹œì‘')
    parser.add_argument('--status', action='store_true', help='í˜„ì¬ ìƒíƒœ ì¶œë ¥')
    parser.add_argument('--config', type=str, help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    monitor = ExperimentMonitor()
    
    if args.config:
        # ì„¤ì • ì—…ë°ì´íŠ¸
        try:
            import yaml
            with open(args.config, 'r') as f:
                config_update = yaml.safe_load(f)
            monitor.config.update(config_update)
            print(f"âœ… ì„¤ì • ì—…ë°ì´íŠ¸: {args.config}")
        except Exception as e:
            print(f"âš ï¸ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    if args.status:
        # ìƒíƒœë§Œ ì¶œë ¥í•˜ê³  ì¢…ë£Œ
        monitor.print_status_report()
        return
    
    if args.start:
        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        monitor.start_monitoring()
        try:
            print("ğŸ” ëª¨ë‹ˆí„°ë§ ì‹¤í–‰ ì¤‘... (Ctrl+Cë¡œ ì¤‘ì§€)")
            while monitor.monitoring:
                time.sleep(5)
                # ì£¼ê¸°ì ìœ¼ë¡œ ìƒíƒœ ì¶œë ¥ (ì„ íƒì‚¬í•­)
                if len(monitor.system_alerts) > 0:
                    # ìƒˆë¡œìš´ ê²½ê³ ê°€ ìˆìœ¼ë©´ ìƒíƒœ ì¶œë ¥
                    pass
        except KeyboardInterrupt:
            print("\nğŸ›‘ ì‚¬ìš©ìê°€ ëª¨ë‹ˆí„°ë§ì„ ì¤‘ì§€í–ˆìŠµë‹ˆë‹¤.")
        finally:
            monitor.stop_monitoring()
        return
    
    # ëŒ€í™”í˜• ëª¨ë“œ
    print("ğŸ” ì‹¤í—˜ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ")
    print("=" * 40)
    print("ğŸ“‹ ì˜µì…˜:")
    print("1. ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    print("2. í˜„ì¬ ìƒíƒœ í™•ì¸")
    print("3. ì„¤ì • í™•ì¸")
    print("0. ì¢…ë£Œ")
    
    while True:
        try:
            choice = input("\nì„ íƒí•˜ì„¸ìš” (0-3): ").strip()
            
            if choice == '0':
                print("ğŸ‘‹ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                monitor.stop_monitoring()
                break
            elif choice == '1':
                monitor.start_monitoring()
                print("ğŸ” ëª¨ë‹ˆí„°ë§ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. 'Ctrl+C'ë¡œ ì¤‘ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                try:
                    while monitor.monitoring:
                        time.sleep(1)
                except KeyboardInterrupt:
                    print("\nğŸ›‘ ëª¨ë‹ˆí„°ë§ì„ ì¤‘ì§€í•©ë‹ˆë‹¤.")
                    monitor.stop_monitoring()
            elif choice == '2':
                monitor.print_status_report()
            elif choice == '3':
                print("\nâš™ï¸ í˜„ì¬ ì„¤ì •:")
                for key, value in monitor.config.items():
                    print(f"   {key}: {value}")
            else:
                print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
            monitor.stop_monitoring()
            break
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()
